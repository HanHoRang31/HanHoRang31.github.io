[{"categories":null,"contents":"","date":"Mar 05","permalink":"https://HanHoRang31.github.io/projects/a_project/","tags":null,"title":"HanHoRang Git Repo"},{"categories":null,"contents":" 1 2 AWS EKS Workshop Study (=AEWS)ëŠ” EKS Workshop ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°,ê³µê°œëœ AWS EKS Workshopì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. EKS VPC CNI CNI(Container Network Interface) ë€ ë„¤íŠ¸ì›Œí¬ í”ŒëŸ¬ê·¸ì¸ ì¸í„°í˜ì´ìŠ¤ë¡œ k8s ë„¤íŠ¸ì›Œí¬ í™˜ê²½ì„ êµ¬ì„±í•´ì¤€ë‹¤. EKS ì—ì„œëŠ” ê¸°ë³¸ CNIë¡œ VPCë¥¼ ì‚¬ìš©í•œë‹¤. ì—¬ê¸°ì„œ VPCëŠ” AWS ë„¤íŠ¸ì›Œí¬ ì„œë¹„ìŠ¤ì¸ AWS VPCë¡œ VPC CIDRì„ ì´ìš©í•˜ì—¬ íŒŒë“œ IP í• ë‹¹ ë° í†µì‹ ì„ ì§€ì›í•œë‹¤.\nEKS ì—ì„œ CNIë¥¼ VPCë¡œ ì‚¬ìš©í•˜ë©´ ëŒ€í‘œì ìœ¼ë¡œ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ì ì€ ë‘ ê°€ì§€ì´ë‹¤.\në…¸ë“œ ëŒ€ì—­ê³¼ íŒŒë“œ ëŒ€ì—­ì´ ë™ì¼í•˜ì—¬ ë‹¤ë¥¸ ë…¸ë“œê°„ í†µì‹ ì‹œ ì˜¤ë²„ë ˆì´ê°€ ì—†ì–´ í†µì‹  ì˜¤ë²„í—¤ë“œê°€ ê°ì†Œí•œë‹¤.\në‹¤ë¥¸ CNI(Caclico)ëŠ” ë…¸ë“œì™€ íŒŒë“œ IP ëŒ€ì—­ì´ ë‹¬ë¼ ë…¸ë“œ ê°„ í†µì‹ ì— ì˜¤ë²„ë ˆì´ë¥¼ ì‚¬ìš©í•˜ëŠ” ë°˜ë©´ VPC CNIëŠ” ëŒ€ì—­ì´ ê°™ì•„ ì˜¤ë²„ë ˆì´ì—†ì´ ì›ë³¸ íŒ¨í‚· ê·¸ëŒ€ë¡œ í†µì‹ í•œë‹¤.\nAWS VPC ì˜ ì—°ë™ ì„œë¹„ìŠ¤ (VPC ì„œë¸Œë„·, ë³´ì•ˆ ê·¸ë£¹)ë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë˜í”½ ì œì–´ê°€ ê°€ëŠ¥í•˜ë‹¤.\në„¤íŠ¸ì›Œí¬ ì„¸ë¶€ ì •ë³´ í™•ì¸í•˜ê¸° VPC CNIì— ëŒ€í•´ ì„¸ë¶€ì ìœ¼ë¡œ í™•ì¸í•´ë³´ê² ë‹¤. VPC CNIëŠ” aws-cni íŒŒë“œë¥¼ í†µí•´ ê° ë…¸ë“œì— ë°°í¬ëœë‹¤. ì´ë¥¼ í™•ì¸í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ê¸°ë³¸ ì •ë³´ë¥¼ í™•ì¸í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 # CNI ë²„ì „ ì •ë³´ í™•ì¸ kubectl describe daemonset aws-node --namespace kube-system | grep Image | cut -d \u0026#34;/\u0026#34; -f 2 --- amazon-k8s-cni-init:v1.12.6-eksbuild.1 amazon-k8s-cni:v1.12.6-eksbuild.1 # VPC MODE í™•ì¸ kubectl describe cm -n kube-system kube-proxy-config | grep mode --- mode: \u0026#34;iptables\u0026#34; # ë…¸ë“œ IP ë° PUBLIC IP í™•ì¸ aws ec2 describe-instances --query \u0026#34;Reservations[*].Instances[*].{PublicIPAdd:PublicIpAddress,PrivateIPAdd:PrivateIpAddress,InstanceName:Tags[?Key==\u0026#39;Name\u0026#39;]|[0].Value,Status:State.Name}\u0026#34; --filters Name=instance-state-name,Values=running --output table --- ------------------------------------------------------------------------- | DescribeInstances | +------------------------+----------------+------------------+----------+ | InstanceName | PrivateIPAdd | PublicIPAdd | Status | +------------------------+----------------+------------------+----------+ | hanhorang-ng1-Node | 192.168.3.162 | 15.164.220.246 | running | | hanhorang-ng1-Node | 192.168.2.16 | 3.34.30.94 | running | | hanhorang-bastion-EC2 | 192.168.1.100 | 13.125.121.220 | running | | hanhorang-ng1-Node | 192.168.1.5 | 3.36.127.19 | running | +------------------------+----------------+------------------+----------+ # kubectl get pods -n kube-system -o wide --- NAME READY STATUS RESTARTS AGE IP NODE NOMINATED NODE READINESS GATES aws-load-balancer-controller-7857849d69-qc9nr 1/1 Running 0 146m 192.168.1.190 ip-192-168-1-5.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; aws-load-balancer-controller-7857849d69-qjvkk 1/1 Running 0 146m 192.168.3.186 ip-192-168-3-162.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; aws-node-l2twq 1/1 Running 0 170m 192.168.1.5 ip-192-168-1-5.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; aws-node-tj9xl 1/1 Running 0 170m 192.168.3.162 ip-192-168-3-162.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; aws-node-v9m8g 1/1 Running 0 170m 192.168.2.16 ip-192-168-2-16.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; coredns-6777fcd775-2qq92 1/1 Running 0 168m 192.168.2.227 ip-192-168-2-16.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; coredns-6777fcd775-rhqdp 1/1 Running 0 168m 192.168.1.254 ip-192-168-1-5.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; external-dns-6b5bbbf9d-l7ms2 1/1 Running 0 143m 192.168.2.221 ip-192-168-2-16.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-proxy-bbgr9 1/1 Running 0 168m 192.168.3.162 ip-192-168-3-162.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-proxy-nm8ls 1/1 Running 0 169m 192.168.2.16 ip-192-168-2-16.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt; kube-proxy-xm2qq 1/1 Running 0 169m 192.168.1.5 ip-192-168-1-5.ap-northeast-2.compute.internal \u0026lt;none\u0026gt; \u0026lt;none\u0026gt;** VPC CNI Modeë¡œ userspace ,iptables , ipvs ëª¨ë“œê°€ ì¡´ì¬í•˜ë‚˜, ë³´í†µ iptable ëª¨ë“œë¥¼ ì‚¬ìš©í•œë‹¤. ì´ìœ ëŠ” userspace ê²½ìš°, ëŠë¦¬ê³  ë¹„íš¨ìœ¨ì ì´ì—¬ì„œ ê±°ì˜ ì‚¬ìš©ë˜ì§€ ì•Šì€ ìƒíƒœì´ë‹¤. ë°˜ë©´ ipvs ì˜ ê²½ìš°, L4 ê¸°ë°˜ì˜ ë¡œë“œë°¸ëŸ°ì„œë¡œ ë§¤ìš° ë¹ ë¥¸ ì´ì ì´ ìˆì§€ë§Œ í˜¸í™˜ì„± ë¬¸ì œë¡œ ì¶”ê°€ ì„¤ì •ì´ í•„ìš”í•˜ê³  ì»¤ë®¤ë‹ˆí‹° ê·œëª¨ê°€ ì ì–´ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì´ ë™ë°˜ë˜ì–´ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ì–´ì„œ ê° ë…¸ë“œì— ì ‘ì†í•˜ì—¬ ë„¤íŠ¸ì›Œí¬ ì •ë³´ë¥¼ í™•ì¸í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 # ê° ë…¸ë“œ IP í™•ì¸ ë° ë³€ìˆ˜ ì„¤ì • kubectl get nodes -o wide --- NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-192-168-1-5.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h10m v1.24.11-eks-a59e1f0 192.168.1.5 3.36.127.19 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 ip-192-168-2-16.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h10m v1.24.11-eks-a59e1f0 192.168.2.16 3.34.30.94 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 ip-192-168-3-162.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h10m v1.24.11-eks-a59e1f0 192.168.3.162 15.164.220.246 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 # ìœ„ External IP í™•ì¸í•˜ì—¬ ë…¸ë“œë³„ ë³€ìˆ˜ ì„¤ì • N1=3.36.127.19 N2=3.34.30.94 N3=15.164.220.246 # ê° ë…¸ë“œì— íˆ´ ì„¤ì¹˜ ssh ec2-user@$N1 sudo yum install links tree jq tcpdump -y ssh ec2-user@$N2 sudo yum install links tree jq tcpdump -y ssh ec2-user@$N3 sudo yum install links tree jq tcpdump -y # ë„¤íŠ¸ì›Œí¬ CNI ë¡œê·¸ ê²½ë¡œ í™•ì¸ ssh ec2-user@$N1 tree /var/log/aws-routed-eni --- /var/log/aws-routed-eni â”œâ”€â”€ egress-v4-plugin.log # ì´ê·¸ë˜ìŠ¤ íŠ¸ë˜í”½ ê´€ë ¨ ë¡œê·¸ íŒŒì¼ â”œâ”€â”€ ipamd.log # eni IP ì£¼ì†Œ í• ë‹¹, í•´ì œ, ê·¸ë¦¬ê³  ì˜¤ë¥˜ ë“±ê³¼ ê´€ë ¨ëœ ì´ë²¤íŠ¸ì™€ ìƒíƒœ ë³€ê²½ ë¡œê·¸ íŒŒì¼ â””â”€â”€ plugin.log # íŒŒë“œì˜ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •, íŠ¸ë˜í”½ ê´€ë¦¬, ì˜¤ë¥˜ ì²˜ë¦¬ ë“±ê³¼ ê´€ë ¨ëœ ì´ë²¤íŠ¸ì™€ ìƒíƒœ ë³€ê²½ ë¡œê·¸ íŒŒì¼** # eni IP ì£¼ì†Œ í• ë‹¹, í•´ì œ, ê·¸ë¦¬ê³  ì˜¤ë¥˜ ë“±ê³¼ ê´€ë ¨ëœ ì´ë²¤íŠ¸ì™€ ìƒíƒœ ë³€ê²½ ë¡œê·¸ íŒŒì¼ ssh ec2-user@$N1 cat /var/log/aws-routed-eni/ipamd.log | jq --- { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T07:16:00.757Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;ipamd/ipamd.go:1599\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Adding 192.168.1.190/32 to DS for eni-0d79c0daf04234458\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T07:16:00.757Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;ipamd/ipamd.go:1599\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;IP already in DS\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T07:16:00.757Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;ipamd/ipamd.go:1475\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Trying to add 192.168.1.145\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;info\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T07:16:00.757Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;ipamd/ipamd.go:1599\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Adding 192.168.1.145/32 to DS for eni-0d79c0daf04234458\u0026#34; } ... # íŒŒë“œì˜ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ ì„¤ì •, íŠ¸ë˜í”½ ê´€ë¦¬, ì˜¤ë¥˜ ì²˜ë¦¬ ë“±ê³¼ ê´€ë ¨ëœ ì´ë²¤íŠ¸ì™€ ìƒíƒœ ë³€ê²½ ë¡œê·¸ íŒŒì¼ ssh ec2-user@$N1 cat /var/log/aws-routed-eni/plugin.log | jq --- { \u0026#34;level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T05:59:41.741Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;driver/driver.go:281\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Successfully disabled IPv6 RA and ICMP redirects on hostVeth eni25c78048487\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T05:59:41.741Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;driver/driver.go:297\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Successfully setup container route, containerAddr=192.168.1.190/32, hostVeth=eni25c78048487, rtTable=main\u0026#34; } { \u0026#34;level\u0026#34;: \u0026#34;debug\u0026#34;, \u0026#34;ts\u0026#34;: \u0026#34;2023-05-08T05:59:41.741Z\u0026#34;, \u0026#34;caller\u0026#34;: \u0026#34;driver/driver.go:297\u0026#34;, \u0026#34;msg\u0026#34;: \u0026#34;Successfully setup toContainer rule, containerAddr=192.168.1.190/32, rtTable=main\u0026#34; } ... ì§ì ‘ ë¼ìš°í„° ë° ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ í™•ì¸í•˜ì—¬ íŒŒë“œ IPì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\në¹¨ê°„ ë„¤ëª¨ëŠ” ë…¸ë“œ IPë¡œ í”„ë¼ì´ë¹— IPv4 ì£¼ì†Œê°€ í• ë‹¹ë˜ì–´ ìˆìŒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë˜í•œ ë…¸ë€ ë„¤ëª¨ ë° ì„ ì´ íŒŒë“œ í• ë‹¹ì´ ë˜ë©´ ìƒê¸°ëŠ” IPë¡œ ë³´ì¡° í”„ë¼ì´ë¹— IPv4 ì£¼ì†Œê°€ í• ë‹¹ë¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. ë…¸ë“œì— íŒŒë“œê°€ í• ë‹¹ë˜ë©´ ë„¤íŠ¸ì›Œí¬ì¸í„°í˜ì´ìŠ¤ê°€ eniY@N ì˜ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ê°€ í• ë‹¹ëœë‹¤. ë¼ìš°í„° ì •ë³´ë¥¼ í™•ì¸í–ˆì„ ë•Œ ë…¸ë“œ 1ì˜ CIDRì´ 192.168.1.0/24 ë¡œ í•´ë‹¹ IP ëŒ€ì—­ì˜ íŠ¸ë˜í”½ì„ ë°›ìœ¼ë©´ 192.168.1.5 ë¡œ í†µì‹ ë¨ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í†µì‹  íë¦„ í™•ì¸í•˜ê¸° ì´ë ‡ê²Œ í• ë‹¹ëœ íŒŒë“œì˜ IPê°€ ì–´ë–»ê²Œ í†µì‹ í•˜ëŠ”ì§€ íŒŒë“œê°„ í†µì‹ ê³¼ ì™¸ë¶€ í†µì‹ ì„ ë‚˜ëˆ  í†µì‹  íë¦„ì„ í™•ì¸í•´ë³´ì. ë¨¼ì € í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ íŒŒë“œê°„ í†µì‹ ì„ í™•ì¸í•˜ê² ë‹¤. í…ŒìŠ¤íŠ¸ íŒŒë“œë¥¼ 3ê°œ ë°°í¬í•˜ì—¬ íŒŒë“œ 1ê³¼ íŒŒë“œ2ì˜ IP í†µì‹ íë¦„ì„ í™•ì¸í•  ê²ƒì´ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # í…ŒìŠ¤íŠ¸ íŒŒë“œ ë°°í¬ cat \u0026lt;\u0026lt;EOF | kubectl create -f - apiVersion: apps/v1 kind: Deployment metadata: name: netshoot-pod spec: replicas: 3 selector: matchLabels: app: netshoot-pod template: metadata: labels: app: netshoot-pod spec: containers: - name: netshoot-pod image: nicolaka/netshoot command: [\u0026#34;tail\u0026#34;] args: [\u0026#34;-f\u0026#34;, \u0026#34;/dev/null\u0026#34;] terminationGracePeriodSeconds: 0 EOF # ë°°í¬ í™•ì¸ kubectl get pods -A ---- NAMESPACE NAME READY STATUS RESTARTS AGE default netshoot-pod-7757d5dd99-9dr8p 1/1 Running 0 90s default netshoot-pod-7757d5dd99-jw4z4 1/1 Running 0 90s default netshoot-pod-7757d5dd99-tgwj7 1/1 Running 0 90s ë‚´ë¶€ í†µì‹ ì€ tcpdump ì˜ íŒ¨í‚· ë¤í”„ë¥¼ í†µí•´ í†µì‹  ê³¼ì •ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. íŒŒë“œ1ì— ì ‘ì†í•˜ì—¬ íŒŒë“œ2ì— ì§ì ‘ íŠ¸ë˜í”½ì„ ì´ì„œ í†µì‹  íë¦„ì„ í™•ì¸í•˜ì\níŒ¨í‚·ì—ì„œì™€ ê°™ì´ ì˜¤ë²„ë ˆì´ì—†ì´ íŒŒë“œì— í• ë‹¹ëœ IPë¡œ ì§ì ‘ í†µì‹ í•¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. ì´ì–´ì„œ ì™¸ë¶€ í†µì‹ ì„ ì§„í–‰í•´ë³´ì. ì™¸ë¶€ í†µì‹ ì€ SNATì„ í†µí•´ ì§„í–‰í•˜ê²Œ ë˜ëŠ”ë° SNATì˜ ê²½ìš° iptableì˜ ë£°ì„ í†µí•´ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nIptable ë£°ì— ë”°ë¼ AWS-SNAT-CHAIN-0, AWS-SNAT-CHAIN-1 ì— ë§¤ì¹­ë˜ì–´, ëª©ì ì§€ê°€ 192.168.0.0/16 ì•„ë‹ˆê³  ì™¸ë¶€ ë¹ ì ¸ë‚˜ê°ˆë•Œ SNAT 192.168.1.5ë¡œ ë³€ê²½ë˜ì–´ ë‚˜ê°„ë‹¤ íŒŒë“œ ì•ˆì—ì„œ ì™¸ë¶€ ë„¤íŠ¸ì›Œí¬ë¡œ í†µì‹ ì„ í•˜ì—¬ í†µì‹  íë¦„ì„ í™•ì¸í•˜ì\ní†µì‹  íŒ¨í‚·ì„ í†µí•´ í™•ì¸í•˜ë©´ iptableì˜ ë£°ê³¼ ê°™ì´ 192.168.1.5ë¡œ IPê°€ SNATë˜ì–´ í†µì‹ ë¨ì„ ì•Œ ìˆ˜ ìˆë‹¤. ë„¤íŠ¸ì›Œí¬ Addon ì„¤ì¹˜(ALB, External DNS) ì´ì–´ì„œ EKSì—ì„œ ì œê³µí•˜ëŠ” ë„¤íŠ¸ì›Œí¬ ì• ë“œì˜¨ ì¤‘ ALB Controllerì™€ External DNSë¥¼ ì‚´í´ë³´ê³  ë°°í¬í•˜ê² ë‹¤. ê° addonì„ ê°„ëµí•˜ê²Œ ìš”ì•½í•´ì„œ í‘œë¡œ ë‚˜íƒ€ë‚´ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\nAddon ì„œë¹„ìŠ¤ ì‚¬ìš© AWS ì„œë¹„ìŠ¤ ëª©ì  Load Balancer Controller AWS Elastic Load Balancer(ELB) ë„¤íŠ¸ì›Œí¬ ë¡œë“œë°¸ëŸ°ì„œ(L4, L7) ì‚¬ìš© External DNS Controller AWS Route53 DNS ë„ë©”ì¸ ì—°ë™ ë° ì‚¬ìš© í‘œë¡œ í™•ì¸í•  ìˆ˜ ìˆê² ì§€ë§Œ ë„¤íŠ¸ì›Œí¬ addonë“¤ì€ AWS ë„¤íŠ¸ì›Œí¬ ì„œë¹„ìŠ¤(ELB, Route53)ì„ ì—°ë™í•´ì„œ ì‚¬ìš©í•œë‹¤. ê·¸ë ‡ê¸° ë•Œë¬¸ì— Addon ì„¤ì¹˜ì‹œ AWS ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ë³´ì•ˆ ì •ì±…(IAM) ì—°ë™ì´ í•„ìš”í•˜ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” IAM ì •ì±… ì—°ë™ ë°©ë²•ìœ¼ë¡œ IAM OIDCë¥¼ í†µí•´ EKS ì„œë¹„ìŠ¤ì–´ì¹´ìš´íŠ¸ì— IAM ì •ì±…ì„ ì—°ë™ì„ í•˜ê² ë‹¤.\nALB Controller ì„¤ì¹˜ IAM ì •ì±… ìƒì„± ë° ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ì—°ë™í•˜ê² ë‹¤. ë‹¤ìŒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # ALB controller ì •ì±… ì„¤ì¹˜ curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/install/iam_policy.json aws iam create-policy --policy-name AWSLoadBalancerControllerIAMPolicy --policy-document file://iam_policy.json # ì •ì±… arn ìƒì„± í™•ì¸ ACCOUNT_ID={AWS ê³„ì • ë„˜ë²„} aws iam get-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --query \u0026#39;Policy.Arn\u0026#39; --- \u0026#34;arn:aws:iam::955963799952:policy/AWSLoadBalancerControllerIAMPolicy\u0026#34; # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ìƒì„± CLUSTER_NAME={EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„} eksctl create iamserviceaccount --cluster=$CLUSTER_NAME --namespace=kube-system --name=aws-load-balancer-controller \\ --attach-policy-arn=arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --override-existing-serviceaccounts --approve # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ í™•ì¸ kubectl edit sa/aws-load-balancer-controller -n kube-system --- apiVersion: v1 kind: ServiceAccount metadata: annotations: # annoation ì— role-arnì´ ì¶”ê°€ëœ ê²ƒì„ í™•ì¸! eks.amazonaws.com/role-arn: arn:aws:iam::955963799952:role/eksctl-hanhorang-addon-iamserviceaccount-kub-Role1-1MPK8ATNJVXQH creationTimestamp: \u0026#34;2023-05-08T05:32:22Z\u0026#34; labels: app.kubernetes.io/managed-by: eksctl name: aws-load-balancer-controller namespace: kube-system resourceVersion: \u0026#34;1236\u0026#34; uid: 5fe3e69b-8cfc-426c-a16a-509e1f7c4a86 ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ì—°ë™ì´ í™•ì¸ì´ ë˜ì—ˆìœ¼ë©´ ALB ì„ ì„¤ì¹˜í•˜ê² ë‹¤. ì„¤ì¹˜ëŠ” Helmì„ í†µí•´ ì§„í–‰í–ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # ALB ì„¤ì¹˜ helm repo add eks https://aws.github.io/eks-charts helm repo update helm install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system --set clusterName=$CLUSTER_NAME \\ --set serviceAccount.create=false --set serviceAccount.name=aws-load-balancer-controller # ALB íŒŒë“œ í™•ì¸ kubectl get pods -A --- NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-load-balancer-controller-7857849d69-qc9nr 1/1 Running 0 24m kube-system aws-load-balancer-controller-7857849d69-qjvkk 1/1 Running 0 24m # ALB ë¡œê·¸ í™•ì¸ kubectl logs pods/aws-load-balancer-controller-7857849d69-qc9nr -n kube-system --- {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;version\u0026#34;,\u0026#34;GitVersion\u0026#34;:\u0026#34;v2.5.1\u0026#34;,\u0026#34;GitCommit\u0026#34;:\u0026#34;06abaed66e17a411ba064f34e6018b889780ac66\u0026#34;,\u0026#34;BuildDate\u0026#34;:\u0026#34;2023-04-17T22:36:53+0000\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.metrics\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Metrics server is starting to listen\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;:8080\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;setup\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;adding health check for controller\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-v1-pod\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-v1-service\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-elbv2-k8s-aws-v1beta1-ingressclassparams\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-elbv2-k8s-aws-v1beta1-targetgroupbinding\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-elbv2-k8s-aws-v1beta1-targetgroupbinding\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-networking-v1-ingress\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;setup\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;starting podInfo repo\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:47Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook.webhooks\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Starting webhook server\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:47Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Starting server\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;health probe\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;[::]:61779\u0026#34;} ... External DNS ì„¤ì¹˜ External DNS ì„¤ì¹˜ ê³¼ì •ë„ ì• ALB ì„¤ì¹˜ ê³¼ì •ê³¼ ë™ì¼í•˜ë‹¤. IAM OIDC ì—°ë™ì„ ì§„í–‰í•˜ê³ , ë°°í¬ë¥¼ ì§„í–‰í•˜ê² ë‹¤.\në¨¼ì €, ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ OIDC ì •ì±… ì—°ë™ë¶€í„° ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # vi iam_external_policy.json ìƒì„± cat \u0026lt;\u0026lt;EOT \u0026gt; iam_external_policy.json { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ChangeResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:route53:::hostedzone/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53:ListResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } EOT aws iam create-policy --policy-name \u0026#34;AllowExternalDNSUpdates\u0026#34; --policy-document file://iam_external_policy.json.json # ì •ì±… arn ìƒì„± í™•ì¸ aws iam get-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AllowExternalDNSUpdates --query \u0026#39;Policy.Arn\u0026#39; --- \u0026#34;arn:aws:iam::955963799952:policy/AllowExternalDNSUpdates\u0026#34; # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ìƒì„± eksctl create iamserviceaccount --cluster=$CLUSTER_NAME --namespace=kube-system --name=external-dns \\ --attach-policy-arn=arn:aws:iam::$ACCOUNT_ID:policy/AllowExternalDNSUpdates --override-existing-serviceaccounts --approve # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ í™•ì¸ kubectl edit sa/external-dns -n kube-system --- apiVersion: v1 kind: ServiceAccount metadata: annotations: # ë§ˆì°¬ê°€ì§€ë¡œ ì—°ë™ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. eks.amazonaws.com/role-arn: arn:aws:iam::955963799952:role/eksctl-hanhorang-addon-iamserviceaccount-kub-Role1-499RATDKJVJU kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;ServiceAccount\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;external-dns\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;external-dns\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;}} creationTimestamp: \u0026#34;2023-05-08T06:02:38Z\u0026#34; labels: app.kubernetes.io/managed-by: eksctl app.kubernetes.io/name: external-dns name: external-dns namespace: kube-system resourceVersion: \u0026#34;13937\u0026#34; uid: 67ce20cc-6545-486c-b525-450be6311d65 external DNSì„ ì—°ë™í•˜ê¸° ìœ„í•´ì„œëŠ” ë„ë©”ì¸ì´ í•„ìš”í•˜ë‹¤. í•„ìëŠ” Route53 ë„ë©”ì¸ì„ êµ¬ì…í–ˆë‹¤. ë„ë©”ì¸ êµ¬ë§¤ í›„ ë„ë©”ì¸ HOST IDë¥¼ ë³€ìˆ˜ë¡œ ì§€ì •í•˜ì—¬ external DNS ì„¤ì¹˜ì‹œ íŒŒë¼ë¯¸í„°ë¡œ ì‚¬ìš©í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # MyDomain=\u0026lt;ìì‹ ì˜ ë„ë©”ì¸\u0026gt; MyDomain=hanhorang.link # ìì‹ ì˜ Route 53 ë„ë©”ì¸ ID ì¡°íšŒ ë° ë³€ìˆ˜ ì§€ì • MyDnzHostedZoneId=$(aws route53 list-hosted-zones-by-name --dns-name \u0026#34;${MyDomain}.\u0026#34; --query \u0026#34;HostedZones[0].Id\u0026#34; --output text) # ExternalDNS ë°°í¬ curl -s -O https://raw.githubusercontent.com/gasida/PKOS/main/aews/externaldns.yaml cat externaldns.yaml | yh MyDomain=$MyDomain MyDnzHostedZoneId=$MyDnzHostedZoneId envsubst \u0026lt; externaldns.yaml | kubectl apply - # ë¡œê·¸ í™•ì¸ kubectl get pods -A --- kube-system external-dns-6b5bbbf9d-l7ms2 1/1 Running 0 4 kubectl logs pods/external-dns-6b5bbbf9d-l7ms2 -n kube-system --- time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;config: {APIServerURL: KubeConfig: RequestTimeout:30s DefaultTargets:[] ContourLoadBalancerService:heptio-contour/contour GlooNamespace:gloo-system SkipperRouteGroupVersion:zalando.org/v1 Sources:[service ingress] Namespace: AnnotationFilter: LabelFilter: FQDNTemplate: CombineFQDNAndAnnotation:false IgnoreHostnameAnnotation:false IgnoreIngressTLSSpec:false IgnoreIngressRulesSpec:false GatewayNamespace: GatewayLabelFilter: Compatibility: PublishInternal:false PublishHostIP:false AlwaysPublishNotReadyAddresses:false ConnectorSourceServer:localhost:8080 Provider:aws GoogleProject: GoogleBatchChangeSize:1000 GoogleBatchChangeInterval:1s GoogleZoneVisibility: DomainFilter:[hanhorang.link] ExcludeDomains:[] RegexDomainFilter: RegexDomainExclusion: ZoneNameFilter:[] ZoneIDFilter:[] TargetNetFilter:[] ExcludeTargetNets:[] AlibabaCloudConfigFile:/etc/kubernetes/alibaba-cloud.json AlibabaCloudZoneType: AWSZoneType:public AWSZoneTagFilter:[] AWSAssumeRole: AWSAssumeRoleExternalID: AWSBatchChangeSize:1000 AWSBatchChangeInterval:1s AWSEvaluateTargetHealth:true AWSAPIRetries:3 AWSPreferCNAME:false AWSZoneCacheDuration:0s AWSSDServiceCleanup:false AzureConfigFile:/etc/kubernetes/azure.json AzureResourceGroup: AzureSubscriptionID: AzureUserAssignedIdentityClientID: BluecatDNSConfiguration: BluecatConfigFile:/etc/kubernetes/bluecat.json BluecatDNSView: BluecatGatewayHost: BluecatRootZone: BluecatDNSServerName: BluecatDNSDeployType:no-deploy BluecatSkipTLSVerify:false CloudflareProxied:false CloudflareDNSRecordsPerPage:100 CoreDNSPrefix:/skydns/ RcodezeroTXTEncrypt:false AkamaiServiceConsumerDomain: AkamaiClientToken: AkamaiClientSecret: AkamaiAccessToken: AkamaiEdgercPath: AkamaiEdgercSection: InfobloxGridHost: InfobloxWapiPort:443 InfobloxWapiUsername:admin InfobloxWapiPassword: InfobloxWapiVersion:2.3.1 InfobloxSSLVerify:true InfobloxView: InfobloxMaxResults:0 InfobloxFQDNRegEx: InfobloxNameRegEx: InfobloxCreatePTR:false InfobloxCacheDuration:0 DynCustomerName: DynUsername: DynPassword: DynMinTTLSeconds:0 OCIConfigFile:/etc/kubernetes/oci.yaml InMemoryZones:[] OVHEndpoint:ovh-eu OVHApiRateLimit:20 PDNSServer:http://localhost:8081 PDNSAPIKey: PDNSTLSEnabled:false TLSCA: TLSClientCert: TLSClientCertKey: Policy:sync Registry:txt TXTOwnerID:/hostedzone/Z08463751O7YNWD79KKIX TXTPrefix: TXTSuffix: Interval:1m0s MinEventSyncInterval:5s Once:false DryRun:false UpdateEvents:false LogFormat:text MetricsAddress::7979 LogLevel:info TXTCacheInterval:0s TXTWildcardReplacement: ExoscaleEndpoint:https://api.exoscale.ch/dns ExoscaleAPIKey: ExoscaleAPISecret: CRDSourceAPIVersion:externaldns.k8s.io/v1alpha1 CRDSourceKind:DNSEndpoint ServiceTypeFilter:[] CFAPIEndpoint: CFUsername: CFPassword: RFC2136Host: RFC2136Port:0 RFC2136Zone: RFC2136Insecure:false RFC2136GSSTSIG:false RFC2136KerberosRealm: RFC2136KerberosUsername: RFC2136KerberosPassword: RFC2136TSIGKeyName: RFC2136TSIGSecret: RFC2136TSIGSecretAlg: RFC2136TAXFR:false RFC2136MinTTL:0s RFC2136BatchChangeSize:50 NS1Endpoint: NS1IgnoreSSL:false NS1MinTTLSeconds:0 TransIPAccountName: TransIPPrivateKeyFile: DigitalOceanAPIPageSize:50 ManagedDNSRecordTypes:[A CNAME] GoDaddyAPIKey: GoDaddySecretKey: GoDaddyTTL:0 GoDaddyOTE:false OCPRouterName: IBMCloudProxied:false IBMCloudConfigFile:/etc/kubernetes/ibmcloud.json TencentCloudConfigFile:/etc/kubernetes/tencent-cloud.json TencentCloudZoneType: PiholeServer: PiholePassword: PiholeTLSInsecureSkipVerify:false PluralCluster: PluralProvider:}\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Instantiating new Kubernetes client\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Using inCluster-config based on serviceaccount-token\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Created Kubernetes client https://10.100.0.1:443\u0026#34; time=\u0026#34;2023-05-08T06:02:45Z\u0026#34; level=info msg=\u0026#34;Applying provider record filter for domains: [hanhorang.link. .hanhorang.link.]\u0026#34; time=\u0026#34;2023-05-08T06:02:45Z\u0026#34; level=info msg=\u0026#34;All records are already up to date\u0026#34; ì„¤ì¹˜ ì´í›„ ë°˜ë“œì‹œ ë¡œê·¸ë¥¼ í™•ì¸í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. í•„ìì˜ ê²½í—˜ì—ì„œ ë„ë©”ì¸ ì—°ë™ì´ ì˜ëª»ë˜ì—ˆë‹¤ë˜ê°€, IAM ì •ì±… ë¯¸ìŠ¤ë¡œ addon ì—°ë™ì´ ì˜ëª»ë˜ë©´ ë¡œê·¸ë¥¼ í†µí•´ ìƒì„¸ í™•ì¸ì´ ê°€ëŠ¥í•˜ê¸° ë–„ë¬¸ì´ë‹¤.\nEKS VPC ìš´ì˜ EKS Workshop Networking ë¥¼ í† ëŒ€ë¡œ í•„ìê°€ ì‹¤ìŠµí•œ ë‚´ìš©ë“¤ì„ ê³µìœ í•œë‹¤.\nPrefix Delegationì„ í†µí•œ ë…¸ë“œë³„ í• ë‹¹ IP í™•ì¥í•˜ê¸° EKS ë…¸ë“œëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ë¡œ ìš´ì˜ëœë‹¤. ë¬¸ì œëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ë³„ë¡œ í• ë‹¹ë˜ëŠ” IP ê°œìˆ˜ì˜ ì œí•œì´ ì¡´ì¬í•œë‹¤. ì´ìœ ëŠ” ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ë‹¹ í• ë‹¹ê°€ëŠ¥í•œ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì˜ ì œí•œì´ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì¸ìŠ¤í„´ìŠ¤ë³„ IP ê°œìˆ˜ ì œí•œ ê´€ë ¨í•˜ì—¬ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ì„œë„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 3 4 5 kubectl get nodes -o jsonpath=\u0026#34;{range .items[*]}{.metadata.labels[\u0026#39;beta\\.kubernetes\\.io\\/instance-type\u0026#39;]}{\u0026#39;\\t\u0026#39;}{.status.capacity.pods}{\u0026#39;\\n\u0026#39;}{end}\u0026#34; --- t3.medium 17 t3.medium 17 t3.medium 17 ê¸°ì¡´ì—ëŠ” IP í• ë‹¹ ê°œìˆ˜ë¥¼ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ì„ ë³€ê²½í•´ì•¼ í–ˆì§€ë§Œ, Amazon VPC CNI ì¶”ê°€ ê¸°ëŠ¥ ë²„ì „ 1.9.0 ì´ìƒë¶€í„° Prefix Delegation ë¥¼ í†µí•´ ìµœëŒ€ íŒŒë“œ ê°œìˆ˜ê¹Œì§€ IP í• ë‹¹ ê°œìˆ˜ë¥¼ í™•ì¥í•  ìˆ˜ ìˆë‹¤. Prefix Delegation ë€ IPv6 ê¸°ëŠ¥ìœ¼ë¡œ í•˜ìœ„ IPì— ì ‘ë‘ì‚¬ë¥¼ ìœ„ì„í•˜ì—¬ ìµœëŒ€ IPë¥¼ í• ë‹¹í•  ìˆ˜ ìˆê²Œ ë§Œë“¤ì–´ ì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤. ì´ë¥¼ VPC CNIì—ë„ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. IP Modeì™€ Prefix Mode ë¥¼ ë¹„êµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ì´ ë‚˜íƒ€ë‚¼ ìˆ˜ ìˆë‹¤.\nì˜¤ë¥¸ìª½ì´ Prefix Modeë¡œ Secondary ENIì— ì ‘ë‘ì‚¬ê°€ ìœ„ì„ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ë¹„êµí•˜ìë©´ ê°œë³„ ë³´ì¡° IP ì£¼ì†Œë¥¼ í• ë‹¹í•˜ëŠ” ëŒ€ì‹  ì ‘ë‘ì‚¬ë¥¼ í• ë‹¹í•˜ì—¬ ìµœëŒ€ IP ê°œìˆ˜ëŠ˜ ëŠ˜ë¦´ ìˆ˜ ìˆë‹¤. ì¢‹ì€ ê¸°ëŠ¥ì´ì§€ë§Œ ì‚¬ìš©í•˜ê¸°ì— ëª‡ ê°€ì§€ ì œí•œì´ ì¡´ì¬í•œë‹¤. ê¸°ëŠ¥ ë„ì… ì „ ì œí•œ ì‚¬í•­ì„ ê¼­ í™•ì¸í•˜ì!\nVPC CNI version 1.9.0 ì´ìƒ Nitro ê¸°ë°˜ì˜ ì¸ìŠ¤í„´ìŠ¤ì—ì„œë§Œ ê°€ëŠ¥ /28 ì ‘ë‘ì‚¬ë¥¼ ìƒì„±í•  ìˆ˜ ìˆëŠ” ì‚¬ìš© ê°€ëŠ¥í•œ IP ì£¼ì†Œê°€ ì¶©ë¶„í•˜ì§€ ì•Šì€ ê²½ìš° ë°”ë¡œ VPC CNI íŒŒë“œë¥¼ í†µí•´ ì„¤ì •í•´ë³´ê² ë‹¤. ë¨¼ì €, ë²„ì „ í™•ì¸ê³¼ VPC CNIì˜ ì˜µì…˜ì„ ì‚´í´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 # VPC CNI ë²„ì „ í™•ì¸ 1.9.0 ì´ìƒ kubectl describe daemonset aws-node --namespace kube-system | grep Image | cut -d \u0026#34;/\u0026#34; -f 2 --- amazon-k8s-cni-init:v1.12.6-eksbuild.1 amazon-k8s-cni:v1.12.6-eksbuild.1 # Prefix ê´€ë ¨ ì˜µì…˜ í™•ì¸ (ì£¼ì„ ì²˜ë¦¬ íŒŒë¼ë¯¸í„° í™•ì¸) kubectl describe daemonsets.apps aws-node -n kube-system | grep ADDITIONAL_ENI_TAGS: -B1 -A26 Environment: ADDITIONAL_ENI_TAGS: {} ANNOTATE_POD_IP: false AWS_VPC_CNI_NODE_PORT_SUPPORT: true AWS_VPC_ENI_MTU: 9001 AWS_VPC_K8S_CNI_CONFIGURE_RPFILTER: false AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG: false AWS_VPC_K8S_CNI_EXTERNALSNAT: false AWS_VPC_K8S_CNI_LOGLEVEL: DEBUG AWS_VPC_K8S_CNI_LOG_FILE: /host/var/log/aws-routed-eni/ipamd.log AWS_VPC_K8S_CNI_RANDOMIZESNAT: prng AWS_VPC_K8S_CNI_VETHPREFIX: eni AWS_VPC_K8S_PLUGIN_LOG_FILE: /var/log/aws-routed-eni/plugin.log AWS_VPC_K8S_PLUGIN_LOG_LEVEL: DEBUG CLUSTER_ENDPOINT: https://65CBAF476ED2A8986CC4BAFE19F86C44.yl4.ap-northeast-2.eks.amazonaws.com CLUSTER_NAME: hanhorang DISABLE_INTROSPECTION: false DISABLE_METRICS: false DISABLE_NETWORK_RESOURCE_PROVISIONING: false ENABLE_IPv4: true ENABLE_IPv6: false ENABLE_POD_ENI: false ENABLE_PREFIX_DELEGATION: false # PREFIX ê´€ë ¨ ì˜µì…˜ VPC_ID: vpc-0cc614fae36493a12 WARM_ENI_TARGET: 1 # PREFIX ê´€ë ¨ ì˜µì…˜ WARM_PREFIX_TARGET: 1 # PREFIX ê´€ë ¨ ì˜µì…˜ MY_NODE_NAME: (v1:spec.nodeName) MY_POD_NAME: (v1:metadata.name) #MINIMUM_IP_TARGET: # PREFIX ê´€ë ¨ ì˜µì…˜ Prefix ê´€ë ¨ íŒŒë¼ë¯¸í„°ì˜ ì˜µì…˜ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nENABLE_PREFIX_DELEGATION : Prefix Delegation í™œì„±í™” ì—¬ë¶€ WARM_PREFIX_TARGET : í˜„ì¬ ì´ˆê³¼í•˜ì—¬ í• ë‹¹í•  ì ‘ë‘ì‚¬ ìˆ˜ WARM_IP_TARGET, MINIMUM_IP_TARGET : (WARM_PREFIX_TARGETë¥¼ ì„¤ì •í•˜ë©´ ì˜¤ë²„ë¼ì´ë“œ ë¨) í• ë‹¹í•  IP ìˆ˜ì™€ ìµœì†Œ IP ì£¼ì†Œ ìˆ˜ íŒŒë¼ë¯¸í„°ì—ì„œ WARMì´ë¼ëŠ” í‘œí˜„ì´ ë“±ì¥í•˜ëŠ”ë°, CNI ëŠ” WARM Pool(ì›œí’€) ì´ë¼ê³  í•˜ì—¬ ë” ë¹ ë¥¸ íŒŒë“œ ì‹œì‘ì„ ìœ„í•´ IP ë° ì ‘ë‘ì‚¬ë¥¼ ì‚¬ì „ í• ë‹¹í•˜ëŠ” ê¸°ëŠ¥ì´ë‹¤. ì´ ì›œí’€ì„ í†µí•´ì„œ IPì™€ ì ‘ë‘ì‚¬ë¥¼ íŒŒë“œì— í• ë‹¹ë°›ëŠ”ë‹¤.\nhttps://aws.github.io/aws-eks-best-practices/networking/prefix-mode/\në” ë§ì€ íŒŒë“œê°€ ì˜ˆì•½ë˜ë©´ ENIì— í”„ë¦¬í”½ìŠ¤ë¥¼ ìš”ì²­í•˜ê³ , ë§Œì•½ì— ENIê°€ ì‚¬ìš©ëŸ‰ì— ë„ë‹¬í•˜ë©´ ìƒˆ ENIë¥¼ í• ë‹¹í•˜ë ¤ê³  ì‹œë„í•˜ì—¬ ì—°ê²°í•œë‹¤. ìƒˆ ENIëŠ” ìµœëŒ€ ENI ì œí•œì— ë„ë‹¬í•  ë•Œê¹Œì§€ ì—°ê²°ëœë‹¤. ì‚´í´ë³¸ íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì ‘ë‘ì‚¬ ëª¨ë“œë¥¼ í™œì„±í•´ë³´ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 kubectl set env daemonset aws-node -n kube-system ENABLE_PREFIX_DELEGATION=true --- daemonset.apps/aws-node env updated kubectl describe daemonsets.apps aws-node -n kube-system | grep ADDITIONAL_ENI_TAGS: -B1 -A26 --- Environment: ADDITIONAL_ENI_TAGS: {} ANNOTATE_POD_IP: false AWS_VPC_CNI_NODE_PORT_SUPPORT: true AWS_VPC_ENI_MTU: 9001 AWS_VPC_K8S_CNI_CONFIGURE_RPFILTER: false AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG: false AWS_VPC_K8S_CNI_EXTERNALSNAT: false AWS_VPC_K8S_CNI_LOGLEVEL: DEBUG AWS_VPC_K8S_CNI_LOG_FILE: /host/var/log/aws-routed-eni/ipamd.log AWS_VPC_K8S_CNI_RANDOMIZESNAT: prng AWS_VPC_K8S_CNI_VETHPREFIX: eni AWS_VPC_K8S_PLUGIN_LOG_FILE: /var/log/aws-routed-eni/plugin.log AWS_VPC_K8S_PLUGIN_LOG_LEVEL: DEBUG CLUSTER_ENDPOINT: https://65CBAF476ED2A8986CC4BAFE19F86C44.yl4.ap-northeast-2.eks.amazonaws.com CLUSTER_NAME: hanhorang DISABLE_INTROSPECTION: false DISABLE_METRICS: false DISABLE_NETWORK_RESOURCE_PROVISIONING: false ENABLE_IPv4: true ENABLE_IPv6: false ENABLE_POD_ENI: false ENABLE_PREFIX_DELEGATION: true # ë³€ê²½ë˜ì—ˆë‹¤! VPC_ID: vpc-0cc614fae36493a12 WARM_ENI_TARGET: 1 WARM_PREFIX_TARGET: 1 MY_NODE_NAME: (v1:spec.nodeName) MY_POD_NAME: (v1:metadata.name) ì„¤ì •ì´ í™•ì¸ë˜ë©´, í…ŒìŠ¤íŠ¸ìš© íŒŒë“œë¥¼ 150ê°œ ë°°í¬í•´ë³´ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 cat \u0026lt;\u0026lt;EOF | kubectl create -f - apiVersion: apps/v1 kind: Deployment metadata: name: netshoot-pod spec: replicas: 150 selector: matchLabels: app: netshoot-pod template: metadata: labels: app: netshoot-pod spec: containers: - name: netshoot-pod image: nicolaka/netshoot command: [\u0026#34;tail\u0026#34;] args: [\u0026#34;-f\u0026#34;, \u0026#34;/dev/null\u0026#34;] terminationGracePeriodSeconds: 0 EOF # ì´ìƒí•˜ë‹¤ íŒŒë“œê°€ 43ê°œë°–ì— í• ë‹¹ë˜ì§€ ì•Šì•˜ë‹¤. kubectl get deploy --- NAME READY UP-TO-DATE AVAILABLE AGE netshoot-pod 43/150 150 43 19s Pending ëœ íŒŒë“œì˜ ì´ë²¤íŠ¸ë¥¼ í™•ì¸í•˜ë‹ˆ ë…¸ë“œ ì œí•œìœ¼ë¡œ íŒŒë“œ í• ë‹¹ì´ ë˜ì§€ ì•Šì•˜ë‹¤.\n1 2 3 4 Events: Type Reason Age From Message ---- ------ ---- ---- ------- Warning FailedScheduling 88s default-scheduler 0/3 nodes are available: 3 Too many pods. preemption: 0/3 nodes are available: 3 No preemption victims found for incoming pod. í™•ì¸í•´ë³´ë‹ˆ ë…¸ë“œì—ì„œ MaX íŒŒë“œ ìˆ˜ì¹˜ê°€ ì¡´ì¬í•˜ê¸° ë•Œë¬¸ì´ì˜€ë‹¤. ì•ì„œ ë³¸ 17ê°œê°€ í•´ë‹¹ ì¸ìŠ¤í„´ìŠ¤ì˜ ë§¥ìŠ¤ íŒŒë“œ ìˆ˜ì˜€ë‹¤. ì´ MAX íŒŒë“œ ì œí•œì„ ëŠ˜ë¦¬ê¸° ìœ„í•´ì„œëŠ” ì›Œì»¤ ë…¸ë“œì˜ kubeletì˜ ì˜µì…˜ì„ ìˆ˜ì •í•´ì•¼ í•œë‹¤. ë°©ë²•ì€ ë‘ ê°€ì§€ë¡œ 1. EKS êµ¬ì¶•ì‹œ MAX POD ì„¤ì • ë° 2. ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œ kubeletì„ ìˆ˜ì •í•˜ì—¬ MAX PODë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.\nEksctl íŒŒë¼ë¯¸í„°ë¥¼ í†µí•œ MAX POD ì„¤ì • 1 2 3 4 5 6 7 eksctl create nodegroup \\ --cluster hanhorang \\ --region ap-northeast-2 \\ --name ng-1 \\ --node-type t3.medium \\ --managed \\ --max-pods-per-node 100 # í•´ë‹¹ íŒŒë¼ë¯¸í„° ì‹¤í–‰ì¤‘ì¸ ë…¸ë“œ kubelet ìˆ˜ì • ( kimalram ë‹˜ ë¸”ë¡œê·¸ ê¸€ì„ ì°¸ê³ í•˜ì˜€ìŠµë‹ˆë‹¤! ) ì‹¤í–‰ ì¤‘ì¸ ë…¸ë“œì— ì ‘ì†í•˜ì—¬ kubelet ì˜µì…˜ì˜ MAX íŒŒë“œë¥¼ ìˆ˜ì •í•  ê²ƒì´ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 # ë…¸ë“œ IP í™•ì¸ kubectl get nodes -o wide --- ssNAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-192-168-1-209.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h16m v1.24.11-eks-a59e1f0 192.168.1.209 52.78.121.165 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 ip-192-168-2-134.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h17m v1.24.11-eks-a59e1f0 192.168.2.134 3.36.17.42 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 ip-192-168-3-250.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 3h17m v1.24.11-eks-a59e1f0 192.168.3.250 54.180.101.37 Amazon Linux 2 5.10.178-162.673.amzn2.x86_64 containerd://1.6.19 # ë…¸ë“œ ì ‘ì† ssh ec2-user@52.78.121.165 --- The authenticity of host \u0026#39;52.78.121.165 (52.78.121.165)\u0026#39; can\u0026#39;t be established. ECDSA key fingerprint is SHA256:gr23rumKlP2+B0Dn0wYN+UPxaCgoyrL/uyhjBZxPCug. ECDSA key fingerprint is MD5:7c:d8:29:c9:5c:09:66:b6:7c:64:62:e6:85:1d:46:ac. Are you sure you want to continue connecting (yes/no)? yes Warning: Permanently added \u0026#39;52.78.121.165\u0026#39; (ECDSA) to the list of known hosts. Last login: Mon May 1 20:27:30 2023 from 205.251.233.237 __| __|_ ) _| ( / Amazon Linux 2 AMI ___|\\___|___| https://aws.amazon.com/amazon-linux-2/ 3 package(s) needed for security, out of 12 available Run \u0026#34;sudo yum update\u0026#34; to apply all updates. # ë…¸ë“œ eks ì„¤ì • ë¶€ë¶„ ê²½ë¡œ ì ‘ì† cd /etc/eks # kubelet ì¬ì‹¤í–‰ sudo /etc/eks/bootstrap.sh hanhorang --use-max-pods false --kubelet-extra-args \u0026#39;--max-pods=110\u0026#39; --- 2023-05-09T11:31:57+0000 [eks-bootstrap] INFO: starting... 2023-05-09T11:31:57+0000 [eks-bootstrap] INFO: --use-max-pods=\u0026#39;false\u0026#39; 2023-05-09T11:31:57+0000 [eks-bootstrap] INFO: --kubelet-extra-args=\u0026#39;--max-pods=110\u0026#39; 2023-05-09T11:31:57+0000 [eks-bootstrap] INFO: Using kubelet version 1.24.11 2023-05-09T11:31:57+0000 [eks-bootstrap] INFO: Using containerd as the container runtime 2023-05-09T11:31:58+0000 [eks-bootstrap] INFO: --cluster-ca or --api-server-endpoint is not defined, describing cluster... 2023-05-09T11:31:59+0000 [eks-bootstrap] INFO: Using IP family: ipv4 [Service] Slice=runtime.slice â€˜/etc/eks/containerd/kubelet-containerd.serviceâ€™ -\u0026gt; â€˜/etc/systemd/system/kubelet.serviceâ€™ 2023-05-09T11:32:01+0000 [eks-bootstrap] INFO: complete! # kubelet ë¡œê·¸ í™•ì¸ ( ìˆ˜ì •ì´ ì•ˆë¨) sudo ps -ef | grep kubelet -- root 2860 1 1 08:11 ? 00:02:29 /usr/bin/kubelet --config /etc/kubernetes/kubelet/kubelet-config.json --kubeconfig /var/lib/kubelet/kubeconfig --container-runtime-endpoint unix:///run/containerd/containerd.sock --image-credential-provider-config /etc/eks/image-credential-provider/config.json --image-credential-provider-bin-dir /etc/eks/image-credential-provider --node-ip=192.168.1.209 --pod-infra-container-image=602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/pause:3.5 --v=2 --cloud-provider=aws --container-runtime=remote --node-labels=eks.amazonaws.com/sourceLaunchTemplateVersion=1,alpha.eksctl.io/cluster-name=hanhorang,alpha.eksctl.io/nodegroup-name=ng1,eks.amazonaws.com/nodegroup-image=ami-0da378ed846e950a4,eks.amazonaws.com/capacityType=ON_DEMAND,eks.amazonaws.com/nodegroup=ng1,eks.amazonaws.com/sourceLaunchTemplateId=lt-0a84643ab8f551110 --max-pods=17 ec2-user 6100 4064 0 11:34 pts/0 00:00:00 grep --color=auto kubelet # kubelet ì¬ì‹œì‘ sudo systemctl restart kubelet kubelet ì€ Static íŒŒë“œë¡œ ë™ì‘í•˜ë¯€ë¡œ ìˆ˜ë™ìœ¼ë¡œ ì¬ì‹œì‘ì„ í•´ì¤˜ì•¼ ê¸°ëŠ¥ì´ ì ìš©ëœë‹¤. ë§¥ìŠ¤ íŒŒë“œê°€ ì ìš©ë˜ì—ˆìœ¼ë©´ ì „ì— ë°°í¬í•œ 150ê°œ íŒŒë“œ ë™ì‘ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 3 4 kubectl get deploy --- NAME READY UP-TO-DATE AVAILABLE AGE netshoot-pod 150/150 150 150 38m CUSTOM Networkë¥¼ í†µí•œ IP í™•ì¥í•˜ê¸° ì„œë¸Œë„· ëŒ€ì—­ì— IPê°€ ë¶€ì¡±í–ˆì„ ë•Œ ì¶”ê°€ ì„œë¸Œë„· CIDRì„ ë¶€ì—¬í•˜ì—¬ IP í• ë‹¹ ê°œìˆ˜ë¥¼ ì¶”ê°€ë¡œ í™•ì¥í•  ìˆ˜ ìˆë‹¤.\nê³µì‹ ë¬¸ì„œì— ë”°ë¥´ë©´ Custom CIDR ì œì•½ ì‚¬í•­ë„ ì¡´ì¬í•œë‹¤. ì ìš©ì‹œ ë°˜ë“œì‹œ ì°¸ê³ í•˜ì\nì‚¬ìš©ì ì§€ì • ë„¤íŠ¸ì›Œí‚¹ì„ ì‚¬ìš© ì„¤ì •í•˜ë©´ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì— í• ë‹¹ëœ IP ì£¼ì†Œê°€ podsì— í• ë‹¹ë˜ì§€ ì•ŠëŠ”ë‹¤. ë³´ì¡° ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì˜ IP ì£¼ì†Œë§ŒÂ podsì— í• ë‹¹ëœë‹¤. í´ëŸ¬ìŠ¤í„°ì—ì„œÂ IPv6Â íŒ¨ë°€ë¦¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì‚¬ìš©ì ì§€ì • ë„¤íŠ¸ì›Œí‚¹ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ì‚¬ìš©ì ì§€ì • ë„¤íŠ¸ì›Œí‚¹ì„ ì‚¬ìš©í•˜ì—¬Â IPv4Â ì£¼ì†Œ ì†Œëª¨ë¥¼ ì™„í™”í•˜ë ¤ëŠ” ê²½ìš° ëŒ€ì‹ Â IPv6Â íŒ¨ë°€ë¦¬ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•  ìˆ˜ ìˆë‹¤. ê·¸ëŸ¬ë©´ ì„œë¸Œë„· CIDR ì„ ì¶”ê°€í•˜ê² ë‹¤. ì¶”ê°€ ê³¼ì •ì€ ë‹¤ìŒì˜ 4ê°€ì§€ë¡œ ì§„í–‰ëœë‹¤.\nVPC ì„œë¸Œë„· ìƒì„± aws-node íŒŒë“œ íŒŒë¼ë¯¸í„° ìˆ˜ì •(VPC CNI) ENIConfig (CRD) ë°°í¬ ìƒì„± ë° EKS ë…¸ë“œì— ì—°ê²° ë…¸ë“œ ê·¸ë£¹ ì¬ë°°í¬ VPC í• ë‹¹ ë° ì„œë¸Œë„· ìƒì„±ì€ AWS ì½˜ì†”ì—ì„œ ì§„í–‰í•˜ì˜€ë‹¤. AWS ì½˜ì†” [VPC] ì—ì„œ CIDR ë° ì„œë¸Œë„· ì¡°ì‘ì´ ê°€ëŠ¥í•˜ë‹¤. ë‹¤ìŒê³¼ ê°™ì´ 10.64.0.0/16 ì˜ VPC CIDR ê³¼ ëŒ€ì—­ì— ë§ëŠ” ì„œë¸Œë„·ì„ ìƒì„±í•˜ì˜€ë‹¤.\nìƒì„±í•œ ì„œë¸Œë„· IDëŠ” ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¡œ ì¡°íšŒê°€ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 #aws ec2 describe-subnets --filters \u0026#34;Name=vpc-id,Values=$vpc_id\u0026#34; --query \u0026#39;Subnets[*].{SubnetId: SubnetId, AvailabilityZone: AvailabilityZone, CidrBlock: CidrBlock}\u0026#39; --output table aws ec2 describe-subnets --filters \u0026#34;Name=vpc-id,Values=vpc-0fc5c162640e67e66\u0026#34; --query \u0026#39;Subnets[*].{SubnetId: SubnetId, AvailabilityZone: AvailabilityZone, CidrBlock: CidrBlock}\u0026#39; --output table --------------------------------------------------------------------- | DescribeSubnets | +------------------+-------------------+----------------------------+ | AvailabilityZone | CidrBlock | SubnetId | +------------------+-------------------+----------------------------+ | ap-northeast-2a | 100.64.1.0/24 | subnet-06daaaa9fa3990545 | | ap-northeast-2c | 192.168.3.0/24 | subnet-0020334582f221a4e | | ap-northeast-2b | 100.64.2.0/24 | subnet-0a498cbb63e30d085 | | ap-northeast-2c | 100.64.3.0/24 | subnet-03de86c554113fec7 | | ap-northeast-2b | 192.168.2.0/24 | subnet-0808f8970f303632f | | ap-northeast-2a | 192.168.11.0/24 | subnet-0bc63c89a9965b672 | | ap-northeast-2c | 192.168.13.0/24 | subnet-0f229c12c2c595c5b | | ap-northeast-2b | 192.168.12.0/24 | subnet-06229a20d32b499de | | ap-northeast-2a | 192.168.1.0/24 | subnet-0de74f64866c7a8e5 | +------------------+-------------------+----------------------------+ ì´ì–´ì„œ VPC CNI íŒŒë“œ(aws-node)ì— custom network ë¥¼ ì‚¬ìš©í•˜ê² ë‹¤ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ì.\n1 2 3 4 5 kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG=true kubectl describe daemonsets.apps aws-node -n kube-system | grep CUSTOM ---- AWS_VPC_K8S_CNI_CUSTOM_NETWORK_CFG: true # ì„¤ì • í™•ì¸ ì¶”ê°€ ì‘ì—…ìœ¼ë¡œ ì„œë¸Œë„· ë°°í¬ ì„¤ì •ì— ëŒ€í•œ eniconfig íŒŒì¼ì„ ì‘ì„±í•˜ì—¬ ë°°í¬í•˜ë„ë¡ í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # eniconfigs.yaml apiVersion: crd.k8s.amazonaws.com/v1alpha1 kind: ENIConfig metadata: name: ap-noratheast-2a spec: securityGroups: - sg-0db212244a3e72ae1 subnet: subnet-06daaaa9fa3990545 --- apiVersion: crd.k8s.amazonaws.com/v1alpha1 kind: ENIConfig metadata: name: ap-noratheast-2b spec: securityGroups: - sg-0db212244a3e72ae1 subnet: subnet-0a498cbb63e30d085 --- apiVersion: crd.k8s.amazonaws.com/v1alpha1 kind: ENIConfig metadata: name: ap-noratheast-2c spec: securityGroups: - sg-0db212244a3e72ae1 subnet: subnet-03de86c554113fec7 ì¶”ê°€í•  ì„œë¸Œë„·ë§Œ ì‘ì„±í•˜ë„ë¡ í•˜ì. ë°‘ì˜ ë…¸ë“œì— annotationì„ ì¶”ê°€í•  ê²ƒì´ê¸° ë•Œë¬¸ì— AND ë¡œ ì„œë¸Œë„·ì´ ì¶”ê°€ëœë‹¤.\në³´ì•ˆ ê·¸ë£¹ì€ ë°°í¬ëœ ì›Œí¬ ë…¸ë“œì˜ ë³´ì•ˆ ê·¸ë£¹ìœ¼ë¡œ ì‘ì„±í•˜ì˜€ë‹¤.\nmetadata.name ì— ë˜ë„ë¡ AZ ì´ë¦„ì„ ì…ë ¥í•˜ë„ë¡ í•˜ì, AZ ì´ë¦„ì´ ì•„ë‹ˆë©´ ë…¸ë“œì— ì ìš©ì‹œí‚¤ê¸° ìœ„í•´ì„œëŠ” ì•„ë˜ì™€ ê°™ì´ ì¶”ê°€ ì£¼ì„ì´ í•„ìš”í•˜ë‹¤.\n1 2 3 kubectl annotate node ip-192-168-1-84.ap-northeast-2.compute.internal k8s.amazonaws.com/eniConfig=ap-noratheast-2a-custom kubectl annotate node ip-192-168-2-219.ap-northeast-2.compute.internal k8s.amazonaws.com/eniConfig=ap-noratheast-2b-custom kubectl annotate node ip-192-168-3-140.ap-northeast-2.compute.internal k8s.amazonaws.com/eniConfig=ap-noratheast-2c-custom ë°°í¬ ë° ë…¸ë“œì— ì—°ê²°í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 kubectl apply -f eniconfigs.yaml --- eniconfig.crd.k8s.amazonaws.com/ap-northeast-2a created eniconfig.crd.k8s.amazonaws.com/ap-northeast-2b created eniconfig.crd.k8s.amazonaws.com/ap-northeast-2c created kubectl get eniconfig --- NAME AGE ap-northeast-2a 16s ap-northeast-2b 16s ap-northeast-2c 16s # VPC ì„œë¸Œë„· ì—…ë°ì´íŠ¸ kubectl set env daemonset aws-node -n kube-system ENI_CONFIG_LABEL_DEF=topology.kubernetes.io/zone ì—…ë°ì´íŠ¸ëœ ë‚´ìš©ì´ ë…¸ë“œì—ëŠ” ë°”ë¡œ ì ìš©ë˜ì§€ ì•ŠëŠ”ë‹¤. ìƒˆë¡œ ì¶”ê°€ëœ ë…¸ë“œì—ë§Œ ì ìš©ëœë‹¤. ìƒˆë¡œ ë…¸ë“œ ê·¸ë£¹ì„ ì¶”ê°€í•˜ê³  í™•ì¸í•˜ë„ë¡ í•˜ì.\n1 2 3 4 5 6 eksctl create nodegroup \\ --cluster hanhorang \\ --region ap-northeast-2 \\ --name ng-2 \\ --node-type t3.medium \\ --managed AWS ì½˜ì†”ì„ í†µí•´ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nSG for Pod ì„¤ì • VPC ë³´ì•ˆ ê·¸ë£¹ì„ íŒŒë“œì—ë„ ì„¤ì •í•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ë‹¤. íŒŒë“œì— ë³´ì•ˆ ê·¸ë£¹ì„ ì ìš©í•˜ë©´ íŒŒë“œ ì ‘ê·¼ì— ì„¸ë¶€ì ì¸ ë³´ì•ˆ ê´€ë¦¬ê°€ ê°€ëŠ¥í•´ì§„ë‹¤.\nhttps://www.eksworkshop.com/docs/networking/security-groups-for-pods/\nSG for Podë¥¼ ì„¤ì •í•˜ê¸° ì „ ëª‡ê°€ì§€ ì œí•œ ì‚¬í•­ì´ ì¡´ì¬í•œë‹¤.\nìœˆë„ìš° ë…¸ë“œì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.\nì¸ìŠ¤í„´ìŠ¤ ìœ í˜• ì¤‘ t íƒ€ì…ì˜ ì¸ìŠ¤í„´ìŠ¤ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤.\nIPv6 íŒ¨ë°€ë¦¬ìš©ìœ¼ë¡œ êµ¬ì„±ëœ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ fargateì—ì„œëŠ” ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤.\nì •ì±… ì œí•œì´ ìˆì„ì‹œ ì‚¬ìš©ìì— SG for Podë¥¼ ìœ„í•œ ì„¹ì…˜ì„ ì¶”ê°€ í•´ì•¼ í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 ... subjects: - kind: Group apiGroup: rbac.authorization.k8s.io name: system:authenticated - apiGroup: rbac.authorization.k8s.io kind: User name: eks:vpc-resource-controller - kind: ServiceAccount name: eks-vpc-resource-controller VPC CNI ë²„ì „ì´ 1.7.7 ì´ìƒì´ì—¬ì•¼ í•œë‹¤.\nì´ì™¸ì—ë„ VPC CNI ë²„ì „ ë³„ í”Œë˜ê·¸ ë§ˆë‹¤ ì œí•œì‚¬í•­ì´ ì¡´ì¬í•œë‹¤. ì„¸ë¶€ ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì.\nê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ SG for Pod ì„¤ì •ì„ ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 # ë²„ì „ í™•ì¸ kubectl describe daemonset aws-node --namespace kube-system | grep amazon-k8s-cni: | cut -d : -f 3 --- v1.12.6-eksbuild.1 # EKS VPC ResourceController Role ì¶”ê°€ cluster_role=$(aws eks describe-cluster --name hanhorang --query cluster.roleArn --output text | cut -d / -f 2) # í´ëŸ¬ìŠ¤í„°ì— ì •ì±… ì—°ê²° aws iam attach-role-policy --policy-arn arn:aws:iam::aws:policy/AmazonEKSVPCResourceController --role-name $cluster_role # VPC CNI íŒŒë¼ë¯¸í„° ìˆ˜ì •(Pod eni ê´€ë¦¬ íŒŒë¼ë¯¸í„° í—ˆìš©) kubectl set env daemonset aws-node -n kube-system ENABLE_POD_ENI=true # íŒŒë“œ eni ê°€ëŠ¥ ë…¸ë“œ í™•ì¸ # ìœ„ ëª…ë ¹ì–´ë¡œ ì—…ë°ì´íŠ¸ì— ëª‡ ì´ˆì˜ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤. kubectl get nodes -o wide -l vpc.amazonaws.com/has-trunk-attached=true --- NAME STATUS ROLES AGE VERSION INTERNAL-IP EXTERNAL-IP OS-IMAGE KERNEL-VERSION CONTAINER-RUNTIME ip-192-168-1-108.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 20m v1.24.11-eks-a59e1f0 192.168.1.108 3.38.214.241 Amazon Linux 2 5.10.178-162.673.amzn2.aarch64 containerd://1.6.19 ip-192-168-2-45.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 20m v1.24.11-eks-a59e1f0 192.168.2.45 3.38.188.199 Amazon Linux 2 5.10.178-162.673.amzn2.aarch64 containerd://1.6.19 ip-192-168-3-18.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 20m v1.24.11-eks-a59e1f0 192.168.3.18 13.125.254.20 Amazon Linux 2 5.10.178-162.673.amzn2.aarch64 containerd://1.6.19 # íŒŒë“œì—ì„œ VPC ì™¸ë¶€ ì£¼ì†Œë¡œ ì•„ì›ƒë°”ìš´ë“œë˜ëŠ” íŠ¸ë˜í”½ì€ ê¸°ë³¸ ENIë¡œ ê°€ë©°, ë…¸ë“œ ë³´ì•ˆ ê·¸ë£¹ì— ëŒ€í•œ ê·œì¹™ì´ ì ìš©ëœë‹¤, íŒŒë“œì˜ enië§Œ ì ìš©ì‹œí‚¤ê³  ì‹¶ë‹¤ë©´ ì•„ë˜ íŒŒë¼ë¯¸í„°ë¥¼ ì¶”ê°€í•˜ì. kubectl set env daemonset aws-node -n kube-system AWS_VPC_K8S_CNI_EXTERNALSNAT=true # ì˜µì…˜ 1. liveness \u0026amp; readyprobe ì‚¬ìš© ê²½ìš°, kubeletì´ TCPë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒë“œ eni ì™€ ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ TCP ì´ˆê¸° demux ì¤‘ì§€ kubectl patch daemonset aws-node -n kube-system \\ -p \u0026#39;{\u0026#34;spec\u0026#34;: {\u0026#34;template\u0026#34;: {\u0026#34;spec\u0026#34;: {\u0026#34;initContainers\u0026#34;: [{\u0026#34;env\u0026#34;:[{\u0026#34;name\u0026#34;:\u0026#34;DISABLE_TCP_EARLY_DEMUX\u0026#34;,\u0026#34;value\u0026#34;:\u0026#34;true\u0026#34;}],\u0026#34;name\u0026#34;:\u0026#34;aws-vpc-cni-init\u0026#34;}]}}}}\u0026#39; # ì˜µì…˜ 2. externalTrafficPolicy: local, NodeLocal DNSCache, ìì²´ ë³´ì•ˆ ê·¸ë£¹ì´ ìˆëŠ” ë„¤íŠ¸ì›Œí¬ ì •ì±…ì´ ìˆëŠ” ê²½ìš° ì•„ë˜ ëª…ë ¹ì–´ ì¶”ê°€ # í•´ë‹¹ ì„¤ì •ì„ ê¸°ì¡´ Podsì— ì ìš©í•˜ë ¤ë©´, ë…¸ë“œë¥¼ ì¬ì‹œì‘í•´ì•¼í•¨ kubectl set env daemonset aws-node -n kube-system POD_SECURITY_GROUP_ENFORCING_MODE=standard SG for Pod ì„¤ì • ì´í›„ íŒŒë“œì— ì§ì ‘ ë³´ì•ˆ ê·¸ë£¹ì„ ì„¤ì •í•˜ë„ë¡ í•˜ê² ë‹¤. í™œìš© ì˜ˆì œëŠ” EKS Workshop ì„ ì°¸ê³ í•˜ì˜€ë‹¤.\nhttps://www.eksworkshop.com/docs/introduction/getting-started/about\nComponent Description UI í”„ë¡ íŠ¸ì—”ë“œë¡œ ì‚¬ìš©ì ì¸í„°í˜ì´ìŠ¤ë¥¼ ì œê³µí•˜ë©° ë‹¤ë¥¸ ì„œë¹„ìŠ¤ì— ëŒ€í•œ APIì„ ì—°ê²°í•œë‹¤. Catalog ìƒí’ˆ ëª©ë¡ê³¼ ìƒì„¸ ì •ë³´ì— ëŒ€í•œ API Cart ê³ ê° ì‡¼í•‘ì¹´íŠ¸ì— ëŒ€í•œ API Checkout ì²´í¬ì•„ì›ƒ í”„ë¡œì„¸ìŠ¤ë¥¼ ì¡°ì •í•˜ëŠ” API Orders ê³ ê° ì£¼ë¬¸ì„ ë°›ê³  ì²˜ë¦¬í•˜ëŠ” API Static assets ìƒí’ˆ ì¹´íƒˆë¡œê·¸ì™€ ê´€ë ¨ëœ ì´ë¯¸ì§€ì™€ ê°™ì€ ì •ì  íŒŒì¼ í™œìš© ì˜ˆì œëŠ” ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ì˜ ì›¹ ìŠ¤í† ì–´ ì–´í”Œë¦¬ì¼€ì´ì…˜ìœ¼ë¡œ ì•„ë˜ Catalogì˜ DBë¥¼ RDSë¡œ ë³€ê²½í•˜ê³  Catalog Podì— ë³´ì•ˆ ê·¸ë£¹ì„ ì ìš©í•˜ì—¬ RDS ì ‘ê·¼ ê¶Œí•œì„ ë¶€ì—¬í•œë‹¤. ì´ë ‡ê²Œ í•˜ë©´ Catalogì—ì„œë§Œ RDSì— ì ‘ê·¼ì´ ê°€ëŠ¥í•´ì§„ë‹¤.\níŒŒì¼ ë°°í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 git clone https://github.com/aws-samples/eks-workshop-v2.git cd eks-workshop-v2/environment/workspace/manifests # public ecr ë¡œê·¸ì¸ aws ecr-public get-login-password --region us-east-1 | docker login --username AWS --password-stdin public.ecr.aws kubectl apply -k . ğŸ§Â ë°°í¬ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\nEKS ë…¸ë“œì—ì„œ ì´ë¯¸ì§€ pull ì´ ì•ˆë˜ì–´ íŒŒë“œ ì‹¤í–‰ì´ ì•ˆë˜ëŠ” ë¬¸ì œê°€ ë°œìƒí–ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 kubectl describe pods/catalog-mysql-0 -n catalog --- ... Events: Type Reason Age From Message ---- ------ ---- ---- ------- Normal Scheduled 10m default-scheduler Successfully assigned catalog/catalog-mysql-0 to ip-192-168-2-197.ap-northeast-2.compute.internal Normal Pulling 9m19s (x4 over 10m) kubelet Pulling image \u0026#34;public.ecr.aws/docker/library/mysql:5.7\u0026#34; Warning Failed 9m18s (x4 over 10m) kubelet Failed to pull image \u0026#34;public.ecr.aws/docker/library/mysql:5.7\u0026#34;: rpc error: code = NotFound desc = failed to pull and unpack image \u0026#34;public.ecr.aws/docker/library/mysql:5.7\u0026#34;: no match for platform in manifest: not found Warning Failed 9m18s (x4 over 10m) kubelet Error: ErrImagePull Warning Failed 9m5s (x6 over 10m) kubelet Error: ImagePullBackOff Normal BackOff 56s (x42 over 10m) kubelet Back-off pulling image \u0026#34;public.ecr.aws/docker/library/mysql:5.7\u0026#34; ì´ìƒí•œ ì ì€ ë² ìŠ¤ì²œ ì„œë²„ì—ì„œëŠ” ì´ë¯¸ì§€ í’€ì´ ë˜ëŠ” ë°˜ë©´, EKS ë…¸ë“œì—ì„œëŠ” ì´ë¯¸ì§€ í’€ì— ëŒ€í•´ not foundê°€ ë°œìƒí•œë‹¤.\ní™•ì¸í•´ë³´ë‹ˆ í•´ë‹¹ ì´ë¯¸ì§€ì˜ ê²½ìš°(ECR) ì—ì„œ linux/arm64/v8 ì— ëŒ€í•œ ì´ë¯¸ì§€ ë ˆì´ì–´ ëŒ€í•œ ì •ë³´ê°€ ì—†ì–´ì„œ ë°œìƒí•œ ë¬¸ì œì˜€ë‹¤. linux/arm64/v8 ë ˆì´ì–´ëŠ” AWS ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• (A1, M6g,C6g,R6g)ì—ì„œ ì‚¬ìš©ë˜ëŠ” ë°˜ë©´ linux/amd64 ëŠ” (x86-64) ì•„í‚¤í…ì²˜ë¡œ AWS ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•(t2,t3 m4, m5) ê¸°ë°˜ì˜ í”„ë¡œì„¸ì„œì—ì„œ ë™ì‘í•œë‹¤.\ní•´ê²° ë°©ë²•ìœ¼ë¡œ ì´ë¯¸ì§€ë¥¼ ì§ì ‘ ë¹Œë“œ ë° Push í•  ìˆ˜ ìˆì§€ë§Œ, ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì„ m5.large ë¡œ ë³€ê²½í–ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 kubectl get pods -A --- NAMESPACE NAME READY STATUS RESTARTS AGE assets assets-97576f445-fbf8m 1/1 Running 0 2m5s carts carts-75d5cc858f-xh474 1/1 Running 0 2m5s carts carts-dynamodb-69b57dddc9-5qcmb 1/1 Running 0 2m5s catalog catalog-6d688b9f9c-9f8sg 1/1 Running 2 (103s ago) 2m5s catalog catalog-mysql-0 1/1 Running 0 2m4s checkout checkout-79d67d6765-r442r 1/1 Running 0 2m5s checkout checkout-redis-cb98f6ff7-qmsk5 1/1 Running 0 2m5s kube-system aws-node-h8rnr 1/1 Running 0 7m15s kube-system aws-node-k7nzq 1/1 Running 0 7m47s kube-system aws-node-mbc76 1/1 Running 0 7m31s kube-system coredns-dc4979556-hfztx 1/1 Running 0 14m kube-system coredns-dc4979556-s8qj7 1/1 Running 0 14m kube-system kube-proxy-h2r6m 1/1 Running 0 9m8s kube-system kube-proxy-jjjmx 1/1 Running 0 9m8s kube-system kube-proxy-np7fj 1/1 Running 0 9m8s orders orders-7fcc4fb7d8-kvb2b 1/1 Running 1 (91s ago) 2m5s orders orders-mysql-5d99464c58-mp6xm 1/1 Running 0 2m5s rabbitmq rabbitmq-0 1/1 Running 0 2m4s ui ui-5b9cf4db94-54v8g 1/1 Running 0 2m4s ì´ì–´ì„œ Catalog ì˜ DBë¥¼ mysqlì—ì„œ AWS RDS ë¡œ ë³€ê²½í•˜ê¸° ìœ„í•œ ì‘ì—…ì„ ì§„í–‰í•˜ê² ë‹¤. ì´ë¥¼ ìœ„í•´ ë³´ì•ˆ ê·¸ë£¹ ìƒì„± ë° RDS ìƒì„±ì„ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ì.\në³´ì•ˆ ê·¸ë£¹ ìƒì„±(VPCëŠ” EKS VPCë¡œ ì„¤ì •)\nRDS ìƒì„± ê³¼ì • ì¤‘ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •ì„ ì•ì„œ ìƒì„±í•œ ë³´ì•ˆ ê·¸ë£¹ìœ¼ë¡œ ë§Œë“¤ê³ , VPCë¥¼ EKS ê°€ ë°°í¬ëœ VPCë¡œ ì„¤ì •í•˜ì. ì¶”ê°€ë¡œ í•„ìëŠ” ë¹„ìš© ë¬¸ì œë¡œ í”„ë¦¬í‹°ì–´ë¡œ ì„¤ì •í–ˆê³  ë¹„ë°€ë²ˆí˜¸ë¥¼ 12341234 ë¡œ ì„¤ì •í–ˆë‹¤.\nìƒì„±í•œ DB ì¸ìŠ¤í„´ìŠ¤ì˜ ì—”ë“œí¬ì¸íŠ¸ë¥¼ í™˜ê²½ ë³€ìˆ˜ë¡œ ì…ë ¥í•˜ì—¬ catalogë¥¼ ì¬ë°°í¬ í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 export CATALOG_RDS_PASSWORD=12341234 export CATALOG_RDS_ENDPOINT=catalog-db2.cnrosybtsnww.ap-northeast-2.rds.amazonaws.com:3306 kubectl apply -k /workspace/modules/networking/securitygroups-for-pods/rds -- # ìƒì„± ì´í›„ DB endpoint í™•ì¸ kubectl get -n catalog cm catalog -o yaml --- apiVersion: v1 data: DB_ENDPOINT: database-2.cnrosybtsnww.ap-northeast-2.rds.amazonaws.com:3306 DB_NAME: catalog DB_READ_ENDPOINT: database-2.cnrosybtsnww.ap-northeast-2.rds.amazonaws.com:3306 kind: ConfigMap metadata: annotations: kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;data\u0026#34;:{\u0026#34;DB_ENDPOINT\u0026#34;:\u0026#34;database-2.cnrosybtsnww.ap-northeast-2.rds.amazonaws.com:3306\u0026#34;,\u0026#34;DB_NAME\u0026#34;:\u0026#34;catalog\u0026#34;,\u0026#34;DB_READ_ENDPOINT\u0026#34;:\u0026#34;database-2.cnrosybtsnww.ap-northeast-2.rds.amazonaws.com:3306\u0026#34;},\u0026#34;kind\u0026#34;:\u0026#34;ConfigMap\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;name\u0026#34;:\u0026#34;catalog\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;catalog\u0026#34;}} creationTimestamp: \u0026#34;2023-05-10T19:48:42Z\u0026#34; name: catalog namespace: catalog resourceVersion: \u0026#34;6645\u0026#34; # ê¸°ì¡´ catalog íŒŒë“œ ì‚­ì œ kubectl delete pod -n catalog -l app.kubernetes.io/component=service # catalog ë¡œê·¸ í™•ì¸ kubectl -n catalog logs deployment/catalog --- 2023/05/10 20:13:25 Running database migration... 2023/05/10 20:13:30 Error: Failed to prep migration dial tcp 192.168.12.123:3306: i/o timeout 2023/05/10 20:13:30 Error: Failed to run migration dial tcp 192.168.12.123:3306: i/o timeout 2023/05/10 20:13:30 dial tcp 192.168.12.123:3306: i/o timeout ê²°ê³¼ ì²˜ëŸ¼ i/o timeout ì´ ë°œìƒí•˜ëŠ”ë° ë³´ì•ˆ ê·¸ë£¹ì„ ì„¤ì •í•˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤.\në³´ì•ˆ ì •ì±… ìƒì„±ì„ í†µí•´ ì•ì„œ ìƒì„±í•œ ë³´ì•ˆ ê·¸ë£¹(pods-connect-rds)ì„ catalog íŒŒë“œì— ì ìš©ì‹œí‚¤ì.\n1 2 3 4 5 6 7 8 9 10 11 12 apiVersion: vpcresources.k8s.aws/v1beta1 kind: SecurityGroupPolicy metadata: name: catalog-rds-access namespace: catalog spec: podSelector: matchLabels: app.kubernetes.io/component: mysql securityGroups: groupIds: - sg-07739bd847069f56e # catalog-sg ë³´ì•ˆ ê·¸ë£¹ ì ìš© í›„ íŒŒë“œë¥¼ ì¬ë°°í¬í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 export CATALOG_SG_ID=sg-08bb6f8b77a20e693 kubectl apply -k . --- WARNING: This Kustomization is relying on a bug that loads values from the environment when they are omitted from an env file. This behaviour will be removed in the next major release of Kustomize. WARNING: This Kustomization is relying on a bug that loads values from the environment when they are omitted from an env file. This behaviour will be removed in the next major release of Kustomize. WARNING: This Kustomization is relying on a bug that loads values from the environment when they are omitted from an env file. This behaviour will be removed in the next major release of Kustomize. namespace/catalog unchanged serviceaccount/catalog unchanged configmap/catalog unchanged configmap/catalog-env-7gtc4hbmd2 unchanged configmap/catalog-sg-env-5969b7c958 created secret/catalog-db unchanged service/catalog unchanged service/catalog-mysql unchanged service/ui-nlb unchanged deployment.apps/catalog unchanged statefulset.apps/catalog-mysql unchanged securitygrouppolicy.vpcresources.k8s.aws/catalog-rds-access created # ê¸°ì¡´ catalog íŒŒë“œ ì‚­ì œ kubectl delete pod -n catalog -l app.kubernetes.io/component=service # ë³´ì•ˆ ê·¸ë£¹ ë³€ê²½ í™•ì¸ kubectl get events -n catalog | grep SecurityGroupRequested -- 5m22s Normal SecurityGroupRequested pod/catalog-6d688b9f9c-gjhvt Pod will get the following Security Groups [sg-08bb6f8b77a20e693] 20s Normal SecurityGroupRequested pod/catalog-6d688b9f9c-vnlgb Pod will get the following Security Groups [sg-08bb6f8b77a20e693] 10s Normal SecurityGroupRequested pod/catalog-mysql-0 Pod will get the following Security Groups [sg-08bb6f8b77a20e693] ì´í›„ íŒŒë“œì— ì ‘ì†í•˜ì—¬ rdsì— ì ‘ì†í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì ‘ê·¼ì´ ëœë‹¤.(ë°‘ ì‚¬ì§„ì˜ ë¹¨ê°„ë„¤ëª¨) ë°˜ë©´ì— ë…¸ë“œì—ì„œ rds ì ‘ê·¼ ì‹œë„ì‹œ timeoutì´ ë°œìƒí•œë‹¤. (ë°‘ ì‚¬ì§„ì˜ íŒŒë€ë„¤ëª¨)\nì›Œí¬ìƒµì— ìˆëŠ” ë‚´ìš©ì„ ë”°ë¼í–ˆì§€ë§Œ, catalog íŒŒë“œì—ì„œ ì—°ê²°ì´ ì•ˆë˜ì–´ catalog-mysal ì—ì„œ RDS ì—°ê²° í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. ì‹¤ìŠµ ì§„í–‰ì— ì°¸ê³ í•˜ì!\në§ˆì¹˜ë©° ì´ë²ˆ ê¸€ì—ì„œëŠ” ëª» ë‹¤ë¤˜ì§€ë§Œ, VPC ê´€ë ¨í•˜ì—¬ ë‹¤ë£° ì£¼ì œê°€ ë§ë‹¤! í‹ˆí‹ˆíˆ ì •ë¦¬í•˜ì—¬ VPC Deep Dive 2íƒ„ì—ì„œ í•´ë‹¹ ë‚´ìš©ë“¤ì„ ë‹¤ë£° ìˆ˜ ìˆë„ë¡ í•˜ê² ë‹¤.\n","date":"May 12","permalink":"https://HanHoRang31.github.io/post/aews-eks-vpc-1/","tags":["KANS","eks","cloud","AWS","kubernetes","vpc"],"title":"[AEWS] EKS VPC CNI Deep Dive"},{"categories":null,"contents":" 1 2 AWS EKS Workshop Study (=AEWS)ëŠ” EKS Workshop ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°,ê³µê°œëœ AWS EKS Workshopì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì§€ë‚œ ë¸”ë¡œê·¸ ê¸€ì— ì´ì–´ì„œ kubeflow ë¥¼ ìŠ¤í„°ë””í•œ ë‚´ìš©ì„ ê³µìœ í•˜ê³ ì í•œë‹¤. ì˜¤ëŠ˜ ì£¼ì œëŠ” kubeflow ì˜ ì¸í”„ë¼ ìš”ì†Œë¡œ ì™œ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ì„ ì“°ëŠ” ê²ƒì´ ì¢‹ì€ ê°€ì™€ kubeflow ê°€ AWS í´ë¼ìš°ë“œ(EKS)ì— ì˜¬ë¼ê°”ì„ ë•Œ ì–´ë–¤ ì´ì ì´ ìˆëŠ” ì§€ í™•ì¸í•˜ê² ë‹¤.\nML on kubernetes ë¨¼ì €, ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ ì§€ì›í•˜ëŠ” ë° ë§¤ìš° ìœ ìš©í•œ í”Œë«í¼ìœ¼ë¡œ ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ê°€ ìˆë‹¤. (ì°¸ê³  : ChatGPT)\ní™•ì¥ì„±: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ í´ëŸ¬ìŠ¤í„°ì˜ ë‹¤ì–‘í•œ ë…¸ë“œì— ìë™ìœ¼ë¡œ ë¶„ì‚°ì‹œí‚¤ëŠ” ëŠ¥ë ¥ì„ ê°€ì§€ê³  ìˆë‹¤. ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ì„ í•™ìŠµí•˜ê±°ë‚˜ ì˜ˆì¸¡ì„ ìƒì„±í•  ë•Œ í•„ìš”í•œ ì»´í“¨íŒ… ìì›ì„ ìë™ìœ¼ë¡œ í™•ì¥í•˜ê³  ì¶•ì†Œí•  ìˆ˜ ìˆë‹¤ëŠ” ê²ƒì„ ì˜ë¯¸í•œë‹¤. í¬í„°ë¹Œë¦¬í‹°ì™€ ë‹¤ì¤‘ í´ë¼ìš°ë“œ ì§€ì›: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ì—¬ëŸ¬ í´ë¼ìš°ë“œ ì œê³µ ì—…ì²´ì— ê±¸ì³ ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë°°í¬í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë° ë„ì›€ì´ ëœë‹¤. ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ ì–´ë””ì„œë“  ì‰½ê²Œ ì´ë™í•˜ê³  ë°°í¬í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤. ìë™í™”ì™€ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ì»¨í…Œì´ë„ˆí™” ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë°°í¬, í™•ì¥ ë° ê´€ë¦¬ë¥¼ ìë™í™”í•œë‹¤. ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ íŒŒì´í”„ë¼ì¸ì˜ ë³µì¡í•œ ì›Œí¬í”Œë¡œìš°ë¥¼ ì‰½ê²Œ ê´€ë¦¬í•˜ê³  ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í•  ìˆ˜ ìˆìŒì„ ì˜ë¯¸í•œë‹¤. ìì› ê´€ë¦¬: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” CPU, ë©”ëª¨ë¦¬ ë“±ì˜ ìì›ì„ íš¨ê³¼ì ìœ¼ë¡œ ê´€ë¦¬í•˜ì—¬ ê° ì• í”Œë¦¬ì¼€ì´ì…˜ì— í•„ìš”í•œ ìì›ì„ ì œê³µí•œë‹¤. ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ì—ì„œ ì¤‘ìš”í•œ ì—­í• ì´ë‹¤. ì»¤ë®¤ë‹ˆí‹°ì™€ ì—ì½”ì‹œìŠ¤í…œ: ì¿ ë²„ë„¤í‹°ìŠ¤ëŠ” ê°•ë ¥í•œ ì»¤ë®¤ë‹ˆí‹°ì™€ ì—ì½”ì‹œìŠ¤í…œì„ ê°€ì§€ê³  ìˆë‹¤. ì—¬ê¸°ì—ëŠ” ë¨¸ì‹ ëŸ¬ë‹ì— íŠ¹í™”ëœ ë„êµ¬ì™€ í”„ë ˆì„ì›Œí¬ë¥¼ ì¿ ë²„ë„¤í‹°ìŠ¤ì— ì‰½ê²Œ í†µí•©í•  ìˆ˜ ìˆëŠ” Kubeflowì™€ ê°™ì€ í”„ë¡œì íŠ¸ê°€ í¬í•¨ëœë‹¤. ì—¬ê¸°ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ë³¼ ì ì€ 4ë²ˆì¸ ê²ƒ ê°™ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì˜ ëª¨ë¸ í•™ìŠµ ê³¼ì •ì—ì„œ ë¶„ì‚° ì²˜ë¦¬ë¡œ í•™ìŠµì„ ì§„í–‰í•˜ë©´ ì†ë„ê°€ ì„ í˜•ì ìœ¼ë¡œ ë¹¨ë¼ì§€ê¸° ë•Œë¬¸ì´ë‹¤.\nhttps://www.youtube.com/watch?v=qctwfYZKK8M\u0026amp;t=528s\nì¿ ë²„ë„¤í‹°ìŠ¤ê°€ ë¨¸ì‹ ëŸ¬ë‹ í”Œë«í¼ì— ìœ ìš©í•œ í”Œë«í¼ì¸ ê²ƒì„ í™•ì¸í–ˆì§€ë§Œ, ì–´ë–»ê²Œ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¨¸ì‹ ëŸ¬ë‹ í”Œë«í¼ì„ ë¨¸ì‹ ëŸ¬ë‹ ê³¼í•™ìë‚˜ ë¶„ì„ê°€ ë¶„ë“¤ì—ê²Œ ì œê³µí•  ê²ƒì— ëŒ€í•œ ì˜ë¬¸ì´ ë‚¨ëŠ”ë‹¤. ì—¬ê¸°ì— ëŒ€í•œ í•´ê²°ì ì´ ì§€ë‚œ ì‹œê°„ì— êµ¬ì¶•í•œ kubeflow ì¸ë° ML í”Œë«í¼ì„ í•œ ë° ëª¨ì•„ ë¬¶ì–´ ì„¤ì¹˜í•˜ê³  ì¸í„°ë„· ë§í¬ë¥¼ í†µí•´ ì‰½ê²Œ ì œê³µí•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\nhttps://www.youtube.com/watch?v=6GYuRy84M1o\u0026amp;t=67s\nKubeflow on AWS kubeflow on AWS ë¼ëŠ” ë§ì€ kubeflowë¥¼ EKSì—ì„œ ë°°í¬í–ˆì„ ë•Œë¥¼ ì–˜ê¸°í•œë‹¤. kubeflow on AWS ë¡œ ì˜¬ë¦¬ë©´ AWS ì„œë¹„ìŠ¤ì™€ì˜ í†µí•©ì„ í†µí•´ ìš´ì˜ ì˜¤ë²„í—¤ë“œë¥¼ ì¤„ì´ë©´ì„œ ì•ˆì „ì„±, ë³´ì•ˆ, ì´ì‹ì„±, í™•ì¥ì„±ì´ ìš°ìˆ˜í•œ ML ì‹œìŠ¤í…œì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤.\nAWS ì„œë¹„ìŠ¤ í†µí•©ì„ êµ¬ì²´ì ìœ¼ë¡œ ì˜ˆë¥¼ ë“¤ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\nì‚¬ìš©í•˜ê¸° ì‰¬ìš´ íŒŒì´í”„ë¼ì¸ ì•„í‹°íŒ©íŠ¸ ìŠ¤í† ì–´ë¥¼ ìœ„í•œ Amazon Simple Storage Service(Amazon S3) ë†’ì€ í™•ì¥ì„±ì˜ íŒŒì´í”„ë¼ì¸ ë° ë©”íƒ€ë°ì´í„° ìŠ¤í† ì–´ë¥¼ ìœ„í•œ Amazon Relational Database Service(Amazon RDS) í›ˆë ¨ ì„±ëŠ¥ í–¥ìƒ ëª©ì ì˜ ê°„ë‹¨í•˜ê³  í™•ì¥ ê°€ëŠ¥í•œ ì„œë²„ë¦¬ìŠ¤ íŒŒì¼ ìŠ¤í† ë¦¬ì§€ ì†”ë£¨ì…˜ì„ ìœ„í•œÂ Amazon Elastic File System/Amazon FSx for Lustre ì• í”Œë¦¬ì¼€ì´ì…˜ ì•¡ì„¸ìŠ¤ì— í•„ìš”í•œ ë³´ì•ˆ ì•”í˜¸ ë³´í˜¸ë¥¼ ìœ„í•œ AWS Secrets Manager ì˜êµ¬ ë¡œê·¸ ê´€ë¦¬ë¥¼ ìœ„í•œ AWS CloudWatch ê³ ë„ë¡œ ìµœì í™”ëœ Jupyter ë…¸íŠ¸ë¶ ì„œë²„ ì´ë¯¸ì§€ë¥¼ ìœ„í•œÂ AWS Deep Learning Containers HTTPSë¥¼ ê²½ìœ í•˜ëŠ” ì•ˆì „í•œ ì™¸ë¶€ íŠ¸ë˜í”½ ê´€ë¦¬ë¥¼ ìœ„í•œ AWS Application Load Balancer TLSë¥¼ í†µí•œ ì‚¬ìš©ì ì¸ì¦ì„ ìœ„í•œ AWS Cognito ìì„¸í•œ ì„œë¹„ìŠ¤ í†µí•© ë°©ë²• ê´€ë ¨í•˜ì—¬ Kubeflow ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ë„ë¡ í•˜ì.\nì´ë²ˆ ì¥ì—ì„œëŠ” ì§€ë‚œ ì‹œê°„ì— êµ¬ì¶•í•œ kubeflowì— AWS ë¡œë“œë°¸ëŸ°ì„œ ì„œë¹„ìŠ¤ì¸ AWS Application Load Balancer ì™€ íŒŒì¼ ìŠ¤í† ë¦¬ì§€ì¸ EFSë¥¼ ì¶”ê°€ë¡œ êµ¬ì¶•í•˜ëŠ” ë°©ë²•ì„ ê³µìœ í•˜ê² ë‹¤.\nAWS ALB ë° External DNS ì—°ê²° kubeflowì— AWS ALBì„ ì—°ê²°í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ ì¸í„°ë„· ë§ì—ì„œ HTTPSë¡œ ì ‘ê·¼í•˜ë„ë¡ ì„¤ì •í•˜ê² ë‹¤. ì´ì— ëŒ€í•œ ì‚¬ì „ ì‘ì—…ìœ¼ë¡œ ê°œì¸ ë„ë©”ì¸ê³¼ ì¸ì¦ì„œê°€ í•„ìš”í•˜ë‹¤. í•„ìì˜ ê²½ìš° AWS Route53ì—ì„œ ë„ë©”ì¸ì„ êµ¬ë§¤í•˜ì˜€ê³ , AWS ACMì„ í†µí•´ ì¸ì¦ì„œë¥¼ ë°œê¸‰ë°›ì•˜ë‹¤. ì‚¬ì „ ì‘ì—…ì— ëŒ€í•œ ë‚´ìš©ì€ kubeflow on AWS ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì.\nì´ì–´ì„œ EKS í´ëŸ¬ìŠ¤í„°ì— ALB controller ì„¤ì¹˜ê°€ í•„ìš”í•˜ë‹¤. ë‹¤ìŒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # ALB controller ì •ì±… ì„¤ì¹˜ curl -o iam_policy.json https://raw.githubusercontent.com/kubernetes-sigs/aws-load-balancer-controller/v2.4.7/docs/install/iam_policy.json aws iam create-policy --policy-name AWSLoadBalancerControllerIAMPolicy --policy-document file://iam_policy.json # ì •ì±… arn ìƒì„± í™•ì¸ ACCOUNT_ID={AWS ê³„ì • ë„˜ë²„} aws iam get-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --query \u0026#39;Policy.Arn\u0026#39; --- \u0026#34;arn:aws:iam::955963799952:policy/AWSLoadBalancerControllerIAMPolicy\u0026#34; # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ìƒì„± CLUSTER_NAME={EKS í´ëŸ¬ìŠ¤í„° ì´ë¦„} eksctl create iamserviceaccount --cluster=$CLUSTER_NAME --namespace=kube-system --name=aws-load-balancer-controller \\ --attach-policy-arn=arn:aws:iam::$ACCOUNT_ID:policy/AWSLoadBalancerControllerIAMPolicy --override-existing-serviceaccounts --approve # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ í™•ì¸ kubectl edit sa/aws-load-balancer-controller -n kube-system --- apiVersion: v1 kind: ServiceAccount metadata: annotations: # annotation í™•ì¸ eks.amazonaws.com/role-arn: arn:aws:iam::955963799952:role/eksctl-my-eks-kubeflow-addon-iamserviceaccou-Role1-18M1QX0LI36SU creationTimestamp: \u0026#34;2023-05-12T13:22:02Z\u0026#34; labels: app.kubernetes.io/managed-by: eksctl name: aws-load-balancer-controller namespace: kube-system resourceVersion: \u0026#34;42768\u0026#34; uid: 00393ee1-e469-4bd3-bd4e-6a10303a3f76 ~ ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ì—°ë™ì´ í™•ì¸ì´ ë˜ì—ˆìœ¼ë©´ ALB ì„ ì„¤ì¹˜í•˜ê² ë‹¤. ì„¤ì¹˜ëŠ” Helmì„ í†µí•´ ì§„í–‰í–ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # í´ëŸ¬ìŠ¤í„° ì´ë¦„ ì„¤ì • CLUSTER_NAME=my-eks-kubeflow printf \u0026#39;clusterName=\u0026#39;$CLUSTER_NAME\u0026#39;\u0026#39; \u0026gt; awsconfigs/common/aws-alb-ingress-controller/base/params.env # Install Load Balancer Controoler kustomize build awsconfigs/common/aws-alb-ingress-controller/base | kubectl apply -f - kubectl wait --for condition=established crd/ingressclassparams.elbv2.k8s.aws kustomize build awsconfigs/common/aws-alb-ingress-controller/base | kubectl apply -f - # ALB íŒŒë“œ í™•ì¸ kubectl get pods -A --- NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-load-balancer-controller-7857849d69-qc9nr 1/1 Running 0 24m # ALB ë¡œê·¸ í™•ì¸ kubectl logs pods/aws-load-balancer-controller-7857849d69-qc9nr -n kube-system --- {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;version\u0026#34;,\u0026#34;GitVersion\u0026#34;:\u0026#34;v2.5.1\u0026#34;,\u0026#34;GitCommit\u0026#34;:\u0026#34;06abaed66e17a411ba064f34e6018b889780ac66\u0026#34;,\u0026#34;BuildDate\u0026#34;:\u0026#34;2023-04-17T22:36:53+0000\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.metrics\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Metrics server is starting to listen\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;:8080\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;setup\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;adding health check for controller\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-v1-pod\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-v1-service\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-elbv2-k8s-aws-v1beta1-ingressclassparams\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/mutate-elbv2-k8s-aws-v1beta1-targetgroupbinding\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-elbv2-k8s-aws-v1beta1-targetgroupbinding\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Registering webhook\u0026#34;,\u0026#34;path\u0026#34;:\u0026#34;/validate-networking-v1-ingress\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:45Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;setup\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;starting podInfo repo\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:47Z\u0026#34;,\u0026#34;logger\u0026#34;:\u0026#34;controller-runtime.webhook.webhooks\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Starting webhook server\u0026#34;} {\u0026#34;level\u0026#34;:\u0026#34;info\u0026#34;,\u0026#34;ts\u0026#34;:\u0026#34;2023-05-08T05:59:47Z\u0026#34;,\u0026#34;msg\u0026#34;:\u0026#34;Starting server\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;health probe\u0026#34;,\u0026#34;addr\u0026#34;:\u0026#34;[::]:61779\u0026#34;} ... ì´ì–´ì„œ External DNS ë¥¼ ì„¤ì¹˜í•˜ì. ë‹¤ìŒì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ê¸°ë°˜ìœ¼ë¡œ OIDC ì •ì±… ì—°ë™ë¶€í„° ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 # vi iam_external_policy.json ìƒì„± cat \u0026lt;\u0026lt;EOT \u0026gt; iam_external_policy.json { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ChangeResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:route53:::hostedzone/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;route53:ListHostedZones\u0026#34;, \u0026#34;route53:ListResourceRecordSets\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;*\u0026#34; ] } ] } EOT aws iam create-policy --policy-name \u0026#34;AllowExternalDNSUpdates\u0026#34; --policy-document file://iam_external_policy.json.json # ì •ì±… arn ìƒì„± í™•ì¸ aws iam get-policy --policy-arn arn:aws:iam::$ACCOUNT_ID:policy/AllowExternalDNSUpdates --query \u0026#39;Policy.Arn\u0026#39; --- \u0026#34;arn:aws:iam::955963799952:policy/AllowExternalDNSUpdates\u0026#34; # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ ìƒì„± eksctl create iamserviceaccount --cluster=$CLUSTER_NAME --namespace=kube-system --name=external-dns \\ --attach-policy-arn=arn:aws:iam::$ACCOUNT_ID:policy/AllowExternalDNSUpdates --override-existing-serviceaccounts --approve # OIDC ì„œë¹„ìŠ¤ ì–´ì¹´ìš´íŠ¸ í™•ì¸ kubectl edit sa/external-dns -n kube-system --- apiVersion: v1 kind: ServiceAccount metadata: annotations: # ë§ˆì°¬ê°€ì§€ë¡œ ì—°ë™ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. eks.amazonaws.com/role-arn: arn:aws:iam::955963799952:role/eksctl-hanhorang-addon-iamserviceaccount-kub-Role1-499RATDKJVJU kubectl.kubernetes.io/last-applied-configuration: | {\u0026#34;apiVersion\u0026#34;:\u0026#34;v1\u0026#34;,\u0026#34;kind\u0026#34;:\u0026#34;ServiceAccount\u0026#34;,\u0026#34;metadata\u0026#34;:{\u0026#34;annotations\u0026#34;:{},\u0026#34;labels\u0026#34;:{\u0026#34;app.kubernetes.io/name\u0026#34;:\u0026#34;external-dns\u0026#34;},\u0026#34;name\u0026#34;:\u0026#34;external-dns\u0026#34;,\u0026#34;namespace\u0026#34;:\u0026#34;kube-system\u0026#34;}} creationTimestamp: \u0026#34;2023-05-08T06:02:38Z\u0026#34; labels: app.kubernetes.io/managed-by: eksctl app.kubernetes.io/name: external-dns name: external-dns namespace: kube-system resourceVersion: \u0026#34;13937\u0026#34; uid: 67ce20cc-6545-486c-b525-450be6311d65 external DNSì„ ì—°ë™í•˜ê¸° ìœ„í•´ì„œëŠ” ë„ë©”ì¸ì´ í•„ìš”í•˜ë‹¤. ì•ì„œ Route53ì—ì„œ ìƒì„±í•œ ë„ë©”ì¸ì„ ì—°ë™í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 # MyDomain=\u0026lt;ìì‹ ì˜ ë„ë©”ì¸\u0026gt; MyDomain=hanhorang.link # ìì‹ ì˜ Route 53 ë„ë©”ì¸ ID ì¡°íšŒ ë° ë³€ìˆ˜ ì§€ì • MyDnzHostedZoneId=$(aws route53 list-hosted-zones-by-name --dns-name \u0026#34;${MyDomain}.\u0026#34; --query \u0026#34;HostedZones[0].Id\u0026#34; --output text) # ExternalDNS ë°°í¬ curl -s -O https://raw.githubusercontent.com/gasida/PKOS/main/aews/externaldns.yaml cat externaldns.yaml | yh MyDomain=$MyDomain MyDnzHostedZoneId=$MyDnzHostedZoneId envsubst \u0026lt; externaldns.yaml | kubectl apply - # ë¡œê·¸ í™•ì¸ kubectl get pods -A --- kube-system external-dns-6b5bbbf9d-l7ms2 1/1 Running 0 4 kubectl logs pods/external-dns-6b5bbbf9d-l7ms2 -n kube-system --- time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;config: {APIServerURL: KubeConfig: RequestTimeout:30s DefaultTargets:[] ContourLoadBalancerService:heptio-contour/contour GlooNamespace:gloo-system SkipperRouteGroupVersion:zalando.org/v1 Sources:[service ingress] Namespace: AnnotationFilter: LabelFilter: FQDNTemplate: CombineFQDNAndAnnotation:false IgnoreHostnameAnnotation:false IgnoreIngressTLSSpec:false IgnoreIngressRulesSpec:false GatewayNamespace: GatewayLabelFilter: Compatibility: PublishInternal:false PublishHostIP:false AlwaysPublishNotReadyAddresses:false ConnectorSourceServer:localhost:8080 Provider:aws GoogleProject: GoogleBatchChangeSize:1000 GoogleBatchChangeInterval:1s GoogleZoneVisibility: DomainFilter:[hanhorang.link] ExcludeDomains:[] RegexDomainFilter: RegexDomainExclusion: ZoneNameFilter:[] ZoneIDFilter:[] TargetNetFilter:[] ExcludeTargetNets:[] AlibabaCloudConfigFile:/etc/kubernetes/alibaba-cloud.json AlibabaCloudZoneType: AWSZoneType:public AWSZoneTagFilter:[] AWSAssumeRole: AWSAssumeRoleExternalID: AWSBatchChangeSize:1000 AWSBatchChangeInterval:1s AWSEvaluateTargetHealth:true AWSAPIRetries:3 AWSPreferCNAME:false AWSZoneCacheDuration:0s AWSSDServiceCleanup:false AzureConfigFile:/etc/kubernetes/azure.json AzureResourceGroup: AzureSubscriptionID: AzureUserAssignedIdentityClientID: BluecatDNSConfiguration: BluecatConfigFile:/etc/kubernetes/bluecat.json BluecatDNSView: BluecatGatewayHost: BluecatRootZone: BluecatDNSServerName: BluecatDNSDeployType:no-deploy BluecatSkipTLSVerify:false CloudflareProxied:false CloudflareDNSRecordsPerPage:100 CoreDNSPrefix:/skydns/ RcodezeroTXTEncrypt:false AkamaiServiceConsumerDomain: AkamaiClientToken: AkamaiClientSecret: AkamaiAccessToken: AkamaiEdgercPath: AkamaiEdgercSection: InfobloxGridHost: InfobloxWapiPort:443 InfobloxWapiUsername:admin InfobloxWapiPassword: InfobloxWapiVersion:2.3.1 InfobloxSSLVerify:true InfobloxView: InfobloxMaxResults:0 InfobloxFQDNRegEx: InfobloxNameRegEx: InfobloxCreatePTR:false InfobloxCacheDuration:0 DynCustomerName: DynUsername: DynPassword: DynMinTTLSeconds:0 OCIConfigFile:/etc/kubernetes/oci.yaml InMemoryZones:[] OVHEndpoint:ovh-eu OVHApiRateLimit:20 PDNSServer:http://localhost:8081 PDNSAPIKey: PDNSTLSEnabled:false TLSCA: TLSClientCert: TLSClientCertKey: Policy:sync Registry:txt TXTOwnerID:/hostedzone/Z08463751O7YNWD79KKIX TXTPrefix: TXTSuffix: Interval:1m0s MinEventSyncInterval:5s Once:false DryRun:false UpdateEvents:false LogFormat:text MetricsAddress::7979 LogLevel:info TXTCacheInterval:0s TXTWildcardReplacement: ExoscaleEndpoint:https://api.exoscale.ch/dns ExoscaleAPIKey: ExoscaleAPISecret: CRDSourceAPIVersion:externaldns.k8s.io/v1alpha1 CRDSourceKind:DNSEndpoint ServiceTypeFilter:[] CFAPIEndpoint: CFUsername: CFPassword: RFC2136Host: RFC2136Port:0 RFC2136Zone: RFC2136Insecure:false RFC2136GSSTSIG:false RFC2136KerberosRealm: RFC2136KerberosUsername: RFC2136KerberosPassword: RFC2136TSIGKeyName: RFC2136TSIGSecret: RFC2136TSIGSecretAlg: RFC2136TAXFR:false RFC2136MinTTL:0s RFC2136BatchChangeSize:50 NS1Endpoint: NS1IgnoreSSL:false NS1MinTTLSeconds:0 TransIPAccountName: TransIPPrivateKeyFile: DigitalOceanAPIPageSize:50 ManagedDNSRecordTypes:[A CNAME] GoDaddyAPIKey: GoDaddySecretKey: GoDaddyTTL:0 GoDaddyOTE:false OCPRouterName: IBMCloudProxied:false IBMCloudConfigFile:/etc/kubernetes/ibmcloud.json TencentCloudConfigFile:/etc/kubernetes/tencent-cloud.json TencentCloudZoneType: PiholeServer: PiholePassword: PiholeTLSInsecureSkipVerify:false PluralCluster: PluralProvider:}\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Instantiating new Kubernetes client\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Using inCluster-config based on serviceaccount-token\u0026#34; time=\u0026#34;2023-05-08T06:02:43Z\u0026#34; level=info msg=\u0026#34;Created Kubernetes client https://10.100.0.1:443\u0026#34; time=\u0026#34;2023-05-08T06:02:45Z\u0026#34; level=info msg=\u0026#34;Applying provider record filter for domains: [hanhorang.link. .hanhorang.link.]\u0026#34; time=\u0026#34;2023-05-08T06:02:45Z\u0026#34; level=info msg=\u0026#34;All records are already up to date\u0026#34; 1 2 3 4 5 6 7 8 9 10 11 12 export certArn= ACM ì¸ì¦ì„œ arn # ê²½ë¡œ kubeflow-manifests printf \u0026#39;certArn=\u0026#39;$certArn\u0026#39;\u0026#39; \u0026gt; awsconfigs/common/istio-ingress/overlays/https/params.env # istio certArn ì„¤ì • ì—…ë°ì´íŠ¸ kustomize build awsconfigs/common/istio-ingress/overlays/https | kubectl apply -f - # ì •ìƒ ë“±ë¡ í™•ì¸ kubectl get ingress -n istio-system istio-ingress --- NAME CLASS HOSTS ADDRESS PORTS AGE istio-ingress \u0026lt;none\u0026gt; * k8s-istiosys-istioing-663e16c023-2114118481.ap-northeast-2.elb.amazonaws.com 80 43s ì´ì–´ì„œ ë„ë©”ì¸ ë“±ë¡ì´ í•„ìš”í•˜ë‹¤. ë‹¤ìŒì˜ ê²½ë¡œ tests/e2e/utils/load_balancer/config.yaml ì—ì„œ íŒŒì¼ì„ ìˆ˜ì •í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 cluster: name: my-eks-kubeflow region: ap-northeast-2 kubeflow: alb: scheme: internet-facing route53: rootDomain: hostedZoneId: Z08463751O7YNWD79KKIX name: hanhorang.link subDomain: name: platform.hanhorang.link ì ìš© ëª…ë ¹ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 # ê²½ë¡œ kubeflow-manifests # ì„¤ì¹˜ ìŠ¤í¬ë¦½íŠ¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜ cd tests/e2e pip3 install -r requirements.txt # ê²½ë¡œ í™•ì¸! # ë°˜ë“œì‹œ kubeflow-manifests/tests/e2e ì—ì„œ ì§„í–‰í•˜ì. (íŒŒì´ì¬ e2e ëª¨ë“ˆ ì¸ì‹) PYTHONPATH=.. python3 utils/load_balancer/setup_load_balancer.py ì—…ë°ì´íŠ¸ê°€ ì§„í–‰ë˜ì—ˆìœ¼ë©´tests/e2e/utils/load_balancer/config.yaml íŒŒì¼ì„ ë‹¤ì‹œ í™•ì¸í•˜ì. ë“±ë¡í•œ ë„ë©”ì¸ê³¼ certARNì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 cluster: name: my-eks-kubeflow region: ap-northeast-2 kubeflow: alb: dns: k8s-istiosys-istioing-663e16c023-2114118481.ap-northeast-2.elb.amazonaws.com scheme: internet-facing serviceAccount: name: aws-load-balancer-controller namespace: kube-system policyArn: arn:aws:iam::955963799952:policy/alb_ingress_controller_my-eks-kubeflow3tdc061n5e route53: rootDomain: certARN: arn:aws:acm:ap-northeast-2:955963799952:certificate/274b725c-c1ad-4528-a593-e0030aaa62f9 hostedZoneId: Z08463751O7YNWD79KKIX name: hanhorang.link subDomain: certARN: arn:aws:acm:ap-northeast-2:955963799952:certificate/09d02797-709e-4c9b-9b95-8eef6fee7e3f hostedZoneId: Z08293761OELZZQTGI41U name: platform.hanhorang.link ì•½ 5ë¶„~10ë¶„ì´í›„ ë‹¤ìŒì˜ ì„œë¸Œë„ë©”ì¸ (kubeflow.platform.hanhorang.link) ì— ì ‘ì†í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì—°ê²°ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nEFS ì—°ê²° EFS(Amazon Elastic File System)ëŠ” AWSì—ì„œ ì œê³µí•˜ëŠ” íŒŒì¼ ìŠ¤í† ë¦¬ì§€ì´ë‹¤. íŒŒì¼ ìŠ¤í† ë¦¬ì§€ì¸ ë§Œí¼ ì—¬ëŸ¬ ë…¸ë“œì—ì„œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ì—¬ ë¨¸ì‹ ëŸ¬ë‹ê°™ì€ ì›Œí¬ í”Œë¡œìš°ì— ìì£¼ ì¶”ì²œí•˜ëŠ” ì„œë¹„ìŠ¤ì´ë‹¤. kubeflowì—ì„œë„ EFSë¥¼ í™œìš©í•  ìˆ˜ ìˆëŠ”ë° í™œìš©í•˜ì—¬ ì–»ëŠ” ì´ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. (ì°¸ê³  ChatGPT)\në¶„ì‚° í•™ìŠµ: EFSë¥¼ ì‚¬ìš©í•˜ë©´ ì—¬ëŸ¬ ë…¸ë“œê°€ ë™ì¼í•œ íŒŒì¼ ì‹œìŠ¤í…œì— ì ‘ê·¼í•  ìˆ˜ ìˆë‹¤. ëª¨ë“  ë…¸ë“œê°€ ë™ì¼í•œ ë°ì´í„°ì— ì ‘ê·¼í•˜ê³ , ì¤‘ê°„ í•™ìŠµ ê²°ê³¼ë¥¼ ê³µìœ í•˜ë©´ì„œ ë™ì‹œì— ì‘ì—…ì„ ìˆ˜í–‰í•  ìˆ˜ ìˆì–´ í•™ìŠµ ì†ë„ê°€ ë¹¨ë¼ì§„ë‹¤.. ë°ì´í„° ê³µìœ ì™€ ì¬ì‚¬ìš©: EFSëŠ” í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ë…¸ë“œì—ì„œ ë™ì‹œì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ì¤‘ì•™í™”ëœ ì €ì¥ ê³µê°„ì„ ì œê³µí•œë‹¤. ì´ëŠ” ë°ì´í„°ë¥¼ ì‰½ê²Œ ê³µìœ í•˜ê³  ì¬ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•˜ë¯€ë¡œ, ë°ì´í„° ê´€ë¦¬ë¥¼ ë‹¨ìˆœí™”í•˜ê³  ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œìš°ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ë§Œë“ ë‹¤. í™•ì¥ì„±: EFSëŠ” ìë™ìœ¼ë¡œ í™•ì¥ë˜ê³  ì¶•ì†Œë˜ë¯€ë¡œ, ë°ì´í„° ì €ì¥ëŸ‰ì— ëŒ€í•´ ê±±ì •í•  í•„ìš”ê°€ ì—†ë‹¤. ë˜í•œ, ë°ì´í„°ëŠ” ì—¬ëŸ¬ ê°€ìš© ì˜ì—­ì— ê±¸ì³ ë³µì œë˜ë¯€ë¡œ, ë‚´êµ¬ì„±ê³¼ ê°€ìš©ì„±ë„ ë³´ì¥ëœë‹¤. ì§€ì†ì ì¸ ì €ì¥ì†Œ: EFSëŠ” ì§€ì†ì ì¸ ìŠ¤í† ë¦¬ì§€ë¥¼ ì œê³µí•œë‹¤. ì¦‰, íŒŒë“œê°€ ì¢…ë£Œë˜ê±°ë‚˜ ë…¸ë“œì— ë¬¸ì œê°€ ìƒê²¨ë„ ë°ì´í„°ëŠ” ì•ˆì „í•˜ê²Œ ë³´í˜¸ëœë‹¤. ì´ëŠ” ë¨¸ì‹ ëŸ¬ë‹ í›ˆë ¨ì—ì„œ ì¤‘ìš”í•œë°, í›ˆë ¨ ì¤‘ì¸ ëª¨ë¸ì˜ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•˜ê³  í•„ìš”í•  ë•Œ ì–¸ì œë“ ì§€ ë³µêµ¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì•„ë˜ëŠ” EFS ì—°ê²°ì‹œ ê° ì›Œì»¤ ë…¸ë“œì—ì„œ ì‘ë™í•˜ëŠ” ì•„í‚¤í…ì²˜ì´ë‹¤. EFS íŠ¹ì„±ì— ë§ê²Œ ê° ë…¸ë“œê°€ ìŠ¤í† ë¦¬ì§€ë¥¼ ê³µìœ í•˜ì—¬ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\nEFS ì—°ê²°ì„ ìœ„í•´ì„œëŠ” EFS í”„ë¡œë¹„ì €ë‹ì´ í•„ìš”í•˜ë‹¤. EFS í”„ë¡œë¹„ì €ë‹ ë°©ë²•ì€ ì •ì , ë™ì  ë‘ê°€ì§€ë¡œ ì´ë²ˆ ê¸€ì—ì„œëŠ” ë™ì ìœ¼ë¡œ ìƒì„±í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 # IAM ì •ì±… ìƒì„± curl -s -O https://raw.githubusercontent.com/kubernetes-sigs/aws-efs-csi-driver/master/docsiam-policy-example.json aws iam create-policy --policy-name AmazonEKS_EFS_CSI_Driver_Policy --policy-document file://iam-policy-example.json # ISRA ì„¤ì • : ê³ ê°ê´€ë¦¬í˜• ì •ì±… AmazonEKS_EFS_CSI_Driver_Policy ì‚¬ìš© eksctl create iamserviceaccount \\ --name efs-csi-controller-sa \\ --namespace kube-system \\ --cluster ${CLUSTER_NAME} \\ --attach-policy-arn arn:aws:iam::${ACCOUNT_ID}:policy/AmazonEKS_EFS_CSI_Driver_Policy \\ --approve # ì ìš© í™•ì¸, annotation kubectl get sa -n kube-system efs-csi-controller-sa -o yaml | head -5 --- apiVersion: v1 kind: ServiceAccount metadata: annotations: # ì ìš© í™•ì¸ eks.amazonaws.com/role-arn: arn:aws:iam::955963799952:role/eksctl-my-eks-kubeflow-addon-iamserviceaccou-Role1-1TAOJ41 # efs csi driver ì„¤ì¹˜ helm repo add aws-efs-csi-driver https://kubernetes-sigs.github.io/aws-efs-csi-driver/ helm repo update helm upgrade -i aws-efs-csi-driver aws-efs-csi-driver/aws-efs-csi-driver \\ --namespace kube-system \\ --set image.repository=602401143452.dkr.ecr.ap-northeast-2.amazonaws.com/eks/aws-efs-csi-driver \\ --set controller.serviceAccount.create=false \\ --set controller.serviceAccount.name=efs-csi-controller-sa EFS í”„ë¡œë¹„ì €ë‹ ì „ EFS ìŠ¤í† ë¦¬ì§€ ìƒì„±ì´ í•„ìš”í•˜ë‹¤. ìŠ¤í† ë¦¬ì§€ ìƒì„± ë‹¨ê³„ ì „ EKS CIDR ë³´ì•ˆ ê·¸ë£¹ ì¶”ê°€(NFS íŠ¸ë˜í”½ í—ˆìš©)ê°€ í•„ìš”í•˜ë‹¤. ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ë³´ì•ˆ ê·¸ë£¹ì„ ìƒì„±í•˜ê³  EFS íŒŒì¼ ì‹œìŠ¤í…œì„ ìƒì„±í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # ë³´ì•ˆ ê·¸ë£¹ ìƒì„±ì„ ìœ„í•œ ë„¤íŠ¸ì›Œí¬ ë³€ìˆ˜ ì„¤ì • vpc_id=$(aws eks describe-cluster \\ --name my-eks-kubeflow \\ --query \u0026#34;cluster.resourcesVpcConfig.vpcId\u0026#34; \\ --output text) cidr_range=$(aws ec2 describe-vpcs \\ --vpc-ids $vpc_id \\ --query \u0026#34;Vpcs[].CidrBlock\u0026#34; \\ --output text \\ --region ap-northeast-2) # ë³´ì•ˆ ê·¸ë£¹ ìƒì„± security_group_id=$(aws ec2 create-security-group \\ --group-name MyEfsSecurityGroup \\ --description \u0026#34;My EFS security group\u0026#34; \\ --vpc-id $vpc_id \\ --output text) # NFS íŠ¸ë˜í”½ í—ˆìš© aws ec2 authorize-security-group-ingress \\ --group-id $security_group_id \\ --protocol tcp \\ --port 2049 \\ --cidr $cidr_range # EFS íŒŒì¼ ì‹œìŠ¤í…œ ìƒì„± file_system_id=$(aws efs create-file-system \\ --region ap-northeast-2 \\ --performance-mode generalPurpose \\ --query \u0026#39;FileSystemId\u0026#39; \\ --output text) # EFS í™•ì¸ echo $file_system_id -- fs-01eea8c4de75fcd80 # ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ìƒì„± EfsFsId=$(aws efs describe-file-systems --query \u0026#34;FileSystems[*].FileSystemId\u0026#34; --output text) curl -s -O https://raw.githubusercontent.com/kubernetes-sigs/aws-efs-csi-driver/master/examples/kubernetes/dynamic_provisioning/specs/storageclass.yaml sed -i \u0026#34;s/fs-92107410/$EfsFsId/g\u0026#34; storageclass.yaml kubectl apply -f storageclass.yaml kubectl get sc efs-sc -- NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE ebs-sc (default) ebs.csi.aws.com Delete WaitForFirstConsumer false 6h48m efs-sc efs.csi.aws.com Delete Immediate false 25s gp2 kubernetes.io/aws-ebs Delete WaitForFirstConsumer false 7h37m kubeflow ëŒ€ì‹œë³´ë“œì— ì ‘ì†í•˜ì—¬ EFS ìŠ¤í† ë¦¬ì§€ë¥¼ ìƒì„±í•´ë³´ì. ê¸°ë³¸ ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ëŠ” user@example.com , 12341234 ì´ë‹¤.\në¡œê·¸ì¸ ì´í›„ ì™¼ìª½ ë©”ë‰´ [Volumes] â†’ [New Volume] í´ë¦­ í›„ Storage Class í™•ì¸ì‹œ efs-sc ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nìƒì„±ëœ ë³¼ë¥¨ì€ ì½˜ì†” ë° í„°ë¯¸ë„ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nìƒì„±í•œ ë³¼ë¥¨ì€ jupyter notebook ìƒì„±ì‹œ ë°ì´í„° ë³¼ë¥¨ ì„¤ì •í•´ì„œ ë³¼ë¥¨ ì§€ì •ì´ ê°€ëŠ¥í•˜ë‹¤\nì´í›„ EFS ë³¼ë¥¨ì„ ì‚¬ìš©í•˜ëŠ” ê¸°ê³„ í•™ìŠµ í›ˆë ¨ì˜ ì˜ˆì œëŠ” GitHubì— ë”°ë¼ ì§„í–‰í•˜ë„ë¡ í•˜ì.\në§ˆì¹˜ë©° Kubeflow on AWS ê´€ë ¨í•˜ì—¬ ALB ì™€ EFSë¥¼ ì—°ë™í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì•˜ë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” kubeflowë¥¼ í†µí•´ íŒŒì´í”„ë¼ì¸ì„ í†µí•œ ëª¨ë¸ ìƒì„± ë° ì´ë¥¼ ê¸°ë°˜í•œ API deployment ë“±ë“± ML ìª½ ì˜ˆì œë¥¼ ë‹¤ë£° ì˜ˆì •ì´ë‹¤. ë˜í•œ ëª» ë‹¤ë£¬ ì´ì•¼ê¸°ì§€ë§Œ kubeflow í•™ìŠµì‹œ ë…¸ë“œ í™•ì¥ì„±ìœ¼ë¡œ (ë…¸ë“œ ì…€ë ‰í„°, ì–´í”¼ë‹ˆí‹°)ë¥¼ í†µí•´ ë…¸ë“œê°€ ìë™ í™•ì¥ëœë‹¤ëŠ”ë° ì´ ì ì— ëŒ€í•´ì„œë„ í™•ì¸í•  ìƒê°ì´ë‹¤.\n","date":"May 11","permalink":"https://HanHoRang31.github.io/post/kubeflow-on-aws/","tags":["KANS","kubeflow","cloud","AWS","eksctl","eks"],"title":"[AEWS] Kubeflow on AWS"},{"categories":null,"contents":" 1 2 AWS EKS Workshop Study (=AEWS)ëŠ” EKS Workshop ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°,ê³µê°œëœ AWS EKS Workshopì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. EKS êµ¬ì¶• ë° ê´€ë¦¬ íˆ´ì¸ eksctlì€ ë‹¤ì–‘í•œ êµ¬ì„± ì˜µì…˜ì„ ì œê³µí•œë‹¤. ê³µì‹ ë¬¸ì„œì— ì •ë¦¬ê°€ ì˜ ë˜ì–´ ìˆìœ¼ë©° ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œ í•„ì ê¸°ì¤€ì˜ í¥ë¯¸ë¡œìš´ ì˜µì…˜ì„ ëª‡ ê°€ì§€ ì„ íƒí•˜ì—¬ í…ŒìŠ¤íŠ¸í•œ ë‚´ìš©ì„ ê³µìœ í•˜ê³ ì í•œë‹¤.\nEKS addon í™•ì¥ì„ ìœ„í•œ AWS IAM ì •ì±… ìƒì„± EKS ë…¸ë“œë¡œ Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©í•˜ê¸° Spot ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ kubeflow ì¸í”„ë¼ êµ¬ì„±í•˜ê¸° EKS addon í™•ì¥ì„ ìœ„í•œ AWS IAM ì •ì±… ìƒì„± EKS addonëŠ” Amazon EKSì—ì„œ ì œê³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° êµ¬ì„± ìš”ì†Œë¡œ, í´ëŸ¬ìŠ¤í„°ì˜ ê´€ë¦¬, ë„¤íŠ¸ì›Œí‚¹, ë¡œë“œ ë°¸ëŸ°ì‹± ë“±ì„ ë‹´ë‹¹í•˜ëŠ” í™•ì¥ ê¸°ëŠ¥ì´ë‹¤. ì´ëŸ¬í•œ addon ì„ ì‚¬ìš©í•˜ë©´ í™•ì¥ ê¸°ëŠ¥ì˜ ë²„ì „ ê´€ë¦¬ì™€ ì—…ë°ì´íŠ¸ê°€ ì‰¬ì›Œì§„ë‹¤. ê¸°ë³¸ì ìœ¼ë¡œ EKS ì„¤ì¹˜ì‹œ ë„¤íŠ¸ì›Œí¬ë‹¨ì˜ addonì´ ì„¤ì¹˜ëœë‹¤. ì„¤ì¹˜ë˜ëŠ” addonì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nì• ë“œì˜¨ ì´ë¦„ ì„¤ëª… CoreDNS í´ëŸ¬ìŠ¤í„° ë‚´ì˜ DNS ì¿¼ë¦¬ë¥¼ ì²˜ë¦¬í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. Kube-proxy ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤ì™€ ê´€ë ¨ëœ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ì„ ì²˜ë¦¬í•œë‹¤. VPC CNI ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ íŒŒë“œ ê°„ ë„¤íŠ¸ì›Œí‚¹ì„ ê´€ë¦¬í•˜ëŠ” Amazon VPC CNI í”ŒëŸ¬ê·¸ì¸ì´ë‹¤. ë¡œë“œë°¸ëŸ°ì‹±, ë„¤íŠ¸ì›Œí¬ ë“±ì˜ ì¶”ê°€ addonì€ eks ì„¤ì¹˜ ì´í›„ ì„¤ì¹˜ê°€ ê°€ëŠ¥í•˜ë‹¤. ì¤‘ìš”í•œ ì ì€ addon ì„¤ì¹˜ì„ ìœ„í•´ì„œëŠ” í•„ìš” IAM ì •ì±…ì´ í•„ìš”í•˜ë‹¤. EKS addon ì˜ í™•ì¥ ê¸°ëŠ¥ì€ AWS ì„œë¹„ìŠ¤ë¥¼ ì‚¬ìš©í•˜ë©° ì´ë¥¼ ìœ„í•´ AWS ì„œë¹„ìŠ¤ ì‚¬ìš©ì„ ìœ„í•œ IAM ì •ì±…ì´ í•„ìš”í•˜ê¸° ë•Œë¬¸ì´ë‹¤. eksctlëŠ” addon ì„¤ì¹˜ë¥¼ ì œê³µí•˜ì§€ ì•Šì§€ë§Œ, IAM ì •ì±… ìƒì„±ì€ ì œê³µí•œë‹¤. eksctlë¥¼ í†µí•´ì„œ ë…¸ë“œì— IAM ì •ì±…ì´ ë¶€ì—¬ë˜ëŠ”ë° ë¶€ì—¬í•  ìˆ˜ ìˆëŠ” ë¦¬ìŠ¤íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 nodeGroups: - name: ng-1 instanceType: m5.xlarge desiredCapacity: 1 iam: # addon ì •ì±… ë¶€ì—¬ withAddonPolicies: imageBuilder: true # ì´ë¯¸ì§€ ë¹Œë”: ì‚¬ìš©ì ì •ì˜ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ ë¹Œë“œí•˜ê³  ê´€ë¦¬í•˜ëŠ” ë„êµ¬ autoScaler: true # ì˜¤í†  ìŠ¤ì¼€ì¼ëŸ¬: í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ìë™ìœ¼ë¡œ ë…¸ë“œ ë° íŒŒë“œ í¬ê¸°ë¥¼ ì¡°ì • externalDNS: true # ì™¸ë¶€ DNS: ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤ì™€ ì¸ê·¸ë ˆìŠ¤ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì™¸ë¶€ DNS ë ˆì½”ë“œë¥¼ ê´€ë¦¬ certManager: true # ì¸ì¦ì„œ ê´€ë¦¬ì: ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ TLS ì¸ì¦ì„œë¥¼ ìë™ìœ¼ë¡œ ë°œê¸‰ ë° ê´€ë¦¬ appMesh: true # ì•± ë©”ì‹œ: ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ê°„ í†µì‹ ì„ ê´€ë¦¬í•˜ê³  ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì„œë¹„ìŠ¤ ë©”ì‹œ appMeshPreview: true # ì•± ë©”ì‹œ í”„ë¦¬ë·°: ì•± ë©”ì‹œì˜ ë² íƒ€ ê¸°ëŠ¥ì„ ë¯¸ë¦¬ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•´ì£¼ëŠ” í”„ë¦¬ë·° ë²„ì „ ebs: true # Amazon EBS CSI ë“œë¼ì´ë²„: ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ Amazon EBS ë³¼ë¥¨ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•¨ fsx: true # Amazon FSx CSI ë“œë¼ì´ë²„: ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ Amazon FSx íŒŒì¼ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•¨ efs: true # Amazon EFS CSI ë“œë¼ì´ë²„: ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ Amazon EFS íŒŒì¼ ì‹œìŠ¤í…œì„ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•¨ awsLoadBalancerController: true # AWS ë¡œë“œ ë°¸ëŸ°ì„œ ì»¨íŠ¸ë¡¤ëŸ¬: AWS ë¡œë“œ ë°¸ëŸ°ì„œë¥¼ ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤ì™€ í†µí•© xRay: true # AWS X-Ray: ë¶„ì‚° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì„±ëŠ¥ ë¬¸ì œë¥¼ ë¶„ì„í•˜ê³  ë””ë²„ê¹…í•˜ëŠ” ì„œë¹„ìŠ¤ cloudWatch: true # Amazon CloudWatch: AWS ë¦¬ì†ŒìŠ¤ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë‹ˆí„°ë§ ë° ê´€ì¸¡ì„ ì œê³µ eksctl ë¥¼ í†µí•´ ì„¤ì¹˜ëœ ì •ì±…ì€ AWS ì½˜ì†”ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nEKS ë…¸ë“œë¡œ Spot ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš©í•˜ê¸° Spot ì¸ìŠ¤í„´ìŠ¤ëŠ” AWSì˜ ë¯¸ì‚¬ìš© ì»´í“¨íŒ… ìš©ëŸ‰ì„ í• ì¸ëœ ê°€ê²©ìœ¼ë¡œ ì œê³µí•˜ëŠ” Amazon EC2 ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ì´ë‹¤. Spot ì¸ìŠ¤í„´ìŠ¤ëŠ” ì˜¨ë””ë§¨ë“œ ì¸ìŠ¤í„´ìŠ¤ë³´ë‹¤ ë¹„ìš©ì´ ìµœëŒ€ 90% ê¹Œì§€ ì €ë ´í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì§€ë§Œ, ê°€ìš©ì„±ì´ ë–¨ì–´ì§ˆ ê²½ìš° AWSì— ì˜í•´ ì¤‘ë‹¨ë  ìˆ˜ ìˆë‹¤. ì´ëŸ¬í•œ ì´ìœ ë¡œ ê°€ë³€ ì›Œí¬ë¡œë“œ ì²˜ë¦¬ë‚˜ ì‹œê°„ì— ë¯¼ê°í•˜ì§€ ì•ŠëŠ” ì›Œí¬ë¡œë“œ(ë°ì´í„° ë¶„ì„, ë°°ì¹˜) ì‘ì—…ì— ì‚¬ìš©ëœë‹¤.\në³µì¡í•  ê²ƒ ê°™ì§€ë§Œ, Spot ì¸ìŠ¤í„´ìŠ¤ì˜ ë¹„ìš© ì ˆê°ì´ ê°€ì§€ê³  ì˜¤ëŠ” ì¥ì ì´ ì–´ë§ˆë¬´ì‹œí•˜ë‹¤. ë¹„ìš© ì ˆê°ì˜ ì›ë¦¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\nhttps://www.youtube.com/watch?v=ugDrxMqSj-E\u0026amp;t=426s\nê·¸ë¦¼ê³¼ ê°™ì´ ì‚¬ìš©ìê°€ ì›í•˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ì˜ ê°€ê²©ì„ ì •í•´ë‘ë©´ AWS ì—ì„œ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¸ìŠ¤í„´ìŠ¤ë¥¼ í•œì •í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì œê³µí•˜ëŠ” ì‹ì´ë‹¤. ì‚¬ìš©ì ì œì‹œ ê°€ê²©ì— ë”°ë¼ ìµœëŒ€ 90í¼ê¹Œì§€ ì ˆê°ì´ ê°€ëŠ¥í•˜ë‚˜, ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ì¸ìŠ¤í„´ìŠ¤ê°€ ê°€ë³€ì ìœ¼ë¡œ ë³€í•˜ê¸°ì— ë³´í†µ 95%ë¡œ ì¤‘ë‹¨ëœë‹¤ê³  í•œë‹¤.\nAWS ì—ì„œ spot ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì„œë¹„ìŠ¤ë“¤ì´ ë‹¤ì–‘í•˜ë‹¤. ì´ë²ˆ ê¸€ì—ì„œëŠ” EKSì—ì„œ SPOT ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²½ìš°ë¥¼ ë‹¤ë£¨ê² ë‹¤.\neksctl ì—ì„œ ì›Œí¬ ë…¸ë“œì— ëŒ€í•´ spot ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. ë‹¤ë§Œ, ì›Œí¬ ë…¸ë“œ ì˜µì…˜ì´ ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹, ë¹„ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì— ë”°ë¼ êµ¬ì„± ì˜µì…˜ì´ ë‹¤ë¥¸ë° êµ¬ì„± íŒŒì¼ì„ í™•ì¸í•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # spot-ng.yaml --- apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: my-eks region: ap-northeast-2 nodeGroups: # ë¹„ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ - name: spot-1 minSize: 0 maxSize: 2 instancesDistribution: maxPrice: 0.017 instanceTypes: [\u0026#34;t3.small\u0026#34;, \u0026#34;t3.medium\u0026#34;] # At least one instance type should be specified onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 50 spotInstancePools: 2 managedNodeGroups: # ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ - name: spot-m1 instanceTypes: [\u0026#34;c3.large\u0026#34;,\u0026#34;c4.large\u0026#34;,\u0026#34;c5.large\u0026#34;,\u0026#34;c5d.large\u0026#34;,\u0026#34;c5n.large\u0026#34;,\u0026#34;c5a.large\u0026#34;] spot: true desiredCapacity: 1 # ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì„¤ì •í•˜ì§€ ì•Šìœ¼ë©´ m5.largeë¡œ ì„¤ì •ëœë‹¤. - name: spot-m2 spot: true desiredCapacity: 1 ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì€ spot: ture ì„ í†µí•´ ë¹„ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì€ instancesDistribution ì„ í†µí•´ ê°€ëŠ¥í•˜ë‹¤. ì˜µì…˜ ì„¤ì • ë¶€ë¶„ì´ ë§ì´ ì°¨ì´ë‚˜ëŠ”ë° ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì€ AWSê°€ ì•Œì•„ì„œ ì„¤ì •í•´ì£¼ëŠ” ë°˜ë©´ ë¹„ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì€ ì‚¬ìš©ìê°€ ìì„¸í•˜ê²Œ ë¹„ìš© ë° ì •ì±…ì„ ì„¤ì •í•´ì•¼ í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ë¹„ê´€ë¦¬í˜• ë…¸ë“œ ê·¸ë£¹ì„ í†µí•´ êµ¬ì„±í•˜ëŠ” ê²½ìš°ê°€ ë§ìœ¼ë©° spotì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ì˜ˆì— ëŒ€í•´ ì´í•´ê°€ í•„ìš”í•˜ë‹¤. ì•„ë˜ëŠ” ê³µì‹ ë¬¸ì„œì—ì„œ ì œê³µí•˜ëŠ” ì˜ˆë¥¼ ì´í•´í•˜ê¸° ìœ„í•´ ì‘ì„±í•˜ì˜€ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 # 50% ìŠ¤íŒŸ ì¸ìŠ¤í„´ìŠ¤ì™€ 50% ì˜¨ë””ë§¨ë“œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ë…¸ë“œ ê·¸ë£¹ nodeGroups: - name: ng-1 minSize: 2 maxSize: 5 instancesDistribution: maxPrice: 0.017 instanceTypes: [\u0026#34;t3.small\u0026#34;, \u0026#34;t3.medium\u0026#34;] # At least one instance type should be specified onDemandBaseCapacity: 0 # í•­ìƒ ì‚¬ìš© ê°€ëŠ¥í•œ ìµœì†Œ ì˜¨ë””ë§¨ë“œ ì¸ìŠ¤í„´ìŠ¤ ìˆ˜ onDemandPercentageAboveBaseCapacity: 50 # ì´ˆê³¼í•˜ëŠ” ì¸ìŠ¤í„´ìŠ¤ì— ëŒ€í•´ ì˜¨ë””ë§¨ë“œ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‚¬ìš©í•  ë¹„ìœ¨ì„ ì„¤ì •(ë°±ë¶„ìœ¨) spotInstancePools: 2 # ì¸ìŠ¤í„´ìŠ¤ ìœ í˜•ê³¼ ê°€ìš© ì˜ì—­ í’€ ì„¤ì • ì œí•œ # GPU ì¸ìŠ¤í„´ìŠ¤ë„ Spot ì¸ìŠ¤í„´ìŠ¤ë¡œ ì‚¬ìš©ê°€ëŠ¥í•˜ë‹¤. nodeGroups: - name: ng-gpu instanceType: mixed desiredCapacity: 1 instancesDistribution: instanceTypes: - p2.xlarge - p2.8xlarge - p2.16xlarge maxPrice: 0.50 # capacity-optimized ìš©ëŸ‰ ìµœì í™” ì „ëµìœ¼ë¡œ í• ë‹¹ nodeGroups: - name: ng-capacity-optimized minSize: 2 maxSize: 5 instancesDistribution: maxPrice: 0.017 instanceTypes: [\u0026#34;t3.small\u0026#34;, \u0026#34;t3.medium\u0026#34;] # At least one instance type should be specified onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 50 spotAllocationStrategy: \u0026#34;capacity-optimized\u0026#34; # capacity-optimized ìš©ëŸ‰ ìµœì í™” ì „ëµìœ¼ë¡œ í• ë‹¹(ìš°ì„ ìˆœìœ„ë¡œ ì¸ìŠ¤í„´ìŠ¤ íƒ€ì…ì—ì„œ ì²« ë²ˆì§¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ìš°ì„ ìˆœìœ„ë¡œ ì„ íƒëœë‹¤.) nodeGroups: - name: ng-capacity-optimized-prioritized minSize: 2 maxSize: 5 instancesDistribution: maxPrice: 0.017 instanceTypes: [\u0026#34;t3a.small\u0026#34;, \u0026#34;t3.small\u0026#34;] # At least two instance types should be specified onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 0 spotAllocationStrategy: \u0026#34;capacity-optimized-prioritized\u0026#34; ë…¸ë“œ ê·¸ë£¹ì„ ë°°í¬í•˜ë©´ AWS ì½˜ì†”ì—ì„œ ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n1 eksctl create ng --cluster my-eks -f spot-ng.yaml ë°°í¬í•œì§€ 30ë¶„ì´ ì§€ë‚¬ì§€ë§Œ í•˜ë‚˜ì˜ ì¸ìŠ¤í„´ìŠ¤ê°€ ì‹¤í–‰ë˜ì—ˆë‹¤ê°€ ì¤‘ë‹¨ë˜ì—ˆê³  ë˜ ë‹¤ë¥¸ ì¸ìŠ¤í„´ìŠ¤ê°€ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n[ì ˆê°ì•¡ ìš”ì•½] ì—ì„œ í•„ìê°€ ì„¤ì •í•œ ì¸ìŠ¤í„´ìŠ¤ë¡œ ì–¼ë§ˆê°€ ì ˆê°ë˜ì—ˆëŠ”ì§€ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nì˜¤ì˜¤ 72í¼ì„¼íŠ¸ë‚˜..! ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•˜ì!\nSpot ì¸ìŠ¤í„´ìŠ¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œí•œ kubeflow ì¸í”„ë¼ êµ¬ì„±í•˜ê¸° Spot ì¸ìŠ¤í„´ìŠ¤ê°€ ê°€ì ¸ì˜¤ëŠ” ë¹„ìš© ì ˆê°ì„ í†µí•´ ì¿ ë²„ë„¤í‹°ìŠ¤ ë¨¸ì‹ ëŸ¬ë‹ í”Œë«í¼ì¸ kubeflow ì¸í”„ë¼ë¥¼ êµ¬ì„±í•˜ê² ë‹¤. êµ³ì´ ë¨¸ì‹ ëŸ¬ë‹ í”Œë«í¼ì„ ì •í•œ ì´ìœ ëŠ” GPU ì¸ìŠ¤í„´ìŠ¤ ì‚¬ìš© ë¹„ìš©ì„ ìµœëŒ€í•œìœ¼ë¡œ ì ˆê°í•˜ê³  ìì› ì‚¬ìš©ì„ ìµœì í™”ì‹œì¼œì¤„ ìˆ˜ ìˆì–´ì„œ ì„ íƒí•˜ì˜€ë‹¤. eksctl ê³µì‹ ì˜ˆì—ì„œë„ kubeflowì— ëŒ€í•œ ì¸í”„ë¼ êµ¬ì„±ì„ ì˜ˆë¡œ ì œê³µí•˜ê³  ìˆë‹¤. í•´ë‹¹ ì˜ˆë¥¼ ê°€ì§€ê³  ë¦¬ì „ ë° ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³€ê²½í•˜ì—¬ kubeflow ì¸í”„ë¼ë¥¼ êµ¬ì„±í•´ë³´ê² ë‹¤. ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\nGPU ì¸ìŠ¤í„´ìŠ¤(pxë¡œ ì‹œì‘)ë§Œ Spot ì¸ìŠ¤í„´ìŠ¤ë¡œ í• ë‹¹í•˜ì˜€ë‹¤. ìµœì†Œ 0ê°œë¶€í„° ì‹œì‘í•˜ì—¬ í•„ìš”í•  ë•Œë§Œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ í•˜ì—¬ ë¹„ìš©ì„ ì ˆê°í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•˜ì˜€ë‹¤. GPU ì¸ìŠ¤í„´ìŠ¤ì˜ ë¹„ìš©ì„ í™•ì¸í•˜ë©´ ìƒë‹¹íˆ ë¹„ì‹¼ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° ì„œìš¸ ë¦¬ì „ ê¸°ì¤€ p2.xlarge1.465Â USD, p3.2xlarge4.234Â USD ì´ë‹¤. ì•½ ì ˆë°˜ ê¸°ì¤€ì˜ ë¹„ìš©ì„ ì‚°ì •í•´ì„œ Spot ì¸ìŠ¤í„´ìŠ¤ì˜ ë¹„ìš©ì„ ì„¤ì •í•˜ì˜€ë‹¤. ê°€ìš© ì˜ì—­ì„ ap-northeast-2a ì—ë§Œ ì„¤ì •í•œ ì´ìœ ëŠ” ë„¤íŠ¸ì›Œí¬ ì§€ì—° ìµœì†Œí™” ë•Œë¬¸ì´ë‹¤. ë¨¸ì‹ ëŸ¬ë‹ì—ì„œ ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì„ ìµœì†Œí™”í•˜ê¸°ìœ„í•¨ì´ë©° ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬ë¡œë“œ íŠ¹ì„±ìƒ ê³ ê°€ìš©ì„±ì„ ê³ ë ¤í•˜ì§€ ì•Šì•˜ë‹¤. ì•„í‚¤í…ì²˜ë¡œ ë² ìŠ¤ì²œ ì„œë²„ì™€ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•  ê²ƒì´ë‹¤. ë² ìŠ¤ì²œ ì„œë²„ëŠ” cloudformation ì„ í†µí•œ EC2 ì„œë²„ë¡œ ìƒì„±í•˜ê³ , EKS í´ëŸ¬ìŠ¤í„°ëŠ” eksctl êµ¬ì¶•í•˜ê² ë‹¤. ë² ìŠ¤ì²œ ì„œë²„ì˜ cloudformation ì½”ë“œëŠ” í•„ìì˜ ê¹ƒí—ˆë¸Œ repo ë¥¼ ì°¸ê³ í•˜ì—¬ ë°°í¬í•˜ì. ì¤‘ìš”í•œ ì ì€ amië¥¼ ubuntu ì§€ì •í•˜ì˜€ëŠ”ë° kubeflow ì„¤ì¹˜ë¥¼ ìœ„í•´ì„œëŠ” ì„¤ì¹˜ í™˜ê²½ì´ ubuntuì´ì—¬ë§Œ í•œë‹¤.\nhttps://awslabs.github.io/kubeflow-manifests/docs/deployment/prerequisites/\nì´ë¥¼ ìœ„í•´ ë² ìŠ¤ì²œ ì„œë²„ë¥¼ ubuntuë¡œ êµ¬ì„±í•˜ì˜€ë‹¤.\në‹¤ìŒì€ eksctl ë¥¼ í†µí•´ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ê² ë‹¤. êµ¬ì„± yaml íŒŒì¼ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168 169 170 171 172 173 174 175 176 177 178 179 180 181 182 183 184 185 186 187 188 189 190 191 192 193 194 195 196 197 198 199 200 201 202 203 204 205 206 207 208 209 210 211 212 213 214 215 216 217 218 219 220 221 222 223 224 225 226 227 228 229 230 # Cost-Optimized EKS cluster for Kubeflow with spot GPU instances and node scale down to zero # Built in efforts to reducing training costs of ML workloads. # Supporting tutorial can be found at the following link: # https://blog.gofynd.com/how-we-reduced-our-ml-training-costs-by-78-a33805cb00cf # This spec creates a cluster on EKS with the following active nodes # - 2x m5a.2xlarge - Accomodates all pods of Kubeflow # It also creates the following nodegroups with 0 nodes running unless a pod comes along and requests for the node to get spun up # - m5a.2xlarge -- Max Allowed 10 worker nodes # - p2.xlarge -- Max Allowed 10 worker nodes # - p3.2xlarge -- Max Allowed 10 worker nodes # - p3.8xlarge -- Max Allowed 04 worker nodes # - p3dn.24xlarge -- Max Allowed 01 worker nodes apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: # Name of your cluster, change to whatever you find fit. # If changed, make sure to change all nodegroup tags from # \u0026#39;k8s.io/cluster-autoscaler/my-eks-kubeflow: \u0026#34;owned\u0026#34;\u0026#39; --\u0026gt; \u0026#39;k8s.io/cluster-autoscaler/your-new-name: \u0026#34;owned\u0026#34;\u0026#39; name: my-eks-kubeflow # choose your region wisely, this will significantly impact the cost incurred region: ap-northeast-2 # 1.14 Kubernetes version since Kubeflow 1.0 officially supports the same version: \u0026#39;1.25\u0026#39; tags: # Add more cloud tags if needed for billing environment: staging # Add all possible AZs to ensure nodes can be spun up in any AZ later on. # THIS CAN\u0026#39;T BE CHANGED LATER. YOU WILL HAVE TO CREATE A NEW CLUSTER TO ADD NEW AZ SUPPORT. # This list applies to the whole cluster and isn\u0026#39;t specific to nodegroups vpc: id: vpc-04686564a10b92c9c cidr: 192.168.0.0/16 securityGroup: sg-0ea8529af823353e9 nat: gateway: HighlyAvailable subnets: public: public-2a: id: subnet-03eeb6d32aa5397bf cidr: 192.168.1.0/24 public-2c: id: subnet-023bc1a3fce0cde07 cidr: 192.168.2.0/24 private: private-2a: id: subnet-02c160be5273d5171 cidr: 192.168.3.0/24 private-2c: id: subnet-018a370a44f973ac4 cidr: 192.168.4.0/24 iam: withOIDC: true nodeGroups: - name: ng-1 desiredCapacity: 4 minSize: 0 maxSize: 10 # Set one nodegroup with 100GB volumes for Kubeflow to get deployed. # Kubeflow requirement states 1-2 Nodes with 100GB volume attached to the node. volumeSize: 100 volumeType: gp2 instanceType: c5n.xlarge privateNetworking: true ssh: publicKeyName: eks-terraform-key availabilityZones: - ap-northeast-2a labels: node-class: \u0026#34;worker-node\u0026#34; tags: # EC2 tags required for cluster-autoscaler auto-discovery k8s.io/cluster-autoscaler/node-template/label/lifecycle: OnDemand k8s.io/cluster-autoscaler/node-template/label/aws.amazon.com/spot: \u0026#34;false\u0026#34; k8s.io/cluster-autoscaler/node-template/label/gpu-count: \u0026#34;0\u0026#34; k8s.io/cluster-autoscaler/enabled: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/my-eks-kubeflow: \u0026#34;owned\u0026#34; iam: withAddonPolicies: awsLoadBalancerController: true autoScaler: true cloudWatch: true efs: true ebs: true externalDNS: true - name: 1-gpu-spot-p2-xlarge minSize: 0 maxSize: 10 instancesDistribution: # set your own max price. AWS spot instance prices no longer cross OnDemand price. # Comment out the field to default to OnDemand as max price. maxPrice: 0.7 instanceTypes: [\u0026#34;p2.xlarge\u0026#34;] onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 0 spotAllocationStrategy: capacity-optimized labels: lifecycle: Ec2Spot aws.amazon.com/spot: \u0026#34;true\u0026#34; gpu-count: \u0026#34;1\u0026#34; # Stick to one AZ for all GPU nodes. # In case of termination, this will prevent volumes from being unavailable # if the new instance got spun up in another AZ. privateNetworking: true ssh: publicKeyName: eks-terraform-key availabilityZones: - ap-northeast-2a taints: - key: spotInstance value: \u0026#34;true\u0026#34; effect: PreferNoSchedule tags: k8s.io/cluster-autoscaler/node-template/label/lifecycle: Ec2Spot k8s.io/cluster-autoscaler/node-template/label/aws.amazon.com/spot: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/node-template/label/gpu-count: \u0026#34;1\u0026#34; k8s.io/cluster-autoscaler/node-template/taint/spotInstance: \u0026#34;true:PreferNoSchedule\u0026#34; k8s.io/cluster-autoscaler/enabled: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/my-eks-kubeflow: \u0026#34;owned\u0026#34; iam: withAddonPolicies: autoScaler: true cloudWatch: true awsLoadBalancerController: true efs: true ebs: true externalDNS: true - name: 1-gpu-spot-p3-2xlarge minSize: 0 maxSize: 10 instancesDistribution: # set your own max price. AWS spot instance prices no longer cross OnDemand price. # Comment out the field to default to OnDemand as max price. maxPrice: 2.0 instanceTypes: [\u0026#34;p3.2xlarge\u0026#34;] onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 0 spotAllocationStrategy: capacity-optimized labels: lifecycle: Ec2Spot aws.amazon.com/spot: \u0026#34;true\u0026#34; gpu-count: \u0026#34;1\u0026#34; # Stick to one AZ for all GPU nodes. # In case of termination, this will prevent volumes from being unavailable # if the new instance got spun up in another AZ. privateNetworking: true ssh: publicKeyName: eks-terraform-key availabilityZones: - ap-northeast-2a taints: - key: spotInstance value: \u0026#34;true\u0026#34; effect: PreferNoSchedule tags: k8s.io/cluster-autoscaler/node-template/label/lifecycle: Ec2Spot k8s.io/cluster-autoscaler/node-template/label/aws.amazon.com/spot: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/node-template/label/gpu-count: \u0026#34;1\u0026#34; k8s.io/cluster-autoscaler/node-template/taint/spotInstance: \u0026#34;true:PreferNoSchedule\u0026#34; k8s.io/cluster-autoscaler/enabled: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/my-eks-kubeflow: \u0026#34;owned\u0026#34; iam: withAddonPolicies: autoScaler: true cloudWatch: true awsLoadBalancerController: true efs: true ebs: true externalDNS: true - name: 4-gpu-spot-p3-8xlarge minSize: 0 maxSize: 4 instancesDistribution: # set your own max price. AWS spot instance prices no longer cross OnDemand price. # Comment out the field to default to OnDemand as max price. maxPrice: 4.4 instanceTypes: [\u0026#34;p3.8xlarge\u0026#34;] onDemandBaseCapacity: 0 onDemandPercentageAboveBaseCapacity: 0 spotAllocationStrategy: capacity-optimized labels: lifecycle: Ec2Spot aws.amazon.com/spot: \u0026#34;true\u0026#34; gpu-count: \u0026#34;4\u0026#34; # Stick to one AZ for all GPU nodes. # In case of termination, this will prevent volumes from being unavailable # if the new instance got spun up in another AZ. privateNetworking: true ssh: publicKeyName: eks-terraform-key availabilityZones: - ap-northeast-2a taints: - key: spotInstance value: \u0026#34;true\u0026#34; effect: PreferNoSchedule tags: k8s.io/cluster-autoscaler/node-template/label/lifecycle: Ec2Spot k8s.io/cluster-autoscaler/node-template/label/aws.amazon.com/spot: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/node-template/label/gpu-count: \u0026#34;4\u0026#34; k8s.io/cluster-autoscaler/node-template/taint/spotInstance: \u0026#34;true:PreferNoSchedule\u0026#34; k8s.io/cluster-autoscaler/enabled: \u0026#34;true\u0026#34; k8s.io/cluster-autoscaler/my-eks-kubeflow: \u0026#34;owned\u0026#34; iam: withAddonPolicies: autoScaler: true cloudWatch: true awsLoadBalancerController: true efs: true ebs: true externalDNS: true addons: - name: vpc-cni # no version is specified so it deploys the default version version: v1.12.6-eksbuild.1 attachPolicyARNs: - arn:aws:iam::aws:policy/AmazonEKS_CNI_Policy - name: kube-proxy version: latest # auto discovers the latest available - name: coredns version: latest # v1.9.3-eksbuild.2 withAddonPolicies ì •ì±…ì—ì„œ efs: true ê°€ ì¶”ê°€ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° ë¨¸ì‹ ëŸ¬ë‹ì˜ ë°ì´í„° ì…‹ì„ ê³µìœ  ìŠ¤í† ë¦¬ì§€ë¡œ í™œìš©í•˜ì—¬ ëª¨ë¸ í›ˆë ¨ ë° ì¶”ë¡ ì— ëŒ€í•œ ë” ë‚˜ì€ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆê¸° ë•Œë¬¸ì— ì¶”ê°€í•˜ì˜€ë‹¤. eksctlë¥¼ í†µí•´ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ì.\n1 eksctl create cluster -f kubeflow-infra.yaml ì•½ 20ë¶„ ì •ë„ ì†Œìš”ëœë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 root@hanhorang:/home/ubuntu/blog-share/aews-eksctl/example# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-6xqcv 1/1 Running 0 94s kube-system aws-node-dtm6v 1/1 Running 0 94s kube-system aws-node-kn5fj 1/1 Running 0 94s kube-system aws-node-s7grj 1/1 Running 0 94s kube-system coredns-595d647554-f7576 1/1 Running 0 27s kube-system coredns-595d647554-jzvlg 1/1 Running 0 27s kube-system kube-proxy-r9csf 1/1 Running 0 94s kube-system kube-proxy-thglh 1/1 Running 0 94s kube-system kube-proxy-txzr4 1/1 Running 0 94s kube-system kube-proxy-zltl2 1/1 Running 0 94s kube-system nvidia-device-plugin-daemonset-4p24p 1/1 Running 0 73s kube-system nvidia-device-plugin-daemonset-67275 1/1 Running 0 59s kube-system nvidia-device-plugin-daemonset-kmh95 1/1 Running 0 61s kube-system nvidia-device-plugin-daemonset-kzhtv 1/1 Running 0 72s í•´ë‹¹ íŒŒë“œê°€ GPU ë…¸ë“œì—ë§Œ ë°°ì¹˜ë  ìˆ˜ ìˆë„ë¡ ë°ëª¬ì…‹ì„ ìˆ˜ì •í•  ê²ƒì´ë‹¤. ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ìˆ˜ì •í•˜ì.\n1 kubectl edit daemonset/nvidia-device-plugin-daemonset -n kube-system 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 spec: revisionHistoryLimit: 10 selector: matchLabels: name: nvidia-device-plugin-ds template: metadata: annotations: scheduler.alpha.kubernetes.io/critical-pod: \u0026#34;\u0026#34; creationTimestamp: null labels: name: nvidia-device-plugin-ds spec: nodeSelector: # ì¶”ê°€ gpu-count: \u0026#34;\u0026#34; #ì¶”ê°€ ìˆ˜ì • í›„ ì •ìƒì ìœ¼ë¡œ íŒŒë“œ ì—ëŸ¬ê°€ ì‚¬ë¼ì§„ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (terraform-eks@my-eks-kubeflow:N/A) [root@myeks-host example]# kubectl edit daemonset/nvidia-device-plugin-daemonset -n kube-system daemonset.apps/nvidia-device-plugin-daemonset edited (terraform-eks@my-eks-kubeflow:N/A) [root@hanhorang example]# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-9x5kp 1/1 Running 0 10m kube-system aws-node-bf4lw 1/1 Running 0 10m kube-system aws-node-v7gs6 1/1 Running 0 10m kube-system aws-node-wv9qj 1/1 Running 0 10m kube-system aws-node-xjwss 1/1 Running 0 10m kube-system coredns-595d647554-nlfv2 1/1 Running 0 10m kube-system coredns-595d647554-zx92r 1/1 Running 0 10m kube-system kube-proxy-24wxv 1/1 Running 0 10m kube-system kube-proxy-4dh4j 1/1 Running 0 10m kube-system kube-proxy-qp9xk 1/1 Running 0 10m kube-system kube-proxy-xcfqz 1/1 Running 0 10m kube-system kube-proxy-zvn2j 1/1 Running 0 10m kubeflow ë°°í¬ ì• ê³¼ì •ì—ì„œ êµ¬ì„±í•œ EKS í´ëŸ¬ìŠ¤í„°ì— kubeflowë¥¼ ë°°í¬í•˜ê² ë‹¤. ë°°í¬í•˜ê¸° ì „ kubeflowê°€ ë¬´ì—‡ì´ê³  ì•„í‚¤í…ì²˜ê°€ ë¬´ì—‡ì¸ì§€ ê°„ë‹¨í•˜ê²Œ í™•ì¸í•˜ê³  ë„˜ì–´ê°€ê² ë‹¤.\nê³µì‹ë¬¸ì„œì— ë”°ë¥´ë©´ kubeflowëŠ” ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ì˜ ML í”Œë«í¼ì´ë‹¤. í”Œë«í¼ì´ë¼ëŠ” ë§ì´ ì¤‘ìš”í•œ ë°, ë‹¤ë¥¸ ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤ë¥¼ ë§Œë“œëŠ” ê²ƒì´ ì•„ë‹ˆë¼, ì˜¤í”ˆì†ŒìŠ¤ ê¸°ë°˜ì˜ ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤ì„ í•©ì³ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œë¥¼ ê°„ì†Œí™” ì‹œì¼œì£¼ëŠ” í”Œë«í¼ ì„œë¹„ìŠ¤ë¡œ ì œê³µí•œë‹¤ëŠ” ì˜ë¯¸ì´ë‹¤.\nhttps://www.kubeflow.org/\nì–´ë–¤ ë¨¸ì‹ ëŸ¬ë‹ ì˜¤í”ˆì†ŒìŠ¤ë¥¼ ì‚¬ìš©í•˜ëŠ” ì§€ëŠ” ì•„í‚¤í…ì²˜ë¥¼ ë³´ë©´ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”ë‚˜ ë¡œì»¬ì¸ ì¿ ë²„ë„¤í‹°ìŠ¤ ìœ„ì—ì„œ ë‹¤ì–‘í•œ ë¨¸ì‹ ëŸ¬ë‹ ì„œë¹„ìŠ¤ ë° addon ì„œë¹„ìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ ì›Œí¬í”Œë¡œë¥¼ êµ¬ì„±í•œë‹¤ê³  ì´í•´í•˜ì.\nhttps://www.kubeflow.org/docs/started/architecture/\në¨¸ì‹ ëŸ¬ë‹ ì»´í¬ë„ŒíŠ¸ê°€ ë§ì•„ ì„¸ë¶€ì ìœ¼ë¡œëŠ” í™•ì¸í•  ìˆ˜ê°€ ì—†ê³  í° êµ¬ì„± ë³„ë¡œ í™•ì¸í•˜ê² ë‹¤.\nML tools: ë¨¸ì‹ ëŸ¬ë‹ ë„êµ¬ë“¤ì€ ë°ì´í„° ì „ì²˜ë¦¬, ëª¨ë¸ í•™ìŠµ, í‰ê°€, ìµœì í™” ë° ë°°í¬ì™€ ê°™ì€ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œë¥¼ ì§€ì›í•˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° í”„ë ˆì„ì›Œí¬ì´ë‹¤. Kubeflow applications and scaffolding: Kubeflow ì• í”Œë¦¬ì¼€ì´ì…˜ ë° ìŠ¤ìºí´ë”©ì€ Kubeflow í”Œë«í¼ì—ì„œ ì œê³µí•˜ëŠ” ê¸°ë³¸ ë¼ˆëŒ€ì™€ ë„êµ¬ë“¤ë¡œ, ì‚¬ìš©ìê°€ ë¨¸ì‹ ëŸ¬ë‹ ì›Œí¬í”Œë¡œë¥¼ ì‰½ê²Œ êµ¬ì¶•í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì§€ì›í•œë‹¤. ë¨¸ì‹ ëŸ¬ë‹ ì˜¤í”ˆì†ŒìŠ¤ ë¿ë§Œ ì•„ë‹ˆë¼ istio, prometheus, argo ë“±ì˜ ì˜¤í”ˆì†ŒìŠ¤ê°€ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° í•´ë‹¹ ì„œë¹„ìŠ¤ë¥¼ ê²°í•©í•˜ì—¬ ëŒ€ì‹œë³´ë“œ, ì„œë¹„ìŠ¤ ë©”ì‹œ, íŒŒì´í”„ë¼ì¸ êµ¬ì„±ì— ì‚¬ìš©ëœë‹¤. kubeflow ë°°í¬ ì „ ì‘ì—…ìœ¼ë¡œ ë²„ì „ í™•ì¸ ë° í•„ìš” addon ì„¤ì¹˜ê°€ í•„ìš”í•˜ë‹¤. 23ë…„ 5ì›” ê¸°ì¤€ EKS ë²„ì „ ì œê³µë³„ kubeflow ë²„ì „ ì§€ì›ì€ ë‹¤ìŒì˜ ê·¸ë¦¼ì„ í†µí•´ ì°¸ê³ í•˜ì. í•„ìì˜ EKS ë²„ì „ì€ 1.25ë¡œ kubeflow 1.7ë¥¼ ì„¤ì¹˜í•˜ê² ë‹¤.\në‹¤ìŒ ê³¼ì •ìœ¼ë¡œ í•„ìš” íŒ¨í‚¤ì§€ ë° addon ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì. íŒ¨í‚¤ì§€ì˜ ê²½ìš° ê³µì‹ ë¬¸ì„œì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ì‰½ê²Œ ì„¤ì¹˜ê°€ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 4 5 export KUBEFLOW_RELEASE_VERSION=v1.7.0 export AWS_RELEASE_VERSION=v1.7.0-aws-b1.0.0 git clone https://github.com/awslabs/kubeflow-manifests.git \u0026amp;\u0026amp; cd kubeflow-manifests git checkout ${AWS_RELEASE_VERSION} git clone --branch ${KUBEFLOW_RELEASE_VERSION} https://github.com/kubeflow/manifests.git upstream 1 2 # íŒ¨í‚¤ì§€ ì„¤ì¹˜ ëª…ë ¹ì–´ make install-tools ì„¤ì¹˜ ì¤‘ íŒŒì´ì¬ í•„ìš” íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤. ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ í•´ê²°í•˜ì.\n1 2 3 pip install --ignore-installed PyYAML==5.3.1 pip3 install testresources python3.8 -m pip install -r tests/e2e/requirements.txt íŒ¨í‚¤ì§€ ì„¤ì¹˜ í›„, EKS addonì¸ EBS csi driver ì„¤ì¹˜ê°€ í•„ìš”í•˜ë‹¤.\nEBS csi driverì€ AWS ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤. EBS ë³¼ë¥¨ ê´€ë¦¬ë¥¼ ìœ„í•œ IAM ì •ì±… ë° ë¡¤ ìƒì„±ê³¼ ë“œë¼ì´ë²„ ë°°í¬ ê³¼ì •ìœ¼ë¡œ ì§„í–‰í•˜ì˜€ë‹¤.\n1 2 # OIDC í™•ì¸ aws eks describe-cluster --name my-eks-kubeflow --query \u0026#34;cluster.identity.oidc.issuer\u0026#34; --output text ê²°ê³¼ì—ì„œ regionê³¼ oidc ë²ˆí˜¸ë¥¼ ë©”ëª¨í•˜ì. ì•„ë˜ IAM ì •ì±… êµ¬ì„±ì— ê¸°ì…ì´ í•„ìš”í•˜ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # vi aws-ebs-csi-driver-trust-policy.json { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Principal\u0026#34;: { \u0026#34;Federated\u0026#34;: \u0026#34;arn:aws:iam::955963799952:oidc-provider/oidc.eks.ap-northeast-2.amazonaws.com/id/D378D41514C8714C26A69DF6ECC0A999\u0026#34; }, \u0026#34;Action\u0026#34;: \u0026#34;sts:AssumeRoleWithWebIdentity\u0026#34;, \u0026#34;Condition\u0026#34;: { \u0026#34;StringEquals\u0026#34;: { \u0026#34;oidc.eks.ap-northeast-2.amazonaws.com/id/D378D41514C8714C26A69DF6ECC0A999:aud\u0026#34;: \u0026#34;sts.amazonaws.com\u0026#34;, \u0026#34;oidc.eks.ap-northeast-2.amazonaws.com/id/D378D41514C8714C26A69DF6ECC0A999:sub\u0026#34;: \u0026#34;system:serviceaccount:kube-system:ebs-csi-controller-sa\u0026#34; } } } ] } 1 2 3 4 5 6 7 8 9 # ë¡¤ ìƒì„± aws iam create-role \\ --role-name AmazonEKS_EBS_CSI_DriverRole \\ --assume-role-policy-document file://\u0026#34;aws-ebs-csi-driver-trust-policy.json\u0026#34; # ì •ì±… attach aws iam attach-role-policy \\ --policy-arn arn:aws:iam::aws:policy/service-role/AmazonEBSCSIDriverPolicy \\ --role-name AmazonEKS_EBS_CSI_DriverRole ì •ì±… attachê¹Œì§€ ì™„ë£Œí•˜ì˜€ìœ¼ë©´ í•´ë‹¹ ì •ì±…ì„ ì¿ ë²„ë„¤í‹°ìŠ¤ ë‚´ì—ì„œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ ì‚¬ìš©ì ì–´ì¹´ìš´íŠ¸ì— ì—°ë™ì´ í•„ìš”í•˜ë‹¤.\n1 2 3 4 5 6 # sa ìƒì„± kubectl create sa ebs-csi-controller-sa -n kube-system # Role annotation kubectl annotate serviceaccount ebs-csi-controller-sa \\ -n kube-system \\ eks.amazonaws.com/role-arn=arn:aws:iam::955963799952:role/AmazonEKS_EBS_CSI_DriverRole ì—°ë™ì´ ëë‚¬ìœ¼ë©´ EBS ë“œë¼ì´ë²„ë¥¼ ë°°í¬í•˜ì, í•„ìì˜ ê²½ìš° eksctlë¥¼ í†µí•´ ì§„í–‰í•˜ì˜€ë‹¤.\n1 2 aws eks create-addon --cluster-name my-eks-kubeflow --addon-name aws-ebs-csi-driver \\ --service-account-role-arn arn:aws:iam::955963799952:role/AmazonEKS_EBS_CSI_DriverRole 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 root@hanhorang:/home/ubuntu/blog-share/aews-eksctl/example# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-6xqcv 1/1 Running 0 7m46s kube-system aws-node-dtm6v 1/1 Running 0 7m46s kube-system aws-node-kn5fj 1/1 Running 0 7m46s kube-system aws-node-s7grj 1/1 Running 0 7m46s kube-system coredns-595d647554-f7576 1/1 Running 0 6m39s kube-system coredns-595d647554-jzvlg 1/1 Running 0 6m39s kube-system ebs-csi-controller-b576f46c5-2c5sk 5/6 Running 0 16s kube-system ebs-csi-controller-b576f46c5-ffwnk 5/6 Running 0 16s kube-system ebs-csi-node-6tpm6 3/3 Running 0 16s kube-system ebs-csi-node-djrc4 3/3 Running 0 16s kube-system ebs-csi-node-qtngl 3/3 Running 0 16s kube-system ebs-csi-node-thbfc 3/3 Running 0 16s kube-system kube-proxy-r9csf 1/1 Running 0 7m46s kube-system kube-proxy-thglh 1/1 Running 0 7m46s kube-system kube-proxy-txzr4 1/1 Running 0 7m46s kube-system kube-proxy-zltl2 1/1 Running 0 7m46s kube-system nvidia-device-plugin-daemonset-4p24p 1/1 Running 0 7m25s kube-system nvidia-device-plugin-daemonset-67275 1/1 Running 0 7m11s kube-system nvidia-device-plugin-daemonset-kmh95 1/1 Running 0 7m13s kube-system nvidia-device-plugin-daemonset-kzhtv 1/1 Running 0 7m24 ìŠ¤í† ë¦¬ì§€ addon ë°°í¬ ì´í›„ PVCì˜ Default ìŠ¤í† ë¦¬ì§€í´ë˜ìŠ¤ ì§€ì •ì´ í•„ìš”í•˜ë‹¤. ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ë¥¼ ìƒì„±í•˜ê³  ê¸°ë³¸ í´ë˜ìŠ¤ ì„¤ì •ì„ ì§„í–‰í•˜ì.\n1 2 3 4 5 6 7 8 9 # ebs-sc.yaml apiVersion: storage.k8s.io/v1 kind: StorageClass metadata: name: ebs-sc annotations: storageclass.kubernetes.io/is-default-class: \u0026#34;true\u0026#34; provisioner: ebs.csi.aws.com volumeBindingMode: WaitForFirstConsumer 1 2 3 4 # ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ë°°í¬ kubectl apply -f ebs-sc.yaml # ê¸°ë³¸ í´ë˜ìŠ¤ ìˆ˜ì • kubectl patch storageclass gp2 -p \u0026#39;{\u0026#34;metadata\u0026#34;: {\u0026#34;annotations\u0026#34;:{\u0026#34;storageclass.kubernetes.io/is-default-class\u0026#34;:\u0026#34;false\u0026#34;}}}\u0026#39; ë§ˆì§€ë§‰ìœ¼ë¡œ kubeflow ë°°í¬ë¥¼ ì§„í–‰í•˜ê² ë‹¤. ë°°í¬ëŠ” ì•ì„œ ê¹ƒìœ¼ë¡œ í´ë¡ í•œ ë ˆíŒŒì§€í† ë¦¬ì— ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ ëª…ë ¹ì–´ë¥¼ í†µí•´ ì§„í–‰í•˜ê² ë‹¤.\n1 2 3 4 5 export CLUSTER_NAME=my-eks-kubeflow export CLUSTER_REGION=ap-northeast-2 # ì„¤ì¹˜ ëª…ë ¹ì–´ make deploy-kubeflow INSTALLATION_OPTION=kustomize DEPLOYMENT_OPTION=vanilla 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 ... All istio pods are running! ==========Installing dex========== Release \u0026#34;dex\u0026#34; does not exist. Installing it now. NAME: dex LAST DEPLOYED: Tue May 2 22:47:51 2023 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Waiting for dex pods to be ready ... running command: kubectl wait --for=condition=ready pod -l \u0026#39;app in (dex)\u0026#39; --timeout=240s -n auth pod/dex-56d9748f89-99ggv condition met All dex pods are running! ==========Installing oidc-authservice========== Release \u0026#34;oidc-authservice\u0026#34; does not exist. Installing it now. NAME: oidc-authservice LAST DEPLOYED: Tue May 2 22:48:01 2023 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Waiting for oidc-authservice pods to be ready ... running command: kubectl wait --for=condition=ready pod -l \u0026#39;app in (authservice)\u0026#39; --timeout=240s -n istio-system error: timed out waiting for the condition on pods/authservice-0 Waiting for oidc-authservice pods to be ready ... running command: kubectl wait --for=condition=ready pod -l \u0026#39;app in (authservice)\u0026#39; --timeout=240s -n istio-system error: timed out waiting for the condition on pods/authservice-0 Waiting for oidc-authservice pods to be ready ... running command: kubectl wait --for=condition=ready pod -l \u0026#39;app in (authservice)\u0026#39; --timeout=240s -n istio-system ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ êµ¬ì„± ìš”ì†Œë“¤ì´ ì„¤ì¹˜ëœë‹¤. ì•½ 5ë¶„ì •ë„ ì†Œìš”ëœë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 root@hanhorang:/home/ubuntu/blog-share/aews-eksctl/kubeflow-manifests# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE ack-system ack-sagemaker-controller-5667d978b-xhnmn 0/1 Error 4 (56s ago) 105s auth dex-56d9748f89-nk54k 1/1 Running 0 34m cert-manager cert-manager-74d949c895-25bt6 1/1 Running 0 35m cert-manager cert-manager-cainjector-d9bc5979d-m6kt8 1/1 Running 0 35m cert-manager cert-manager-webhook-84b7ddd796-m6dmp 1/1 Running 0 35m istio-system authservice-0 1/1 Running 0 34m istio-system cluster-local-gateway-6955b67f54-tlhp9 1/1 Running 0 8m16s istio-system istio-ingressgateway-67f7b5f88d-n6whr 1/1 Running 0 34m istio-system istiod-56f7cf9bd6-455ht 1/1 Running 0 34m knative-eventing eventing-controller-c6f5fd6cd-mzfzd 1/1 Running 0 7m45s knative-eventing eventing-webhook-79cd6767-pt9dt 1/1 Running 0 7m45s knative-serving activator-67849589d6-m7wlq 2/2 Running 0 8m6s knative-serving autoscaler-6dbcdd95c7-b5tdc 2/2 Running 0 8m6s knative-serving controller-b9b8855b8-ggzrg 2/2 Running 0 8m6s knative-serving domain-mapping-75cc6d667f-vc5hz 2/2 Running 0 8m5s knative-serving domainmapping-webhook-6dfb78c944-s4d5t 2/2 Running 0 8m5s knative-serving net-istio-controller-5fcd96d76f-pqvnt 2/2 Running 0 8m5s knative-serving net-istio-webhook-7ff9fdf999-48d9c 2/2 Running 0 8m5s knative-serving webhook-69cc5b9849-tbn9r 2/2 Running 0 8m5s kube-system aws-node-6xqcv 1/1 Running 0 127m kube-system aws-node-dtm6v 1/1 Running 0 127m kube-system aws-node-kn5fj 1/1 Running 0 127m kube-system aws-node-s7grj 1/1 Running 0 127m kube-system coredns-595d647554-f7576 1/1 Running 0 125m kube-system coredns-595d647554-jzvlg 1/1 Running 0 125m kube-system ebs-csi-controller-b576f46c5-76czd 6/6 Running 0 15m kube-system ebs-csi-controller-b576f46c5-svcbt 6/6 Running 0 15m kube-system ebs-csi-node-57dnr 3/3 Running 0 15m kube-system ebs-csi-node-dcn5z 3/3 Running 0 15m kube-system ebs-csi-node-hbsfg 3/3 Running 0 15m kube-system ebs-csi-node-qhhsm 3/3 Running 0 15m kube-system kube-proxy-r9csf 1/1 Running 0 127m kube-system kube-proxy-thglh 1/1 Running 0 127m kube-system kube-proxy-txzr4 1/1 Running 0 127m kube-system kube-proxy-zltl2 1/1 Running 0 127m kube-system nvidia-device-plugin-daemonset-4p24p 1/1 Running 0 126m kube-system nvidia-device-plugin-daemonset-67275 1/1 Running 0 126m kube-system nvidia-device-plugin-daemonset-kmh95 1/1 Running 0 126m kube-system nvidia-device-plugin-daemonset-kzhtv 1/1 Running 0 126m kubeflow-user-example-com ml-pipeline-ui-artifact-6cb7b9f6fd-jggk2 2/2 Running 0 110s kubeflow-user-example-com ml-pipeline-visualizationserver-7b5889796d-trjjd 2/2 Running 0 110s kubeflow admission-webhook-deployment-6db8bdbb45-7zfzq 1/1 Running 0 5m4s kubeflow cache-server-76cb8f97f9-wqstf 2/2 Running 0 6m25s kubeflow centraldashboard-655c7d894c-vmv5r 2/2 Running 0 6m40s kubeflow jupyter-web-app-deployment-76fbf48ff6-j7tkk 2/2 Running 0 4m55s kubeflow katib-controller-8bb4fdf4f-46zsh 1/1 Running 0 3m6s kubeflow katib-db-manager-f8dc7f465-4z2ch 1/1 Running 0 3m6s kubeflow katib-mysql-db6dc68c-xj6qr 1/1 Running 0 3m6s kubeflow katib-ui-7859bc4c67-khc44 2/2 Running 1 (2m59s ago) 3m6s kubeflow kserve-controller-manager-85b6b6c47d-qxxjp 2/2 Running 0 7m5s kubeflow kserve-models-web-app-99849d9f7-d67hg 2/2 Running 0 6m51s kubeflow kubeflow-pipelines-profile-controller-59ccbd47b9-9k9s4 1/1 Running 0 6m25s kubeflow metacontroller-0 1/1 Running 0 6m23s kubeflow metadata-envoy-deployment-5b6c575b98-rphl6 1/1 Running 0 6m24s kubeflow metadata-grpc-deployment-784b8b5fb4-mmfql 2/2 Running 2 (5m47s ago) 6m24s kubeflow metadata-writer-5899c74595-55kls 2/2 Running 0 6m24s kubeflow minio-65dff76b66-7g4q8 2/2 Running 0 6m24s kubeflow ml-pipeline-cff8bdfff-glgnb 2/2 Running 0 6m24s kubeflow ml-pipeline-persistenceagent-798dbf666f-kwjhf 2/2 Running 0 6m24s kubeflow ml-pipeline-scheduledworkflow-859ff9cf7b-fkskm 2/2 Running 0 6m24s kubeflow ml-pipeline-ui-6d69549787-v2vl6 2/2 Running 0 6m23s kubeflow ml-pipeline-viewer-crd-56f7cfd7d9-phhjn 2/2 Running 1 6m23s kubeflow ml-pipeline-visualizationserver-64447ffc76-zllv2 2/2 Running 0 6m23s kubeflow mysql-c999c6c8-2vhjq 2/2 Running 0 6m23s kubeflow notebook-controller-deployment-84c9bfdf76-r5dc9 2/2 Running 1 (4m33s ago) 4m41s kubeflow profiles-deployment-786df9d89d-mwlsj 3/3 Running 1 (2m4s ago) 2m15s kubeflow tensorboard-controller-deployment-6664b8866f-r6jtv 3/3 Running 1 (2m31s ago) 2m39s kubeflow tensorboards-web-app-deployment-5cb4666798-55j68 2/2 Running 0 2m53s kubeflow training-operator-7589458f95-zvrk9 1/1 Running 0 3m56s kubeflow volumes-web-app-deployment-59cf57d887-r9gt8 2/2 Running 0 4m17s kubeflow workflow-controller-6547f784cd-mzzmw 2/2 Running 1 (6m16s ago) 6m23s ğŸ§Â ë°°í¬ ì¤‘ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\ní•„ìì˜ ê²½ìš° êµ¬ì„± ìš”ì†Œ ì¤‘ oidc-authservice ì—ì„œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì´ ë°œìƒí–ˆë‹¤.\nì´ë²¤íŠ¸ê°€ ì—†ì–´ ì›ì¸ì„ ì°¾ëŠ”ë° ë©°ì¹ ì„ ì†Œìš”í–ˆë‹¤. ì›ì¸ì€ PVC ê¶Œí•œ ë¬¸ì œë¡œ EBS CSI Driver ì— ëŒ€í•œ IAM roleì— ëŒ€í•œ OIDC ê°€ ì˜ëª» ì…ë ¥ë˜ì–´ ë°œìƒí•˜ëŠ” ê²ƒì´ì˜€ë‹¤.\nAWS ì½˜ì†”ì—ì„œ OIDC ë²ˆí˜¸ë¥¼ ìˆ˜ì •í•˜ë‹ˆ ì •ìƒì ìœ¼ë¡œ ì‘ë™ë˜ì—ˆë‹¤.\nKubeflow ë§›ë³´ê¸° kubeflow ë°°í¬ê°€ ì™„ë£Œë˜ì—ˆìœ¼ë©´ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ëŒ€ì‹œë³´ë“œì— í•  ìˆ˜ ìˆë‹¤.\n1 kubectl port-forward --address 0.0.0.0 svc/istio-ingressgateway -n istio-system 8080:80 ì ‘ì†í•˜ë©´ dex ì‹œìŠ¤í…œì— ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ë¥¼ ì…ë ¥í•˜ì. ê³µì‹ ë¬¸ì„œì— ë”°ë¥´ë©´ ê¸°ë³¸ ì•„ì´ë””ì™€ ë¹„ë°€ë²ˆí˜¸ëŠ” user@example.com , 12341234 ì´ë‹¤.\nì´ì–´ì„œ ê°œë°œ í™˜ê²½ì¸ ë…¸íŠ¸ë¶ ì„œë²„ë¥¼ ìƒì„±í•´ë³´ì. ì™¼ìª½ ë©”ë‰´ì—ì„œ [Notebooks] ì—ì„œ ê°œë°œ í™˜ê²½ì„ ì„¤ì •í•˜ì.\nğŸ§Â notebook ìƒì„± íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\ní•„ìì˜ ê²½ìš° notebook ìƒì„±ì‹œ ë‹¤ìŒê³¼ ê°™ì´ ì—ëŸ¬ê°€ ë‚˜ì˜¨ë‹¤. ê¹ƒì´ìŠˆë¥¼ í™•ì¸í•˜ë‹ˆ ì›ì¸ì€ ì¥¬í”¼í„° ë‚´ë¶€ì—ì„œ HTTP ì ‘ê·¼ì—ì„œ ìƒê¸´ ë³´ì•ˆ ì—ëŸ¬ì˜€ë‹¤.\n1 2 [403] Could not find CSRF cookie XSRF-TOKEN in the request. http://3.38.94.212:8080/jupyter/api/namespaces/kubeflow-user-example-com/notebooks í•„ìì˜ ê²½ìš° ë°°í¬ë˜ì–´ ìˆëŠ” jupyer notebookì„ ìˆ˜ì •í•˜ì˜€ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 kubectl edit deploy/jupyter-web-app-deployment -n kubeflow --- ... maxUnavailable: 25% type: RollingUpdate template: metadata: creationTimestamp: null labels: app: jupyter-web-app kustomize.component: jupyter-web-app spec: containers: - env: - name: APP_PREFIX value: /jupyter - name: UI value: default - name: USERID_HEADER value: kubeflow-userid - name: USERID_PREFIX - name: APP_SECURE_COOKIES value: \u0026#34;false\u0026#34; # ture ì—ì„œ false ë¡œ ìˆ˜ì • ! image: docker.io/kubeflownotebookswg/jupyter-web-app:v1.7.0 imagePullPolicy: IfNotPresent name: jupyter-web-app ports: - containerPort: 5000 protocol: TCP resources: {} terminationMessagePath: /dev/termination-log terminationMessagePolicy: File volumeMounts: - mountPath: /etc/config name: config-volume - mountPath: /src/apps/default/static/assets/logos name: logos-volume ... ìˆ˜ì • ì´í›„ í¬íŠ¸í¬ì›Œë”©ì„ ë‹¤ì‹œí•´ì„œ ì‹œë„í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ë…¸íŠ¸ë¶ ì„œë²„ê°€ ë°°í¬ëœë‹¤.\në…¸íŠ¸ë¶ ì„œë²„ì— ë“¤ì–´ê°€ì„œ ê°„ë‹¨í•˜ê²Œ í…ŒìŠ¤íŠ¸í•´ë³´ì!\në§ˆì¹˜ë©° ì´ë²ˆ ê¸€ì—ì„œëŠ” kubeflow ì¸í”„ë¼ì™€ kubeflow ë°°í¬ê¹Œì§€ êµ¬ì„±í•˜ì˜€ë‹¤. ë‹¤ìŒ ì‹œê°„ì—ëŠ” kubeflow ê¸°ëŠ¥(íŒŒë¼ë¯¸í„° ìµœì í™”, GPU í• ë‹¹) ê´€ë ¨ ì¸í”„ë¼ì ì¸ ì¸¡ë©´ì„ ë”¥í•˜ê²Œ ë‹¤ë¤„ë³´ê² ë‹¤.\n","date":"May 06","permalink":"https://HanHoRang31.github.io/post/spot-and-kubeflow/","tags":["KANS","kubeflow","cloud","AWS","eksctl","eks"],"title":"[AEWS] EKS Spot ì¸ìŠ¤í„´ìŠ¤ì™€ Kubeflow ë°°í¬í•˜ê¸°"},{"categories":null,"contents":" 1 2 AWS EKS Workshop Study (=AEWS)ëŠ” EKS Workshop ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°,ê³µê°œëœ AWS EKS Workshopì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. EKS ? Amazon Elastic Kubernetes Service(EKS)ëŠ” AWSì—ì„œ ì œê³µí•˜ëŠ” ê´€ë¦¬í˜• Kubernetes ì„œë¹„ìŠ¤ë‹¤. EKSë¥¼ ì‚¬ìš©í•˜ë©´ Kubernetes í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±, ìš´ì˜ ë° ìœ ì§€ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤.\nhttps://catalog.us-east-1.prod.workshops.aws/workshops/9c0aa9ab-90a9-44a6-abe1-8dff360ae428/ko-KR/10-intro/200-eks\nEKSì˜ ì£¼ìš” íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nê´€ë¦¬í˜• ì„œë¹„ìŠ¤: EKSëŠ” Kubernetes ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì´ë‚˜ ë°ì´í„° í”Œë ˆì¸ë¥¼ ì„¤ì¹˜, ìš´ì˜ ë° ìœ ì§€ ê´€ë¦¬ì‹œì¼œì£¼ëŠ” ì„œë¹„ìŠ¤ì´ë‹¤. ì‚¬ìš©ìê°€ ì¸í”„ë¼ ì„¤ì¹˜, ìš´ì˜, ìœ ì§€ ê´€ë¦¬ë¥¼ í•  í•„ìš”ê°€ ì—†ë‹¤. ë†’ì€ ê°€ìš©ì„±: EKSëŠ” ì—¬ëŸ¬ AWS ê°€ìš© ì˜ì—­(ë°ì´í„° ì„¼í„°ì˜ ë¬¼ë¦¬ì  ìœ„ì¹˜)ì— ê±¸ì³ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ê³¼ ë°ì´í„° í”Œë ˆì¸ë¥¼ ë¶„ì‚°ì‹œì¼œ ì„œë¹„ìŠ¤ì˜ ì•ˆì •ì„±ì„ ì œê³µí•œë‹¤. ì´ëŠ” ë‹¨ì¼ ì¥ì¬ ì§€ì ì„ ì œê±°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆìœ¼ë©° ìë™ ê´€ë¦¬ë˜ëŠ” ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì˜ ê²½ìš° ë¦¬ì „ ë‚´ ê°œë³„ ê°€ìš© ì˜ì—­ì—ì„œ ìµœì†Œ 2ê°œì´ìƒì˜API ì„œë²„ ë…¸ë“œë¥¼ ì‹¤í–‰í•œë‹¤. AWS ì„œë¹„ìŠ¤ í†µí•©: íƒ€ AWS ECR(ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬), ELB(ë„¤íŠ¸ì›Œí¬ ë¡œë“œë°¸ëŸ°ì‹±), IAM(ë³´ì•ˆ), VPC(ë„¤íŠ¸ì›Œí¬)ì™€ ê°™ì€ AWS ì„œë¹„ìŠ¤ì™€ í†µí•©ë˜ì–´ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì €ì¥, ë¡œë“œ ë°¸ëŸ°ì‹±, ì¸ì¦ ë° ê²©ë¦¬ë¥¼ ì‰½ê²Œ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. ì˜¤í”ˆ ì†ŒìŠ¤ Kubernetes í˜¸í™˜ì„±: ìµœì‹  ë²„ì „ì˜ ì˜¤í”ˆ ì†ŒìŠ¤ Kubernetesë¥¼ ì‚¬ìš©í•˜ì—¬ ê¸°ì¡´ í”ŒëŸ¬ê·¸ì¸ê³¼ ë„êµ¬ë¥¼ ê·¸ëŒ€ë¡œ í™œìš©í•  ìˆ˜ ìˆë‹¤. ì§€ì› ë²„ì „ : 23ë…„ 4ì›” í˜„ì¬ kubernetes ë²„ì „ ì¤‘ 1.22~1.26 ì§€ì›ì„ ì§€ì› ì¤‘ì´ë‹¤. ë²„ì „ ì¶œì‹œ ì£¼ê¸°ëŠ” ì—° 3íšŒì´ë©° ê° ë²„ì „ì€ 12ê°œì›” ë™ì•ˆ ì§€ì›ëœë‹¤. ì§€ì›ì´ ëë‚œ ë²„ì „ë“¤ì€ ìë™ìœ¼ë¡œ EKSê°€ ì—…ë°ì´íŠ¸ì‹œí‚¨ë‹¤. EKS ì•„í‚¤í…ì²˜ EKS ì•„í‚¤í…ì²˜ëŠ” í¬ê²Œ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸(ë§ˆìŠ¤í„° ë…¸ë“œ)ê³¼ ë°ì´í„° í”Œë ˆì¸(ì›Œì»¤ ë…¸ë“œ)ë¡œ ë‚˜ë‰œë‹¤. ì•„í‚¤í…ì²˜ ê·¸ë¦¼ì€ ìŠ¤í„°ë””ì—ì„œ ê³µìœ í•´ì£¼ì‹  2022 AWS ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì  ì •ë¦¬ pdfë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‚´í´ë³´ê² ë‹¤. ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ EKSì—ì„œëŠ” Kubernetes ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì˜ ê°€ìš©ì„±ê³¼ ë‚´êµ¬ì„±ì„ ì†ìƒì‹œí‚¬ ìˆ˜ ìˆëŠ” ë‹¨ì¼ ì¥ì•  ì§€ì ì„ ì œê±°í•˜ë„ë¡ ì„¤ê³„ë˜ì—ˆë‹¤. ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ì€ API ì„œë²„ ë…¸ë“œ, etcd í´ëŸ¬ìŠ¤í„°ë¡œ êµ¬ì„±ëœë‹¤.\nAPI ì„œë²„: ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì˜ ëª¨ë“  ì‘ì—…ì„ ì²˜ë¦¬í•˜ê³  ìƒíƒœë¥¼ ì €ì¥í•˜ëŠ” ì¤‘ì•™ í—ˆë¸Œì´ë‹¤. RESTful APIë¥¼ í†µí•´ í†µì‹ í•˜ë©°, ì‚¬ìš©ì ìš”ì²­ì— ë”°ë¼ í´ëŸ¬ìŠ¤í„°ì˜ ìƒíƒœë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ì •ë³´ë¥¼ ë°˜í™˜ì‹œì¼œì¤€ë‹¤. etcd: etcdëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì—ì„œ ì‚¬ìš©í•˜ëŠ” ë¶„ì‚° í‚¤-ê°’ ì €ì¥ì†Œì´ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ëª¨ë“  ì„¤ì • ë°ì´í„°ì™€ í´ëŸ¬ìŠ¤í„° ìƒíƒœ ì •ë³´ë¥¼ ì €ì¥í•œë‹¤. ê° API ì„œë²„ì™€ etcdëŠ” ê°œë³„ ê°€ìš© ì˜ì—­ì—ì„œ ìµœì†Œ 2ê°œ ì´ìƒì˜ í´ëŸ¬ìŠ¤í„°ë¡œ êµ¬ì„±ë˜ì–´ ì‹¤í–‰ëœë‹¤. ì´ë¥¼ í†µí•´ ë‹¨ì¼ ê°€ìš© ì˜ì—­ì˜ ì´ë²¤íŠ¸ê°€ EKS í´ëŸ¬ìŠ¤í„° ê°€ìš©ì„±ì— ì˜í–¥ì„ ë¯¸ì¹˜ì§€ ì•ŠëŠ”ë‹¤. ê° ê°€ìš© ì˜ì—­ì—ì„œëŠ” NAT ê²Œì´íŠ¸ì›¨ì´ë¥¼ í†µí•´ í”„ë¼ì´ë¹— ì„œë¸Œë„·ì—ì„œ ì‹¤í–‰ë˜ë©° ì‚¬ìš©ìëŠ” í•´ë‹¹ ë…¸ë“œì— ì ‘ê·¼í•  ìˆ˜ ì—†ë‹¤. ë˜í•œ API ì„œë²„ëŠ” NLBë¡œ ETCDëŠ” ELBë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ì„œë²„ì˜ ë¶€í•˜ë¥¼ ë¶„ì‚°ì‹œí‚¨ë‹¤. API ì„œë²„ì™€ ETCD í´ëŸ¬ìŠ¤í„°ëŠ” ì˜¤í† ìŠ¤ì¼€ì¼ë§ ê·¸ë£¹ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ì¡°ê±´(í´ëŸ¬ìŠ¤í„° ê·œëª¨ , API ì„œë²„ ë° etcdì— ëŒ€í•œ ìš”ì²­ ì¦ê°€)ì— ë”°ë¼ ìë™ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ê°€ í™•ì¥ëœë‹¤. ë°ì´í„° í”Œë ˆì¸ ë°ì´í„° í”Œë ˆì¸ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ì›Œí¬ë¡œë“œë¥¼ ì‹¤í–‰í•˜ê³  ê´€ë¦¬ë˜ëŠ” ì„œë²„ë‹¤. ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\nkubelet: ë…¸ë“œ ì—ì´ì „íŠ¸ì´ë‹¤. kubeletì€ API ì„œë²„ë¡œë¶€í„° íŒŒë“œë¥¼ ì‹¤í–‰í•˜ê³  ê´€ë¦¬í•´ì•¼ í•˜ëŠ” ëª…ë ¹ì„ ë°›ì•„ ì„œë²„ì— ë°˜ì˜ì‹œì¼œì¤€ë‹¤. ë˜ ì‹¤í–‰ ì¤‘ì¸ íŒŒë“œì™€ ì»¨í…Œì´ë„ˆë¥¼ ê´€ë¦¬í•˜ê³ , ìƒíƒœë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë©°, í•„ìš”í•œ ê²½ìš° API ì„œë²„ì— ìƒíƒœ ì •ë³´ë¥¼ ë³´ê³ í•˜ëŠ” ì—­í• ì„ ìˆ˜í–‰í•œë‹¤. kube-proxy: ë„¤íŠ¸ì›Œí¬ í”„ë¡ì‹œ ë° ë¡œë“œ ë°¸ëŸ°ì„œì´ë‹¤. kube-proxyëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì„œë¹„ìŠ¤ì— ëŒ€í•œ ìš”ì²­ì„ ì ì ˆí•œ íŒŒë“œë¡œ ì „ë‹¬í•˜ê³ , íŒŒë“œ ê°„ì˜ í†µì‹ ì„ ê´€ë¦¬í•œë‹¤. EKS ì˜ ê¸°ë³¸ ë„¤íŠ¸ì›Œí¬ CNIë¡œëŠ” VPC-CNIê°€ ì‹¤í–‰ëœë‹¤. ë˜í•œ, ì‚¬ìš©ìì˜ ìš”êµ¬ì— ë§ê²Œ ë°ì´í„° í”Œë ˆì¸ì˜ êµ¬ì„± ì˜µì…˜ì„ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. êµ¬ì„± ì˜µì…˜ë³„ ì„¸ë¶€ ì •ë³´ëŠ” ë‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ë‹¤.\nhttps://aws.github.io/aws-eks-best-practices/reliability/docs/\nê·¸ë¦¼ì—ì„œ ë¹„êµí•œ ê²ƒê³¼ ê°™ì´ ì‚¬ìš©ì ì±…ì„ ë ˆë²¨ì— ë”°ë¼ 3ê°€ì§€ë¡œ êµ¬ë¶„ëœë‹¤.\nSelf Managed Workers :ì‚¬ìš©ìê°€ ì§ì ‘ ë…¸ë“œë¥¼ êµ¬ì„±í•˜ê³  ê´€ë¦¬í•˜ëŠ” ë°©ì‹ì´ë‹¤. êµ¬ì²´ì ìœ¼ë¡œëŠ” Custom AMIë¥¼ í†µí•´ ì‘ì—…ì ë…¸ë“œë¥¼ ìƒì„±í•˜ë©° AMIì™€ ë…¸ë“œì˜ íŒ¨ì¹˜ ë° ì—…ê·¸ë ˆì´ë“œë¥¼ ì‚¬ìš©ìê°€ ì§ì ‘ ê´€ë¦¬í•œë‹¤. Managed Node groups : AWSê°€ ë…¸ë“œë¥¼ ìë™ìœ¼ë¡œ í”„ë¡œë¹„ì €ë‹í•˜ê³ , ì—…ë°ì´íŠ¸ ë° ìœ ì§€ ê´€ë¦¬ë¥¼ ì²˜ë¦¬í•œë‹¤. EKS Fargate : ì„œë²„ë¦¬ìŠ¤ ì»´í“¨íŒ… ì˜µì…˜ì´ë‹¤. Micro VMë¥¼ ì´ìš©í•˜ì—¬ Podë³„ VMì´ í• ë‹¹ëœë‹¤. AWSê°€ ì„¤ì •ì— ë§ê²Œ íŒŒë“œ ë ˆë²¨ì˜ ìŠ¤ì¼€ì¼ë§ì„ ìë™ìœ¼ë¡œ ì²˜ë¦¬í•œë‹¤. Cluster Endpoint Access EKS í´ëŸ¬ìŠ¤í„°ì˜ API ì„œë²„ì— ëŒ€í•œ ì ‘ê·¼ì„ ì œì–´í•˜ëŠ” ì„¤ì •ì´ë‹¤. í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ë¥¼ ì„¤ì •í•¨ìœ¼ë¡œì¨, í´ëŸ¬ìŠ¤í„°ì— ëŒ€í•œ ì ‘ê·¼ì„ í•„ìš”í•œ ë²”ìœ„ë¡œ ì œí•œí•˜ì—¬ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ì˜µì…˜ì€ 3ê°€ì§€ ì¡´ì¬í•œë‹¤.\nPublic : í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ê°€ Public IPë¡œ í• ë‹¹ë˜ì–´ ì¸í„°ë„·ì—ì„œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ì„¤ì •ì´ë‹¤. í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ì—ì„œë„ IGW ë¥¼ í†µí•´ Public IPì™€ í†µì‹ í•œë‹¤.\ní•´ë‹¹ ì˜µì…˜ì€ AWS ì½˜ì†”ì—ì„œ í™•ì¸ ê°€ëŠ¥í•˜ë‹¤. Public ì„¤ì •ì‹œ ë‹¤ìŒê³¼ ê°™ì´ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë‹¤.\nìœ„ì™€ ê°™ì´ ì¸í„°ë„·ì„ í†µí•´ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ì—¬ ì ‘ê·¼ì„±ì„ ë†’ì¼ ìˆ˜ ìˆë‹¤.\nPublic Private : ì›Œí¬ë…¸ë“œ ë‚´ë¶€ì—ì„œëŠ” Private(VPC ë‚´ë¶€ë§ì—ì„œë§Œ ì ‘ê·¼ ê°€ëŠ¥)ë¡œ, API ì ‘ê·¼ì€ Public(ì¸í„°ë„·ì„ í†µí•œ ì ‘ê·¼ ê°€ëŠ¥)ìœ¼ë¡œë§Œ í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤. ì›Œí¬ ë…¸ë“œì—ì„œ ë¯¼ê°ë°ì´í„° ë…¸ì¶œì„ ë§‰ê¸° ìœ„í•´ Private subnet(ì‚¬ì„¤ë§)ì— ìœ„ì¹˜ì‹œí‚¨ ê²½ìš° ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ì˜µì…˜ì´ë‹¤.\nPrivate : API ì„œë²„ ì—”ë“œí¬ì¸íŠ¸ ë˜í•œ í—ˆìš©ëœ VPCì—ì„œë§Œ ì ‘ê·¼ì´ ê°€ëŠ¥í•œ ì„¤ì •ì´ë‹¤.\ní•´ë‹¹ ì˜µì…˜ìœ¼ë¡œ ì‚¬ìš©ì‹œ API Server URLì€ Route53 privated hosted zoneìœ¼ë¡œ ë³€ê²½ë˜ì–´ VPC ë‚´ë¶€ì—ì„œë§Œ í†µì‹ ì´ ê°€ëŠ¥í•˜ë‹¤. í•´ë‹¹ URLì€ AWS ì½˜ì†”ì˜ EKSë‚˜ kubectl -v=6 ì˜µì…˜ìœ¼ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 4 # API Server URL(Route53 privated hosted zone) (terraform-eks@my-eks:N/A) [root@myeks-host example]# kubectl get pods -A -v=6 I0428 14:26:36.609385 27821 loader.go:374] Config loaded from file: /root/.kube/config I0428 14:26:37.276259 27821 round_trippers.go:553] GET https://232B71CC97744BC94C09D40801D073B0.yl4.ap-northeast-2.eks.amazonaws.com/api/v1/pods?limit=500 200 OK in 661 milliseconds ìœ„ [https://232B71CC97744BC94C09D40801D073B0.yl4.ap-northeast-2.eks.amazonaws.com](https://232B71CC97744BC94C09D40801D073B0.yl4.ap-northeast-2.eks.amazonaws.com) ê°€ API server URLì´ë‹¤. í•´ë‹¹ URLì€ EKS ì»¨íŠ¸ë¡¤ ë…¸ë“œê°€ ì†Œìœ í•˜ê³  ìˆëŠ” ë„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ë¥¼ í†µí•´ í†µì‹ ëœë‹¤. í†µì¹­ EKS owned ENIëŠ” AWS ì½˜ì†”ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\në„¤íŠ¸ì›Œí¬ ì¸í„°í˜ì´ìŠ¤ì—ì„œ í´ëŸ¬ìŠ¤í„°ë¥¼ ë°°í¬í•œ VPCë¥¼ ì…ë ¥í•˜ì—¬ ì¸ìŠ¤í„´ìŠ¤ IDê°€ ì¡´ì¬í•˜ì§€ ì•Šê³ (- í‘œì‹œ), ì„¤ëª…ì— Amazone EKS cluster-name ìœ¼ë¡œ í‘œì‹œëœ ê²ƒì´ EKS owned ENI ì´ë‹¤. ì¸ìŠ¤í„´ìŠ¤ ì†Œìœ ì ë˜í•œ AWS ì†Œìœ ì ë²ˆí˜¸ê°€ ë‹¤ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° AWSê°€ ì§ì ‘ ê´€ë¦¬í•˜ëŠ” ì»¨íŠ¸ë¡¤ ë…¸ë“œì˜ ì†Œìœ ì ë²ˆí˜¸ì´ê¸° ë•Œë¬¸ì´ë‹¤.\nEKS ë°°í¬ ë°©ì‹ EKS ë°°í¬ ë°©ì‹ì€ Manual, Command line utility, Infrastructure as Code ì— ë”°ë¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤.\nManual : AWS Management Console ì—ì„œ ì§ì ‘ êµ¬ì„± Command line utility : ì»¤ë§¨ë“œ ëª…ë ¹ì–´ë¥¼ í†µí•œ êµ¬ì„± (AWS CLI, eksctl) Infrastructure as Code : ì½”ë“œë¥¼ í†µí•œ êµ¬ì„±(Terrafrom, AWS CDK ë“±) ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” eksctl ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê² ë‹¤. eksctl ? Amazon EKS (Elastic Kubernetes Service) í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•˜ê³  ê´€ë¦¬í•˜ê¸° ìœ„í•œ ëª…ë ¹ì¤„ ì¸í„°í˜ì´ìŠ¤(CLI) íˆ´ì´ë‹¤. eksctlë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„± ë° ì‚­ì œ, ì—…ë°ì´íŠ¸í•  ìˆ˜ ìˆìœ¼ë©° VPC, ì„œë¸Œë„·, ë¦¬ì†ŒìŠ¤ ìƒì„±ì„ ìœ„í•œ ì •ì±… ìƒì„± ë“±ì˜ ì‘ì—…ì„ ì‰½ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. ê³µì‹ ë¬¸ì„œë¥¼ í†µí•´ ë‹¤ì–‘í•œ ì¸í”„ë¼ í™˜ê²½ì—ì„œì˜ EKS êµ¬ì„±ì„ ì°¸ê³ í•  ìˆ˜ ìˆë‹¤.\nì•„ì‰¬ìš´ ì ì€ EKSì—ì„œë§Œ êµ¬ì¶•ì´ ëœë‹¤ëŠ” ì ì´ë‹¤. ì¶”í›„ ë‹¤ë¥¸ í´ëŸ¬ìŠ¤í„°ë‚˜ ë©€í‹° í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì‹œ ë‹¤ë¥¸ íˆ´ì„ ì‚¬ìš©í•˜ì.\nì¶”ê°€ë¡œ ì‚¬ìš©í•´ë³´ë‹ˆ.. eksctlëŠ” í˜•ìƒê´€ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. í•œ ë²ˆ ë°°í¬ ì´í›„ì—ëŠ” eksctl êµ¬ì„± íŒŒì¼ì„ í†µí•´ ì¶”ê°€ ì‘ì—…ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤. eksctlë¥¼ í†µí•´ ê¸°ì¡´ì˜ ë¦¬ì†ŒìŠ¤ ë³€ê²½ì´ ë¶ˆê°€ëŠ¥í•˜ë©° ì¶”ê°€ë§Œ ê°€ëŠ¥í•˜ë‹¤. eksctl ë¥¼ í†µí•œ EKS ë°°í¬ eksctlë¥¼ í†µí•´ EKS Private Cluster ë¥¼ ë°°í¬í•˜ê² ë‹¤. êµ¬ì„± ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\në…¸ë“œ ê·¸ë£¹ì€ unmanaged node group ìœ¼ë¡œ, Cluster endpoint ëŠ” Privateë¡œ êµ¬ì„±í•˜ì˜€ë‹¤. ì•„í‚¤í…ì²˜ì—ì„œ í™”ì‚´í‘œëŠ” í†µì‹  ì•„í‚¤í…ì²˜ì´ë‹¤.\nEKS Admin(ë¹¨ê°„ì„ ) : ë² ìŠ¤ì²œ ì„œë²„ë¥¼ í†µí•´ EKS API Serverë¡œ ì ‘ê·¼í•˜ì—¬ EKSë¥¼ ê´€ë¦¬í•˜ëŠ” ê³¼ì •ì´ë‹¤. Private Worker node(ë³´ë¼ì„ ): Private cluster ë¡œ êµ¬ì„±ë˜ì–´ EKS control node ENIë¥¼ í†µí•´ EKS Control nodeì™€ í†µì‹ í•œë‹¤. ë°°í¬ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•˜ê² ë‹¤.\ncloudformationë¥¼ í†µí•œ ë² ìŠ¤ì²œ ì„œë²„ ë°°í¬ eksctlë¥¼ í†µí•œ EKS ë°°í¬ 1. AWS Cloudformationë¥¼ í†µí•œ ë² ìŠ¤ì²œ ì„œë²„ ë°°í¬ AWS Cloudformationì„ í†µí•´ VPC êµ¬ì„± ë° ë² ìŠ¤ì²œ ì„œë²„ë¥¼ ë°°í¬í•˜ê³  eksctl ì„¤ì¹˜ ë° ê´€ë¦¬ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•˜ê² ë‹¤. Cloudformation ìŠ¤í¬ë¦½íŠ¸ëŠ” ìŠ¤í„°ë””ì—ì„œ ê³µìœ í•´ì£¼ì‹  ê²ƒì„ ê¸°ë°˜ìœ¼ë¡œ ë‚´ìš©ì„ ì¶”ê°€í•˜ì˜€ë‹¤.\n1 2 # yaml íŒŒì¼ ë‹¤ìš´ë¡œë“œ curl -O https://github.com/HanHoRang31/blog-share/blob/main/aews-eksctl/cloudformation-bastion.yaml êµ¬ì„± ì½”ë“œì—ì„œ Private í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì„ ìœ„í•œ ì¤‘ìš” ë¶€ë¶„ê³¼ ë² ìŠ¤ì²œ ì„œë²„ì˜ íŒ¨í‚¤ì§€ êµ¬ì„± ì •ë³´ë¥¼ í™•ì¸í•˜ê² ë‹¤. ë¨¼ì € Private í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì„ ìœ„í•´ í•„ìš”í•œ ë³´ì•ˆ ê·¸ë£¹ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 # cloudformation-bastion # íŒŒë¼ë¯¸í„° ... # ë² ìŠ¤ì²œ ì„œë²„ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì • # EKSCTL-Host EKSEC2SG: Type: AWS::EC2::SecurityGroup Properties: GroupDescription: eksctl-host Security Group VpcId: !Ref EksVPC Tags: - Key: Name Value: !Sub ${ClusterBaseName}-HOST-SG SecurityGroupIngress: - IpProtocol: tcp FromPort: \u0026#39;22\u0026#39; ToPort: \u0026#39;22\u0026#39; CidrIp: !Ref SgIngressSshCidr # ë² ìŠ¤ì²œ ì„œë²„ì—ì„œ EKS ë°°í¬ë¥¼ ìœ„í•œ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì • ControlPlaneSecurityGroup: DependsOn: - EKSEC2SG Type: AWS::EC2::SecurityGroup Properties: GroupDescription: Cluster communication with worker nodes VpcId: !Ref EksVPC SecurityGroupIngress: - IpProtocol: tcp FromPort: 443 ToPort: 443 SourceSecurityGroupId: !Ref EKSEC2SG Tags: - Key: Name Value: !Sub ${ClusterBaseName} Control Plane Security Group ... Private Cluster êµ¬ì¶•ìœ¼ë¡œ ì¤‘ìš” ì‚¬í•­ì€ ë‘ ê°€ì§€ì´ë‹¤.\nEKSEC2SG : ë² ìŠ¤ì²œ ì„œë²„ì— ëŒ€í•œ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì • ë¶€ë¶„ì´ë‹¤. í•´ë‹¹ ë¶€ë¶„ì„ í†µí•´ ë² ìŠ¤ì²œ ì„œë²„ì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” IP ë²”ìœ„ë¥¼ ì œí•œí•  ìˆ˜ ìˆë‹¤. ì½”ë“œ ë‚´ SgIngressSshCidr ì—ì„œ ì§€ì •í•œ IPë¥¼ ì œí•œí•˜ë©° í•´ë‹¹ ê°’ì€ ë°°í¬ ëª…ë ¹ì–´ë¡œ override ì„ í†µí•´ ê°’ì„ ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤. ControlPlaneSecurityGroup : ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ê³¼ ì›Œí¬ ë…¸ë“œê°„ í†µì‹ ì„ ìœ„í•œ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì • ë¶€ë¶„ì´ë‹¤. ì½”ë“œì—ì„œëŠ” ë² ìŠ¤ì²œ ì„œë²„ì™€ì˜ í†µì‹ ì„ ìœ„í•´ 443 í¬íŠ¸ì˜ ë³´ì•ˆ ê·¸ë£¹ì„ ì¶”ê°€í•˜ì˜€ë‹¤. userdataë¥¼ í™•ì¸í•˜ë©´ ë² ìŠ¤ì²œ ì„œë²„ì— ì„¤ì¹˜ë˜ëŠ” íŒ¨í‚¤ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì„¤ì¹˜ ëª…ë ¹ì–´ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 ... UserData: Fn::Base64: !Sub | #!/bin/bash hostnamectl --static set-hostname \u0026#34;${ClusterBaseName}-host\u0026#34; # Config convenience echo \u0026#39;alias vi=vim\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#34;sudo su -\u0026#34; \u0026gt;\u0026gt; /home/ec2-user/.bashrc # Change Timezone sed -i \u0026#34;s/UTC/Asia\\/Seoul/g\u0026#34; /etc/sysconfig/clock ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime # Install Packages cd /root yum -y install tree jq git htop lynx # Install kubectl \u0026amp; helm #curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.26.2/2023-03-17/bin/linux/amd64/kubectl curl -O https://s3.us-west-2.amazonaws.com/amazon-eks/1.25.7/2023-03-17/bin/linux/amd64/kubectl install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl curl -s https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash # Install eksctl curl --silent --location \u0026#34;https://github.com/weaveworks/eksctl/releases/latest/download/eksctl_$(uname -s)_amd64.tar.gz\u0026#34; | tar xz -C /tmp mv /tmp/eksctl /usr/local/bin # Install aws cli v2 curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip \u0026gt;/dev/null 2\u0026gt;\u0026amp;1 sudo ./aws/install complete -C \u0026#39;/usr/local/bin/aws_completer\u0026#39; aws echo \u0026#39;export AWS_PAGER=\u0026#34;\u0026#34;\u0026#39; \u0026gt;\u0026gt;/etc/profile export AWS_DEFAULT_REGION=${AWS::Region} echo \u0026#34;export AWS_DEFAULT_REGION=$AWS_DEFAULT_REGION\u0026#34; \u0026gt;\u0026gt; /etc/profile # Install YAML Highlighter wget https://github.com/andreazorzetto/yh/releases/download/v0.4.0/yh-linux-amd64.zip unzip yh-linux-amd64.zip mv yh /usr/local/bin/ # Install krew curl -LO https://github.com/kubernetes-sigs/krew/releases/download/v0.4.3/krew-linux_amd64.tar.gz tar zxvf krew-linux_amd64.tar.gz ./krew-linux_amd64 install krew export PATH=\u0026#34;$PATH:/root/.krew/bin\u0026#34; echo \u0026#39;export PATH=\u0026#34;$PATH:/root/.krew/bin\u0026#34;\u0026#39; \u0026gt;\u0026gt; /etc/profile # Install kube-ps1 echo \u0026#39;source \u0026lt;(kubectl completion bash)\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;alias k=kubectl\u0026#39; \u0026gt;\u0026gt; /etc/profile echo \u0026#39;complete -F __start_kubectl k\u0026#39; \u0026gt;\u0026gt; /etc/profile git clone https://github.com/jonmosco/kube-ps1.git /root/kube-ps1 cat \u0026lt;\u0026lt;\u0026#34;EOT\u0026#34; \u0026gt;\u0026gt; /root/.bash_profile source /root/kube-ps1/kube-ps1.sh KUBE_PS1_SYMBOL_ENABLE=false function get_cluster_short() { echo \u0026#34;$1\u0026#34; | cut -d . -f1 } KUBE_PS1_CLUSTER_FUNCTION=get_cluster_short KUBE_PS1_SUFFIX=\u0026#39;) \u0026#39; PS1=\u0026#39;$(kube_ps1)\u0026#39;$PS1 EOT # Install krew plugin kubectl krew install ctx ns get-all # ktop df-pv mtail tree # Install Docker amazon-linux-extras install docker -y systemctl start docker \u0026amp;\u0026amp; systemctl enable docker # Install nerdctl wget https://github.com/containerd/nerdctl/releases/download/v1.3.1/nerdctl-1.3.1-linux-amd64.tar.gz tar -xzf nerdctl-1.3.1-linux-amd64.tar.gz sudo mv nerdctl /usr/local/bin/ # CLUSTER_NAME export CLUSTER_NAME=${ClusterBaseName} echo \u0026#34;export CLUSTER_NAME=$CLUSTER_NAME\u0026#34; \u0026gt;\u0026gt; /etc/profile # Create SSH Keypair ssh-keygen -t rsa -N \u0026#34;\u0026#34; -f /root/.ssh/id_rsa ... ëª‡ ê°€ì§€ aliasì™€ í™˜ê²½ ì„¤ì •ì„ ì¶”ê°€í•˜ê³ , ì‹œìŠ¤í…œì˜ ì‹œê°„ëŒ€ë¥¼ Asia/Seoulë¡œ ë³€ê²½í•œë‹¤. í•„ìš”í•œ íŒ¨í‚¤ì§€ë“¤(tree, jq, git, htop, lynx, kubectl, helm, eksctl, AWS CLI v2, yh, krew, docker, nerdctl, kube-ps1)ì„ ì„¤ì¹˜í•œë‹¤. í´ëŸ¬ìŠ¤í„° ì´ë¦„ì„ ì„¤ì •í•˜ê³ , SSH í‚¤ í˜ì–´ë¥¼ ìƒì„±í•œë‹¤. ë°°í¬ëŠ” ë‹¤ìŒê³¼ ê°™ì€ íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì§„í–‰í•˜ì˜€ë‹¤.\n1 aws cloudformation deploy --template-file myeks-1week.yaml --stack-name myeks --parameter-overrides KeyName=eks-terraform-key --region ap-northeast-2 ë°°í¬ ì™„ë£Œ í›„ ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¥¼ í†µí•´ ë² ìŠ¤ì²œ ì„œë²„ì— ì ‘ê·¼í•˜ê³  EKS ë°°í¬ ê³¼ì •ìœ¼ë¡œ ë„˜ì–´ê°€ê² ë‹¤.\n1 ssh -i eks-terraform-key.pem ec2-user@$(aws cloudformation describe-stacks --stack-name myeks --query \u0026#39;Stacks[*].Outputs[0].OutputValue\u0026#39; --output text) 2. eksctlë¥¼ í†µí•œ EKS ë°°í¬ ë² ìŠ¤ì²œ ì„œë²„ì— ì ‘ì†í•˜ì—¬ AWS ì¸ì¦ ì •ë³´ë¥¼ ì…ë ¥í•˜ì.\n1 2 3 4 5 [root@myeks-host example]# aws configure AWS Access Key ID [None]: ACCESS-KEY AWS Secret Access Key [None]: SECRET-KEY Default region name [None]: ap-northeast-2 Default output format [None]: json AWS ì¸ì¦ ì •ë³´ ì…ë ¥ í›„ eksctlë¥¼ í†µí•´ private cluster êµ¬ì„±í•˜ì. êµ¬ì„± ë‚´ìš©ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 apiVersion: eksctl.io/v1alpha5 kind: ClusterConfig metadata: name: my-eks region: ap-northeast-2 # ì§€ì—­ ì„¤ì •(ì„œìš¸) version: \u0026#34;1.25\u0026#34; # í´ëŸ¬ìŠ¤í„° ë²„ì „ vpc: id: vpc-05a960a0837da1328 # ë² ìŠ¤ì²œ ì„œë²„ VPC ID (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) cidr: 192.168.0.0/16 # # ë² ìŠ¤ì²œ ì„œë²„ VPC CIDR (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) securityGroup: sg-0c59ddf1a9a73edc9 nat: gateway: HighlyAvailable subnets: public: public-2a: id: subnet-06391e7ab56a8ae9c # ì„œë¸Œë„· ID (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) cidr: 192.168.1.0/24 # ì„œë¸Œë„· CIDR (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) public-2c: id: subnet-00c193bd6e515a79b # ì„œë¸Œë„· ID (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) cidr: 192.168.2.0/24 # ì„œë¸Œë„· CIDR (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) private: private-2a: id: subnet-02d592518f7ae0755 # ì„œë¸Œë„· ID (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) cidr: 192.168.3.0/24 # ì„œë¸Œë„· CIDR (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) private-2c: id: subnet-0dcfc3b165e7b355d # ì„œë¸Œë„· ID (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) cidr: 192.168.4.0/24 # ì„œë¸Œë„· CIDR (ì•„ë˜ ë‚´ìš© ì°¸ê³ ) clusterEndpoints: # í´ëŸ¬ìŠ¤í„° ì—”ë“œí¬ì¸íŠ¸ ì•¡ì„¸ìŠ¤ ì„¤ì • ë¶€ë¶„ publicAccess: false # ê³µìš© ì•¡ì„¸ìŠ¤ ë¹„í™œì„±í™” privateAccess: true # ì‚¬ì„¤ ì•¡ì„¸ìŠ¤ í™œì„±í™” nodeGroups: - name: ng-1 instanceType: m5.xlarge # ì¸ìŠ¤í„´ìŠ¤ ìœ í˜• desiredCapacity: 3 # ì›í•˜ëŠ” ë…¸ë“œ ìˆ˜ privateNetworking: true # ì‚¬ì„¤ ë„¤íŠ¸ì›Œí¬ ì‚¬ìš© ssh: publicKeyName: ec2-key # ec2 ë³´ì•ˆ í‚¤ availabilityZones: - ap-northeast-2a - ap-northeast-2c iam: withAddonPolicies: imageBuilder: true # ì´ë¯¸ì§€ ë¹Œë” ì •ì±… í™œì„±í™” albIngress: true # ALB ì¸ê·¸ë ˆìŠ¤ ì •ì±… í™œì„±í™” cloudWatch: true # CloudWatch ì •ì±… í™œì„±í™” autoScaler: true # ì˜¤í†  ìŠ¤ì¼€ì¼ëŸ¬ ì •ì±… í™œì„±í™” instanceName: EKS-WORKER-TEST volumeSize: 30 # ë³¼ë¥¨ í¬ê¸° ì„¤ì • êµ¬ì„± ë‚´ìš© ì¤‘ VPC, Subnet ID, CIDRì€ AWS Consoleì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤. VPC â†’ Resource Road Map ì„ í†µí•´ ì—°ê²°ëœ ì„œë¸Œë„· ë° ë¼ìš°íŒ… ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì •ë³´ê°€ í•„ìš”í•œ ë¦¬ì†ŒìŠ¤ë¥¼ í´ë¦­í•˜ë©´ ë°”ë¡œ ë„˜ì–´ê°€ì§„ë‹¤.\në³´ì•ˆ ê·¸ë£¹ ID ëŠ” EC2â†’ ë³´ì•ˆ ê·¸ë£¹ì—ì„œ Name myeks Control Plane Security Group ì—ì„œ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nêµ¬ì„± ì…ë ¥ í›„ eksctl ëª…ë ¹ì–´ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ê² ë‹¤.\n1 eksctl create cluster -f private-cluster.yaml ë°°í¬ëŠ” ì•½ 20ë¶„ì •ë„ ì†Œìš”ëœë‹¤. êµ¬ì„± í›„ í´ëŸ¬ìŠ¤í„° API ì„œë²„ ì ‘ê·¼ì„ ìœ„í•œ ì¸ì¦ ì •ë³´ê°€ í•„ìš”í•˜ë‹¤. ì¸ì¦ ì •ë³´ëŠ” ë‹¤ìŒì˜ eksctl ëª…ë ¹ì–´ë¥¼ í†µí•´ ì €ì¥í•  ìˆ˜ ìˆë‹¤.\n1 2 3 (terraform-eks@my-eks-2:N/A) [root@myeks-host example]# eksctl utils write-kubeconfig --name my-eks --region ap-northeast-2 Flag --name has been deprecated, use --cluster 2023-04-29 19:59:36 [âœ”] saved kubeconfig as \u0026#34;/root/.kube/config\u0026#34; ë°°í¬ í™•ì¸ì„ ìœ„í•´ íŒŒë“œ ë¦¬ìŠ¤íŠ¸ë¥¼ í™•ì¸í•´ë³´ì.\n1 2 3 4 5 6 7 8 9 10 11 12 (terraform-eks@my-eks:N/A) [root@myeks-host example]# kubectl get pods -A NAMESPACE NAME READY STATUS RESTARTS AGE kube-system aws-node-4kms4 1/1 Running 0 109m kube-system aws-node-8r2fq 1/1 Running 0 109m kube-system aws-node-hsgmr 1/1 Running 0 109m kube-system aws-node-nf758 1/1 Running 0 109m kube-system coredns-76b4dcc5cc-4mbw2 1/1 Running 0 127m kube-system coredns-76b4dcc5cc-vfpgp 1/1 Running 0 127m kube-system kube-proxy-68vgc 1/1 Running 0 109m kube-system kube-proxy-lgltk 1/1 Running 0 109m kube-system kube-proxy-lqngn 1/1 Running 0 109m kube-system kube-proxy-vl4tb 1/1 Running 0 109m ì•ì„œ ê³µìœ í•œ ë² ìŠ¤ì²œ ì„œë²„ ì¸í”„ë¼ êµ¬ì„± íŒŒì¼ê³¼ eks êµ¬ì„± íŒŒì¼ì„ í†µí•´ ì§„í–‰í•˜ë©´ ì•„ë¬´ ë¬¸ì œ ì—†ì´ êµ¬ì„±ì´ ì™„ë£Œë  ê²ƒì´ë‹¤. ì•„ë˜ ë‚´ìš©ì€ í•„ìê°€ private cluster êµ¬ì„± ì¤‘ ìƒê¸´ ì—ëŸ¬ë¡œ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…í•œ ë‚´ìš©ì´ë‹¤. í˜¹ì‹œ êµ¬ì„± ì¤‘ ì—ëŸ¬ê°€ ë°œìƒí•œë‹¤ë©´ ë‹¤ìŒ ë‚´ìš©ì„ ì°¸ê³ í•˜ì.\níŠ¸ëŸ¬ë¸”ìŠˆíŒ… í´ëŸ¬ìŠ¤í„° ë°°í¬ ì¤‘ timeout ë°œìƒê³¼ ì›Œí¬ ë…¸ë“œ í´ëŸ¬ìŠ¤í„° ì¡°ì¸\nì›Œí¬ ë…¸ë“œ ì¡°ì¸ ì¤‘ ì—ëŸ¬ê°€ ìƒê¸´ ì—ëŸ¬ì´ë‹¤. ì—ëŸ¬ ë©”ì„¸ì§€ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 (N/A:N/A) [root@myeks-host example]# eksctl create cluster -f private-cluster.yaml 2023-04-28 12:24:04 [â„¹] eksctl version 0.138.0 2023-04-28 12:24:04 [â„¹] using region ap-northeast-2 2023-04-28 12:24:04 [!] warning, having public access disallowed will subsequently interfere with some features of eksctl. This will require running subsequent eksctl (and Kubernetes) commands/API calls from within the VPC. Running these in the VPC requires making updates to some AWS resources. See: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html for more details 2023-04-28 12:24:05 [âœ”] using existing VPC (vpc-06210c8560709c761) and subnets (private:map[private-2a:{subnet-0cceb4f7117a82214 ap-northeast-2a 192.168.3.0/24 0 } private-2c:{subnet-0c19b6b58320fce0a ap-northeast-2c 192.168.4.0/24 0 }] public:map[public-2a:{subnet-023a838543987d725 ap-northeast-2a 192.168.1.0/24 0 } public-2c:{subnet-09e710a10ef0fb5ef ap-northeast-2c 192.168.2.0/24 0 }]) 2023-04-28 12:24:05 [!] custom VPC/subnets will be used; if resulting cluster doesn\u0026#39;t function as expected, make sure to review the configuration of VPC/subnets 2023-04-28 12:24:05 [â„¹] nodegroup \u0026#34;ng-2\u0026#34; will use \u0026#34;ami-0fdcb707922882aef\u0026#34; [AmazonLinux2/1.25] 2023-04-28 12:24:05 [â„¹] using EC2 key pair \u0026#34;eks-terraform-key\u0026#34; 2023-04-28 12:24:05 [â„¹] using Kubernetes version 1.25 2023-04-28 12:24:05 [â„¹] creating EKS cluster \u0026#34;my-eks\u0026#34; in \u0026#34;ap-northeast-2\u0026#34; region with un-managed nodes 2023-04-28 12:24:05 [â„¹] 1 nodegroup (ng-2) was included (based on the include/exclude rules) 2023-04-28 12:24:05 [â„¹] will create a CloudFormation stack for cluster itself and 1 nodegroup stack(s) 2023-04-28 12:24:05 [â„¹] will create a CloudFormation stack for cluster itself and 0 managed nodegroup stack(s) 2023-04-28 12:24:05 [â„¹] if you encounter any issues, check CloudFormation console or try \u0026#39;eksctl utils describe-stacks --region=ap-northeast-2 --cluster=my-eks\u0026#39; 2023-04-28 12:24:05 [â„¹] Kubernetes API endpoint access will use provided values {publicAccess=false, privateAccess=true} for cluster \u0026#34;my-eks\u0026#34; in \u0026#34;ap-northeast-2\u0026#34; 2023-04-28 12:24:05 [â„¹] CloudWatch logging will not be enabled for cluster \u0026#34;my-eks\u0026#34; in \u0026#34;ap-northeast-2\u0026#34; 2023-04-28 12:24:05 [â„¹] you can enable it with \u0026#39;eksctl utils update-cluster-logging --enable-types={SPECIFY-YOUR-LOG-TYPES-HERE (e.g. all)} --region=ap-northeast-2 --cluster=my-eks\u0026#39; 2023-04-28 12:24:05 [â„¹] 2 sequential tasks: { create cluster control plane \u0026#34;my-eks\u0026#34;, 2 sequential sub-tasks: { wait for control plane to become ready, create nodegroup \u0026#34;ng-2\u0026#34;, } } 2023-04-28 12:24:05 [â„¹] building cluster stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:24:05 [â„¹] deploying stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:24:35 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:25:05 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:26:05 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:27:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:28:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:29:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:30:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:31:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:32:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:33:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:34:06 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-cluster\u0026#34; 2023-04-28 12:36:06 [â„¹] building nodegroup stack \u0026#34;eksctl-my-eks-nodegroup-ng-2\u0026#34; 2023-04-28 12:36:06 [â„¹] --nodes-min=2 was set automatically for nodegroup ng-2 2023-04-28 12:36:06 [â„¹] --nodes-max=2 was set automatically for nodegroup ng-2 2023-04-28 12:36:07 [â„¹] deploying stack \u0026#34;eksctl-my-eks-nodegroup-ng-2\u0026#34; 2023-04-28 12:36:07 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-nodegroup-ng-2\u0026#34; 2023-04-28 12:39:43 [â„¹] waiting for CloudFormation stack \u0026#34;eksctl-my-eks-nodegroup-ng-2\u0026#34; 2023-04-28 12:39:43 [â„¹] waiting for the control plane to become ready 2023-04-28 12:39:44 [âœ”] saved kubeconfig as \u0026#34;/root/.kube/config\u0026#34; 2023-04-28 12:39:44 [â„¹] no tasks 2023-04-28 12:39:44 [âœ”] all EKS cluster resources for \u0026#34;my-eks\u0026#34; have been created 2023-04-28 12:39:44 [â„¹] adding identity \u0026#34;arn:aws:iam::955963799952:role/eksctl-my-eks-nodegroup-ng-2-NodeInstanceRole-283XKKCXM9GT\u0026#34; to auth ConfigMap 2023-04-28 12:39:44 [â„¹] nodegroup \u0026#34;ng-2\u0026#34; has 0 node(s) 2023-04-28 12:39:44 [â„¹] waiting for at least 2 node(s) to become ready in \u0026#34;ng-2\u0026#34; Error: timed out waiting for at least 2 nodes to join the cluster and become ready in \u0026#34;ng-2\u0026#34;: context deadline exceeded ë³´í†µ íƒ€ì„ì—ëŸ¬ë¡œ í‘œì‹œë˜ë©° kubectl ëª…ë ¹ì–´ë¥¼ í™•ì¸í•˜ë©´ ì›Œí¬ ë…¸ë“œê°€ ì¡°ì¸ì´ ì•ˆë˜ì–´ íŒŒë“œê°€ ì •ìƒì ìœ¼ë¡œ ë°°í¬ë˜ì§€ ì•ŠëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\ní•´ë‹¹ ë‚´ìš©ì€ ê¹ƒ ì´ìŠˆì—ì„œ ì°¸ê³ í•  ìˆ˜ ìˆì§€ë§Œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ì–´ ë©°ì¹ ì„ ê³ ìƒí–ˆë‹¤. ì›ì¸ì€ EKS ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •ì´ì˜€ë‹¤. ì•ì„œ ë² ìŠ¤ì²œì„œë²„ êµ¬ì„±ì‹œ EKS í†µì‹ ì„ ìœ„í•œ ë³´ì•ˆ ê·¸ë£¹ì„ ì„¤ì •í•˜ì˜€ëŠ”ë° ì¶”ê°€ë¥¼ ì•ˆí•˜ë©´ EKS ì›Œí¬ ë…¸ë“œì™€ ë² ìŠ¤ì²œ ì„œë²„ì™€ì˜ í†µì‹ ì´ ì•ˆë˜ì–´ ì¡°ì¸ì´ ì•ˆëœë‹¤. EKS ë³´ì•ˆ ê·¸ë£¹ì„ ì„¤ì •í•˜ê³  ë‹¤ì‹œ EKSë¥¼ ë°°í¬í•˜ì.\nAPI ì„œë²„ ì ‘ê·¼ì´ ì•ˆë˜ëŠ” ê²½ìš°\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 (N/A:N/A) [root@myeks-host example]# eksctl create cluster -f private-cluster.yaml 2023-04-27 19:45:28 [â„¹] eksctl version 0.138.0 2023-04-27 19:45:28 [â„¹] using region ap-northeast-2 2023-04-27 19:45:28 [!] warning, having public access disallowed will subsequently interfere with some features of eksctl. This will require running subsequent eksctl (and Kubernetes) commands/API calls from within the VPC. Running these in the VPC requires making updates to some AWS resources. See: https://docs.aws.amazon.com/eks/latest/userguide/cluster-endpoint.html for more details 2023-04-27 19:45:28 [â„¹] setting availability zones to [ap-northeast-2a ap-northeast-2b ap-northeast-2d] 2023-04-27 19:45:28 [â„¹] subnets for ap-northeast-2a - public:192.168.0.0/19 private:192.168.96.0/19 2023-04-27 19:45:28 [â„¹] subnets for ap-northeast-2b - public:192.168.32.0/19 private:192.168.128.0/19 2023-04-27 19:45:28 [â„¹] subnets for ap-northeast-2d - public:192.168.64.0/19 private:192.168.160.0/19 2023-04-27 19:45:28 [â„¹] nodegroup \u0026#34;EKS-PRIVATE-NODE\u0026#34; will use \u0026#34;ami-0fdcb707922882aef\u0026#34; [AmazonLinux2/1.25] 2023-04-27 19:45:28 [â„¹] using Kubernetes version 1.25 2023-04-27 19:45:28 [â„¹] creating EKS cluster \u0026#34;my-private-eks\u0026#34; in \u0026#34;ap-northeast-2\u0026#34; region with un-managed nodes ... Error: getting auth ConfigMap: Get \u0026#34;https://AA1694EDA538EFE2ADC5FCCABBB4F745.gr7.ap-northeast-2.eks.amazonaws.com/api/v1/namespaces/kube-system/configmaps/aws-auth\u0026#34;: dial tcp 192.168.175.32:443: i/o timeout (terraform-eks@my-private-eks:N/A) [root@myeks-host example]# kubectl get pods -A Unable to connect to the server: dial tcp 192.168.134.188:443: i/o timeout â†’ ì•ì—ë„ ë‹¤ë¤˜ì§€ë§Œ Timeout ì˜ ëŒ€ë¶€ë¶„ì˜ ì›ì¸ì´ ë³´ì•ˆ ê·¸ë£¹ì´ë‹¤. ì´ ê²½ìš°ëŠ” í´ëŸ¬ìŠ¤í„° êµ¬ì„± íŒŒì¼ì—ì„œ ë² ìŠ¤ì²œ ì„œë²„ì˜ ë³´ì•ˆê·¸ë£¹ì„ ì„¤ì •í•˜ì§€ ì•Šì•„ì„œ ìƒê¸´ ë¬¸ì œì˜€ë‹¤. í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì—ì„œ ë² ìŠ¤ì²œ ì„œë²„ì— ëŒ€í•œ ë³´ì•ˆ ê·¸ë£¹(ì•„ì›ƒ ë°”ìš´ë“œ ë² ìŠ¤ì²œì„œë²„ 443 í¬íŠ¸)ì„ ì„¤ì •í•˜ë©´ ëœë‹¤. í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì—ì„œ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •ì€ AWS ì½˜ì†” â†’ EKSì—ì„œ ê°€ëŠ¥í•˜ë‹¤.\nAWS CLI ë° eksctl ê²°ê³¼ i/o timeout\n1 2 (N/A:N/A) [root@myeks-host example]# eksctl get cluster --region ap-northeast-2 Error: checking AWS STS access â€“ cannot get role ARN for current session: operation error STS: GetCallerIdentity, https response error StatusCode: 0, RequestID: , request send failed, Post \u0026#34;https://sts.ap-northeast-2.amazonaws.com/\u0026#34;: dial tcp 52.95.192.98:443: i/o timeout ë§ˆì°¬ê°€ì§€ë¡œ ë³´ì•ˆ ê·¸ë£¹ ë¬¸ì œì˜€ë‹¤. ë² ìŠ¤ì²œ ì„œë²„ì˜ ì•„ì›ƒë°”ìš´ë“œì— 0.0.0.0/0ë¥¼ ì¶”ê°€í•˜ë©´ í•´ê²°ëœë‹¤.\nì½˜ì†”ì—ì„œ ì»´í“¨íŒ… ë¦¬ì†ŒìŠ¤ í™•ì¸ì´ ì•ˆë˜ëŠ” ê²½ìš°\në‹¤ìŒ ê·¸ë¦¼ê³¼ ê°™ì´ EKS ë°°í¬ì´í›„ AWS ì½˜ì†”ì—ì„œ ì›Œí¬ ë…¸ë“œê°€ í‘œì‹œë˜ì§€ ì•ŠëŠ” ê²½ìš°ì´ë‹¤.\nì›ì¸ì€ EKS í´ëŸ¬ìŠ¤í„° ì‚¬ìš©ì ì •ë³´ì— AWS ì‚¬ìš©ì ì •ë³´ê°€ ì—†ê¸° ë•Œë¬¸ì´ë‹¤. ë‹¤ìŒê³¼ ê°™ì´ ì¶”ê°€í•˜ë„ë¡ í•˜ì.\n1 kubectl edit cm/aws-auth -n kube-system 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # Please edit the object below. Lines beginning with a \u0026#39;#\u0026#39; will be ignored, # and an empty file will abort the edit. If an error occurs while saving this file will be # reopened with the relevant failures. # apiVersion: v1 data: mapRoles: | - groups: - system:bootstrappers - system:nodes rolearn: arn:aws:iam::000000000:role/eksctl-my-eks-nodegroup-ng-1-NodeInstanceRole-ZG7JVL5Z4IPU username: system:node:{{EC2PrivateDNSName}} mapUsers: | - userarn: arn:aws:iam:000000000:user/hanhorang # AWS ì¸ì¦ì—ì„œ ì‚¬ìš©í•œ IAM ì‚¬ìš©ì arnë¥¼ ì…ë ¥í•˜ì. username: hanhorang groups: - system:masters kind: ConfigMap metadata: name: aws-auth namespace: kube-system mapUsersì—ì„œ IAM ì‚¬ìš©ì arnì„ ì¶”ê°€í•˜ë©´ í•´ê²°ëœë‹¤.\ní´ëŸ¬ìŠ¤í„° êµ¬ì„± í™•ì¸ í´ëŸ¬ìŠ¤í„° êµ¬ì„± í›„ í´ëŸ¬ìŠ¤í„° ì •ë³´ì™€ ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ë¥¼ í™•ì¸í•˜ê² ë‹¤.\ní´ëŸ¬ìŠ¤í„° êµ¬ì„± í™•ì¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # í´ëŸ¬ìŠ¤í„° í™•ì¸ (terraform-eks@my-eks:N/A) [root@myeks-host example]# eksctl get cluster NAME REGION EKSCTL CREATED my-eks ap-northeast-2 True # í´ëŸ¬ìŠ¤í„° ë…¸ë“œ ê·¸ë£¹ í™•ì¸ (terraform-eks@my-eks:N/A) [root@myeks-host example]# eksctl get nodegroup --cluster my-eks CLUSTER NODEGROUP STATUS CREATED MIN SIZE MAX SIZE DESIRED CAPACITY INSTANCE TYPE IMAGE ID ASG NAMETYPE my-eks ng-1 CREATE_COMPLETE 2023-04-29T09:05:31Z 4 4 4 m5.xlarge ami-0fdcb707922882aef eksctl-my-eks-nodegroup-ng-1-NodeGroup-IWPRDQX6J0CG unmanaged # í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ì •ë³´ í™•ì¸ ë° ë…¸ë“œ í™•ì¸ (terraform-eks@my-eks:N/A) [root@myeks-host example]# kubectl get nodes -v6 I0429 20:21:39.855710 5753 loader.go:374] Config loaded from file: /root/.kube/config I0429 20:21:40.631509 5753 round_trippers.go:553] GET https://8F53A6D3D93C1D751527688A7CB07659.yl4.ap-northeast-2.eks.amazonaws.com/api/v1/nodes?limit=500 200 OK in 769 milliseconds NAME STATUS ROLES AGE VERSION ip-192-168-3-31.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 131m v1.25.7-eks-a59e1f0 ip-192-168-3-59.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 131m v1.25.7-eks-a59e1f0 ip-192-168-4-195.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 131m v1.25.7-eks-a59e1f0 ip-192-168-4-250.ap-northeast-2.compute.internal Ready \u0026lt;none\u0026gt; 131m v1.25.7-eks-a59e1f0 # í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸ kubectl cluster-info dump ... ë² ìŠ¤ì²œ ì„œë²„ì—ì„œ ì›Œí¬ ë…¸ë“œ ì ‘ê·¼ì„ ìœ„í•œ ë³´ì•ˆ ê·¸ë£¹ ì„¤ì •\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 # ì¸ìŠ¤í„´ìŠ¤ IP í™•ì¸ terraform-eks@my-eks:N/A) [root@myeks-host example]# aws ec2 describe-instances --query \u0026#34;Reservations[*].Instances[*].{PublicIPAdd:PublicIpAddress,PrivateIPAdd:PrivateIpAddress,InstanceName:Tags[?Key==\u0026#39;Name\u0026#39;]|[0].Value,Status:State.Name}\u0026#34; --filters Name=instance-state-name,Values=running --output table ------------------------------------------------------------------- | DescribeInstances | +-----------------+-----------------+------------------+----------+ | InstanceName | PrivateIPAdd | PublicIPAdd | Status | +-----------------+-----------------+------------------+----------+ | EKS-WORKER-TEST| 192.168.4.230 | None | running | | EKS-WORKER | 192.168.4.195 | None | running | | EKS-WORKER | 192.168.4.250 | None | running | | EKS-WORKER | 192.168.3.59 | None | running | | EKS-WORKER | 192.168.3.31 | None | running | | myeks-host | 192.168.1.100 | 43.201.102.195 | running | +-----------------+-----------------+------------------+----------+ # ì›Œí¬ ë…¸ë“œë¡œ Pingì„ í•˜ë‚˜ ì•ˆëœë‹¤. (terraform-eks@my-eks:N/A) [root@myeks-host example]# ping 192.168.3.31 PING 192.168.3.31 (192.168.3.31) 56(84) bytes of data. # ë…¸ë“œ ë³´ì•ˆê·¸ë£¹ ID í™•ì¸í•˜ì—¬ ë² ìŠ¤ì²œ ì„œë²„ IPë¥¼ ì¶”ê°€í•˜ì (terraform-eks@my-eks:N/A) [root@myeks-host example]# aws ec2 describe-security-groups --filters Name=group-name,Values=*nodegroup* --query \u0026#34;SecurityGroups[*].[GroupId]\u0026#34; --output text sg-0bf33458f7e193841 sg-0f4cd52a07786b9fb # --group-id ì— ìœ„ ë³´ì•ˆ ê·¸ë£¹ í•˜ë‚˜ ì…ë ¥ (terraform-eks@my-eks:N/A) [root@myeks-host example]# aws ec2 authorize-security-group-ingress --group-id sg-0f4cd52a07786b9fb --protocol \u0026#39;-1\u0026#39; --cidr 192.168.1.100/32 { \u0026#34;Return\u0026#34;: true, \u0026#34;SecurityGroupRules\u0026#34;: [ { \u0026#34;SecurityGroupRuleId\u0026#34;: \u0026#34;sgr-01bca8eecf69c86b6\u0026#34;, \u0026#34;GroupId\u0026#34;: \u0026#34;sg-0f4cd52a07786b9fb\u0026#34;, \u0026#34;GroupOwnerId\u0026#34;: \u0026#34;955963799952\u0026#34;, \u0026#34;IsEgress\u0026#34;: false, \u0026#34;IpProtocol\u0026#34;: \u0026#34;-1\u0026#34;, \u0026#34;FromPort\u0026#34;: -1, \u0026#34;ToPort\u0026#34;: -1, \u0026#34;CidrIpv4\u0026#34;: \u0026#34;192.168.1.100/32\u0026#34; } ] } # ì ‘ê·¼ í™•ì¸ (terraform-eks@my-eks:N/A) [root@myeks-host example]# ping 192.168.3.31 PING 192.168.3.31 (192.168.3.31) 56(84) bytes of data. 64 bytes from 192.168.3.31: icmp_seq=1 ttl=255 time=0.176 ms 64 bytes from 192.168.3.31: icmp_seq=2 ttl=255 time=0.152 ms 64 bytes from 192.168.3.31: icmp_seq=3 ttl=255 time=0.144 ms ì¸ìŠ¤í„´ìŠ¤ ì •ë³´ í™•ì¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 # kubelet í™•ì¸ systemctl status kubelet â— kubelet.service - Kubernetes Kubelet Loaded: loaded (/etc/systemd/system/kubelet.service; enabled; vendor preset: disabled) Drop-In: /etc/systemd/system/kubelet.service.d â””â”€10-kubelet-args.conf, 30-kubelet-extra-args.conf Active: active (running) since Sat 2023-04-29 09:08:56 UTC; 2h 49min ago Docs: https://github.com/kubernetes/kubernetes Process: 3176 ExecStartPre=/sbin/iptables -P FORWARD ACCEPT -w 5 (code=exited, status=0/SUCCESS) Main PID: 3178 (kubelet) Tasks: 16 Memory: 77.3M CGroup: /runtime.slice/kubelet.service â””â”€3178 /usr/bin/kubelet --config /etc/kubernetes/kubelet/kubelet-config.json --kubeconfig /var/lib/kubelet/kubeconfig --container-runtime-endpoint unix://... Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.377073 3178 kubelet.go:2117] \u0026#34;SyncLoop ADD\u0026#34; source=\u0026#34;api\u0026#34; pods=...sncki] Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.377103 3178 topology_manager.go:205] \u0026#34;Topology Admit Handler\u0026#34; Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.513465 3178 reconciler.go:357] \u0026#34;operationExecutor.VerifyControllerAt... Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.614154 3178 reconciler.go:269] \u0026#34;operationExecutor.MountVolume starte... Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.632046 3178 operation_generator.go:730] \u0026#34;MountVolume.SetUp succeeded... Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.703987 3178 util.go:30] \u0026#34;No sandbox for pod can be found. Need...sncki\u0026#34; Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.791915 3178 provider.go:102] Refreshing cache for provider: *c...ovider Apr 29 11:52:06 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:06.792001 3178 provider.go:82] Docker config file not found: coul...t /] Apr 29 11:52:07 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:07.235202 3178 kubelet.go:2155] \u0026#34;SyncLoop (PLEG): event for pod\u0026#34; ...a6526} Apr 29 11:52:11 ip-192-168-3-31.ap-northeast-2.compute.internal kubelet[3178]: I0429 11:52:11.242075 3178 kubelet.go:2155] \u0026#34;SyncLoop (PLEG): event for pod\u0026#34; ...4351a} Hint: Some lines were ellipsized, use -l to show in full. # ë³¼ë¥¨ í™•ì¸ lsblk NAME MAJ:MIN RM SIZE RO TYPE MOUNTPOINT nvme0n1 259:0 0 30G 0 disk â”œâ”€nvme0n1p1 259:1 0 30G 0 part / â””â”€nvme0n1p128 259:2 0 1M 0 part # ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ í™•ì¸ ps axf |grep /usr/bin/containerd 3013 ? Ssl 0:46 /usr/bin/containerd 4269 ? Sl 0:10 /usr/bin/containerd-shim-runc-v2 -namespace k8s.io -id 0ea51c82eb135fca4bdae99f89e8f5804d1e144efb857e8fae310a9d7039e21a -address /run/containerd/containerd.sock 4270 ? Sl 0:02 /usr/bin/containerd-shim-runc-v2 -namespace k8s.io -id f723a90d2f436d77f37789bc29e26fcdbca82ca575bfacde43be2a0978573634 -address /run/containerd/containerd.sock 24478 ? Sl 0:00 /usr/bin/containerd-shim-runc-v2 -namespace k8s.io -id c1657f716d01283e8e7aa183f6583ec4c96af3d1d19b081004d1c565015a6526 -address /run/containerd/containerd.sock 26752 ? S+ 0:00 \\_ grep --color=auto /usr/bin/containerd ì°¸ê³  https://awskoreamarketingasset.s3.amazonaws.com/2022 Summit/pdf/T14S4_Amazon EKS ë§ˆì´ê·¸ë ˆì´ì…˜ ìš”ì  ì •ë¦¬.pdf\nhttps://341123.tistory.com/m/6\n","date":"Apr 29","permalink":"https://HanHoRang31.github.io/post/aews-1-eks/","tags":["KANS","eks","cloud","AWS","kubernetes"],"title":"[AEWS] EKS ì•„í‚¤í…ì²˜ì™€ Private EKS í´ëŸ¬ìŠ¤í„° ë°°í¬í•˜ê¸°"},{"categories":null,"contents":" 1 2 [í…Œí¬ ë”°ë¼ì¡ê¸°]ëŠ” IT ê¸°ì—… ê¸°ìˆ  ìŠ¤íƒ ì‚¬ë¡€ë¥¼ ì°¸ê³ í•˜ì—¬ êµ¬í˜„í•˜ê³  ì •ë¦¬í•˜ëŠ” ì‹œë¦¬ì¦ˆì…ë‹ˆë‹¤. ì˜¤ë¡œì§€ ê¸°ìˆ  ì„±ì¥ì„ ìœ„í•´ ì‘ì„±í•  ì˜ˆì •ì´ë©° ìŠ¤í„°ë”” ê³¼ì •ì—ì„œ ì–»ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ê³µìœ í•˜ê³ ì í•©ë‹ˆë‹¤. ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì¸ Harborì— ëŒ€í•´ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì¡°ì‚¬í•˜ë˜ ì¤‘ ë°°ìš¸ ê²ƒì´ ë§ì€ í…Œí¬ ë¸”ë¡œê·¸ ê¸€ì„ ë°œê²¬í•˜ì˜€ë‹¤. ê·¸ëŒ€ë¡œ ê¸€ë¡œë§Œ ë³´ê¸°ì—ëŠ” í•„ìê°€ ì•„ì‰¬ì›Œì„œ ì§ì ‘ êµ¬í˜„í•˜ê³  êµ¬í˜„ ê³¼ì •ì—ì„œ ì–»ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ê³µìœ í•˜ê³ ì ë¸”ë¡œê·¸ ê¸€ì„ ì‘ì„±í•˜ì˜€ë‹¤. ì°¸ê³ í•œ í…Œí¬ ë¸”ë¡œê·¸ëŠ” ë‹¤ìŒì˜ ë§í¬ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nhttps://engineering.linecorp.com/ko/blog/harbor-for-private-docker-registry\në¸”ë¡œê·¸ ê¸€ì„ ìš”ì•½í•˜ìë©´, Private Docker Registryë¡œ Harborë¥¼ ì„ íƒí•˜ì—¬ êµ¬ì„±í•˜ì˜€ê³ , ì˜¤í”ˆì†ŒìŠ¤ ì˜¤ë¸Œì íŠ¸ ìŠ¤í† ë¦¬ì§€ì¸ Minioë¥¼ í†µí•´ ìŠ¤í† ë¦¬ì§€ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•˜ì˜€ë‹¤. ë˜í•œ ì‚¬ë‚´ LDAP ì„œë²„ë¥¼ ì´ìš©í•˜ì—¬ ì§ì› ì •ë³´ë¥¼ Harborì™€ ì—°ê³„í•˜ì—¬ ë¡œê·¸ì¸ ì •ë³´ë¥¼ ì—°ê³„í•˜ì˜€ë‹¤ê³  í•œë‹¤.\nê¸°ìˆ  êµ¬í˜„ì˜ í° í‹€ì€ ê°™ì§€ë§Œ, ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½(AWS EKS)ì—ì„œ Harborë¥¼ ë°°í¬í•˜ê³  ë„ì»¤ ì´ë¯¸ì§€ ë°±ì—”ë“œ ì €ì¥ì†Œë¡œ Minio ì‚¬ìš©í•˜ê³ ì í•œë‹¤. ë˜í•œ ê³ ê°€ìš©ì„±ì„ ê°€ì§€ê¸° ìœ„í•´ ë‹¤ì¤‘ ì§€ì—­ë³„ ë³¼ë¥¨ì„ ë¶„ì‚°ì‹œí‚¤ê³ , ë°±ì—…ì— ëŒ€í•œ ì•„í‚¤í…ì²˜ë¥¼ ì„¤ê³„í•˜ê³  êµ¬í˜„í•  ê²ƒì´ë‹¤. ì•„í‚¤í…ì²˜ë¥¼ êµ¬í˜„í•˜ë©´ì„œ ê³ ë¯¼í•œ ë¶€ë¶„ë„ ê³µìœ í•  ì˜ˆì •ì´ë‹¤.\nHarbor HarborëŠ” CNCFì—ì„œì˜ ë ˆë²¨ì´ ë§ˆì§€ë§‰ ë ˆë²¨ì¸ Graduation(ì¡¸ì—…) ë‹¨ê³„ì¸ ì˜¤í”ˆì†ŒìŠ¤ ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ì´ë‹¤. ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê¸°ëŠ¥ìœ¼ë¡œ ì•ˆì •ì„±, ìœ ìš©ì„±, ì»¤ë®¤ë‹ˆí‹° ì§€ì› ë“± ì—¬ëŸ¬ ì¸¡ë©´ì—ì„œ ì¶©ë¶„í•œ ì„±ìˆ™ë„ë¥¼ ê°–ì¶˜ ê²ƒìœ¼ë¡œ ì¸ì •ë°›ì•˜ìœ¼ë©° í•„ìš” ì‚¬ë¡€ì— ë§ê²Œ ì»¤ìŠ¤í„° ë§ˆì´ì§•ì´ ê°€ëŠ¥í•˜ë‹¤. ëŒ€í‘œì ì¸ ê¸°ëŠ¥ìœ¼ë¡œëŠ” ë©€í‹° ë ˆíŒŒí‹°í† ë¦¬ ì§€ì›, ë³´ì•ˆ ìŠ¤ìº”, ì‚¬ìš©ì ê´€ë¦¬ ê¶Œí•œ, ì´ë¯¸ì§€ ì‚¬ì´í´ ê´€ë¦¬, ë§ˆì´ê·¸ë ˆì´ì…˜, ì €ì¥ì†Œ ë³µì œ, ìŠ¤í† ë¦¬ì§€ ë°±ì—…, ë¯¸ëŸ¬ë§ ê¸°ëŠ¥ì´ ìˆë‹¤.\nê¸°ëŠ¥ë©´ì—ì„œ ë¯¸ëŸ¬ë§ê³¼ ë³µì œê°€ í—·ê°ˆë¦´ ìˆ˜ ìˆëŠ”ë° ëª©ì ì´ ë¶„ëª… ë‹¤ë¥´ë‹¤. ë¯¸ëŸ¬ë§ì€ ì‹¤ì‹œê°„ ë™ê¸°í™”ë¥¼ í†µí•´ ê³ ê°€ìš©ì„±ê³¼ ë°ì´í„° ì•ˆì •ì„±ì„ ë³´ì¥í•˜ëŠ” ê¸°ëŠ¥ì¸ ë°˜ë©´, ë³µì œëŠ” ë°ì´í„° ë¶„ì‚°, ë°±ì—… ë° ë¡œë“œ ë¶„ì‚°ì„ ìœ„í•´ ì£¼ê¸°ì ìœ¼ë¡œ ë˜ëŠ” ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë¥¼ ë³µì‚¬í•˜ëŠ” ë°©ì‹ì´ë‹¤.\nhttps://landscape.cncf.io/guide#provisioning\u0026ndash;container-registry\nì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. ì¤‘ì•™ í•˜ëŠ˜ìƒ‰ ë„¤ëª¨ ë¶€ë¶„ì´ harbor êµ¬ì„± ìš”ì†Œì´ë‹¤. í¬ê²Œ ë„¤íŠ¸ì›Œí¬ë‹¨, ì„œë¹„ìŠ¤ë‹¨, ë°ì´í„° ì•¡ì„¸ìŠ¤ ê³„ì¸µìœ¼ë¡œ êµ¬ì„±ëœë‹¤.\nhttps://github.com/goharbor/harbor/wiki/Architecture-Overview-of-Harbor\në„¤íŠ¸ì›Œí¬ ê³„ì¸µ(Proxy) : Nginx ì„œë²„ì— ì˜í•´ í˜•ì„±ëœ ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œì´ë‹¤. í•˜ë²„ì˜ ì„œë¹„ìŠ¤ êµ¬ì„± ìš”ì†ŒëŠ” ëª¨ë‘ ì´ ì—­ë°©í–¥ í”„ë¡ì‹œ ë’¤ì— ìˆìœ¼ë©° Proxyë¥¼ í†µí•´ ì „ë‹¬ëœë‹¤. ì´ë¥¼ í†µí•´ ë¡œë“œ ë°¸ëŸ°ì‹±, ë³´ì•ˆ, SSL/TLS ë¶€í•˜ ê´€ë¦¬, ìºì‹± ë¶€í•˜ ê°œì„ , ì••ì¶• ê°œì„ ë“±ì˜ ì´ì ì„ ì–»ì„ ìˆ˜ ìˆë‹¤. ì„œë¹„ìŠ¤ ê³„ì¸µ(Core) : Harbor CoreëŠ” í”„ë¡œì íŠ¸ ê´€ë¦¬, ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬, ì‹œìŠ¤í…œ ì„¤ì • ê´€ë¦¬, ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ ë° ì´ë²¤íŠ¸ ì²˜ë¦¬ì™€ ê°™ì€ ë‹¤ì–‘í•œ í•µì‹¬ ê¸°ëŠ¥ì„ ë‹´ë‹¹í•˜ëŠ” ì¤‘ì‹¬ ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì„¸ë¶€ ê¸°ëŠ¥ì€ ë‹¤ìŒê³¼ ê°™ë‹¤. í”„ë¡œì íŠ¸ ê´€ë¦¬: Harbor CoreëŠ” í”„ë¡œì íŠ¸ì˜ ìƒì„±, ìˆ˜ì •, ì‚­ì œ ë° êµ¬ì„±ì„ ê´€ë¦¬í•œë‹¤. í”„ë¡œì íŠ¸ëŠ” ì‚¬ìš©ìê°€ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì™€ Helm ì°¨íŠ¸ë¥¼ êµ¬ì„± ë° ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” ë…¼ë¦¬ì  ìƒìœ„ ë ˆë²¨ì˜ ë‹¨ìœ„ì´ë‹¤ ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬: Harbor CoreëŠ” ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬ë¥¼ ìˆ˜í–‰í•œë‹¤. ì´ë¥¼ í†µí•´ íŠ¹ì • í”„ë¡œì íŠ¸ì— ëŒ€í•œ ì ‘ê·¼ ê¶Œí•œì„ ì œì–´í•  ìˆ˜ ìˆìœ¼ë©°, ì‚¬ìš©ìëŠ” ìì‹ ì˜ ê¶Œí•œ ë²”ìœ„ ë‚´ì—ì„œ ì´ë¯¸ì§€ ë° ì°¨íŠ¸ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. HarborëŠ” ì—¬ëŸ¬ ì¸ì¦ ë°©ì‹ì„ ì§€ì›í•˜ë©°, ì™¸ë¶€ ì¸ì¦ ì‹œìŠ¤í…œê³¼ì˜ í†µí•©ë„ ê°€ëŠ¥í•˜ë‹¤. ì‹œìŠ¤í…œ ì„¤ì •: Harbor CoreëŠ” ì „ì²´ ì‹œìŠ¤í…œì— ëŒ€í•œ ë‹¤ì–‘í•œ ì„¤ì •ì„ ê´€ë¦¬í•œë‹¤. ì´ì—ëŠ” ê³µí†µ ì„¤ì •, ë„¤íŠ¸ì›Œí¬ ì„¤ì •, ìŠ¤í† ë¦¬ì§€ ì„¤ì •, ë³´ì•ˆ ì„¤ì •, ë¡œê¹… ë° ëª¨ë‹ˆí„°ë§ ì„¤ì • ë“±ì´ í¬í•¨ëœë‹¤. ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜: Harbor CoreëŠ” ë‹¤ë¥¸ ì„œë¹„ìŠ¤ ì»´í¬ë„ŒíŠ¸ì™€ì˜ ìƒí˜¸ ì‘ìš©ì„ ì¡°ì •í•œë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ì´ë¯¸ì§€ ìŠ¤ìº” ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´, í•´ë‹¹ ì‘ì—…ì„ Job Serviceì— ì „ë‹¬í•˜ê³ , ê²°ê³¼ë¥¼ ì‚¬ìš©ìì—ê²Œ ì „ë‹¬í•œë‹¤. ì´ë²¤íŠ¸ ì²˜ë¦¬: Harbor CoreëŠ” ì‹œìŠ¤í…œ ë‚´ë¶€ì˜ ì´ë²¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ë©°, í•„ìš”í•œ ê²½ìš° ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ì™€ ìƒí˜¸ ì‘ìš©í•˜ì—¬ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. ì´ëŸ¬í•œ ì´ë²¤íŠ¸ì—ëŠ” ì´ë¯¸ì§€ ë° ì°¨íŠ¸ì˜ ìƒì„±, ìˆ˜ì •, ì‚­ì œ ë“±ì´ í¬í•¨ëœë‹¤. ë°ì´í„° ì•¡ì„¸ìŠ¤ ê³„ì¸µ(Data Access Layer) : 3ê°€ì§€ë¡œ êµ¬ì„±ë˜ë©° kv-storage(Redis ì‘ì—… ë°ì´í„°ì— ëŒ€í•œ ìºì‹± ìŠ¤í† ë¦¬ì§€), Local / Remote Storage(ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥ì†Œ) , SQL Database(PostgreSQL í”„ë¡œì íŠ¸, ì‚¬ìš©ì, ì—­í• , ë³µì œ ì •ì±…, íƒœê·¸ ë³´ì¡´ ì •ì±…, ìŠ¤ìºë„ˆ, ì°¨íŠ¸ ë° ì´ë¯¸ì§€ì™€ ê°™ì€ Harbor ëª¨ë¸ì˜ ê´€ë ¨ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥)ì„ ìˆ˜í–‰í•œë‹¤. ê³µì‹ë¬¸ì„œì— ë”°ë¥´ë©´ HarborëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìƒíƒœ ë¹„ì €ì¥ ìƒíƒœì´ë©° íŒŒë“œê°„ ë³µì œê°€ ê°€ëŠ¥í•˜ì—¬ íŒŒë“œ HAë¥¼ ì œê³µí•œë‹¤. í•˜ì§€ë§Œ ìŠ¤í† ë¦¬ì§€ ê³„ì¸µ ë ˆë²¨ì—ì„œëŠ” ì‚¬ìš©ìê°€ ê³ ê°€ìš©ì„± PostgreSQL, ì• í”Œë¦¬ì¼€ì´ì…˜ ë°ì´í„° ë° PVCë¥¼ ìœ„í•œ Redis í´ëŸ¬ìŠ¤í„° ë˜ëŠ” ì´ë¯¸ì§€ ë° ì°¨íŠ¸ë¥¼ ì €ì¥í•˜ê¸° ìœ„í•œ ìŠ¤í† ë¦¬ì§€ë¥¼ êµ¬ì¶•í•´ì•¼ í•œë‹¤.\nhttps://goharbor.io/docs/1.10/install-config/harbor-ha-helm/\nì´ì— ë”°ë¼ ìŠ¤í† ë¦¬ì§€ ê³„ì¸µì—ì„œì˜ ê³ ê°€ìš©ì„±ì„ êµ¬ì„±í•˜ê³ ì í•œë‹¤. Harbor í—¬ë¦„ ì°¨íŠ¸ë¥¼ í™•ì¸í•˜ë©´ ìŠ¤í† ë¦¬ì§€ ê´€ë ¨ ì„¤ì •ë¶€ë¶„ì´ 6ê°œì´ë‹¤. ê° ìŠ¤í† ë¦¬ì§€ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nRegistry: Docker ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìŠ¤í† ë¦¬ì§€ì´ë‹¤. ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë° Helm ì°¨íŠ¸ì™€ ê°™ì€ ì•„í‹°íŒ©íŠ¸ë¥¼ ì €ì¥í•˜ê³  ê´€ë¦¬í•œë‹¤. ChartMuseum: Helm ì°¨íŠ¸ ë ˆí¬ì§€í† ë¦¬ ìŠ¤í† ë¦¬ì§€ì´ë‹¤. Helm ì°¨íŠ¸ë¥¼ ì €ì¥í•˜ê³  ì œê³µí•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. JobService: JobServiceì˜ ë¡œê·¸ ë° ì‘ì—… ë°ì´í„°ë¥¼ ì €ì¥í•œë‹¤. JobServiceëŠ” ì´ë¯¸ì§€ ë ˆí”Œë¦¬ì¼€ì´ì…˜, ê°€ë¹„ì§€ ìˆ˜ì§‘, ìŠ¤ìº” ì‘ì—… ë“±ì˜ ì‘ì—…ì„ ìˆ˜í–‰í•œë‹¤. Database: Harborì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ì´ë‹¤. í”„ë¡œì íŠ¸, ì‚¬ìš©ì, ê¶Œí•œ ë° êµ¬ì„± ì •ë³´ì™€ ê°™ì€ ë©”íƒ€ë°ì´í„°ë¥¼ ì €ì¥í•œë‹¤ Redis: Harborì—ì„œ ì‚¬ìš©í•˜ëŠ” ìºì‹± ë° ë©”ì‹œì§€ í ì„œë¹„ìŠ¤ì´ë‹¤. Trivy: ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ì˜ ì·¨ì•½ì  ìŠ¤ìº”ì„ ìˆ˜í–‰í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ìŠ¤ìºë„ˆì´ë‹¤. ì´ êµ¬ì„± ìš”ì†Œì˜ ë³¼ë¥¨ì€ ì·¨ì•½ì  ë°ì´í„°ë² ì´ìŠ¤ ë° ìŠ¤ìº” ê²°ê³¼ë¥¼ ì €ì¥í•œë‹¤. 6ê°œì˜ ìŠ¤í† ë¦¬ì§€ ì¤‘ ê³ ê°€ìš©ì„± êµ¬ì„±ì„ ìœ„í•œ ìŠ¤í† ë¦¬ì§€ëŠ” 3ê°œì´ë‹¤.\nRegistry : ë„ì»¤ ì´ë¯¸ì§€ ì €ì¥ì†Œ ChartMuseum : helm ì°¨íŠ¸ ì €ì¥ì†Œ Database : Harbor ë©”íƒ€ë°ì´í„° ì €ì¥ì†Œ Harborì—ì„œëŠ” ìŠ¤í† ë¦¬ì§€ë¡œ block storage, file storage, object stroage ë¡œ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. ë‹¤ë§Œ, ì €ì¥ì†Œì˜ ì„±ëŠ¥ ë° í™œìš© íŠ¹ì„±ìœ¼ë¡œ ì €ì¥ì†Œë³„ ìŠ¤í† ë¦¬ì§€ë¥¼ ì„¤ì •í•´ì•¼ í•œë‹¤. í—¬ë¦„ ì°¨íŠ¸ë¥¼ í™•ì¸í•˜ë©´ ë„ì»¤ ì´ë¯¸ì§€ ì €ì¥ì†ŒëŠ” object ìŠ¤í† ë¦¬ì§€ë¡œ ë‚˜ë¨¸ì§€ ì €ì¥ì†ŒëŠ” ë¸”ë¡ ìŠ¤í† ë¦¬ì§€ë¡œ ì„¤ì • ì¶”ì²œí•˜ëŠ”ë° ì´ìœ ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\në„ì»¤ ì´ë¯¸ì§€ ì €ì¥ì†Œë¥¼ object storage(ì˜ˆ: Amazon S3)ë¡œ ì‚¬ìš©í•˜ëŠ” ì´ìœ :\ní™•ì¥ì„±: Object storageëŠ” ê±°ì˜ ë¬´ì œí•œì˜ ì €ì¥ ìš©ëŸ‰ì„ ì œê³µí•˜ë¯€ë¡œ, ë§ì€ ë„ì»¤ ì´ë¯¸ì§€ë¥¼ ì €ì¥í•  ìˆ˜ ìˆë‹¤. ë‚´êµ¬ì„±: Object storageëŠ” ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ë¬¼ë¦¬ì  ìœ„ì¹˜ì— ìë™ìœ¼ë¡œ ë³µì œí•˜ë¯€ë¡œ, ë°ì´í„° ì†ì‹¤ì˜ ìœ„í—˜ì´ ë‚®ë‹¤. ë¹„ìš© íš¨ìœ¨: ì¼ë°˜ì ìœ¼ë¡œ object storageëŠ” ìš©ëŸ‰ ë‹¹ ë¹„ìš©ì´ ë‚®ê³ , ì €ì¥ëœ ë°ì´í„°ì— ë”°ë¼ ë¹„ìš©ì´ ì¦ê°€í•œë‹¤. ê¸°íƒ€ ì €ì¥ì†Œë¥¼ ë¸”ë¡ ìŠ¤í† ë¦¬ì§€(ì˜ˆ: AWS EBS)ë¡œ ì €ì¥í•˜ëŠ” ì´ìœ :\në†’ì€ IOPS: EBSëŠ” ë†’ì€ IOPS(Input/Output Operations Per Second) ì„±ëŠ¥ì„ ì œê³µí•˜ë¯€ë¡œ, ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì— ì í•©í•˜ë‹¤. ì§€ì—° ì‹œê°„ ìµœì†Œí™”: ë¸”ë¡ ìŠ¤í† ë¦¬ì§€ëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì— í•„ìš”í•œ ë¹ ë¥¸ ì½ê¸°/ì“°ê¸° ì‘ì—…ì´ ê°€ëŠ¥í•˜ë‹¤. ì¼ê´€ëœ ì„±ëŠ¥: EBSëŠ” ì¼ê´€ëœ ì„±ëŠ¥ì„ ì œê³µí•˜ì—¬ ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì˜ ì•ˆì •ì„±ì„ ë³´ì¥í•œë‹¤. ìŠ¤ëƒ…ìƒ· ë° ë°±ì—…: EBS ë³¼ë¥¨ì˜ ìŠ¤ëƒ…ìƒ·ì„ ì‰½ê²Œ ìƒì„±í•  ìˆ˜ ìˆìœ¼ë©°, ë°ì´í„°ë² ì´ìŠ¤ ë°±ì—… ë° ë³µêµ¬ë¥¼ ìš©ì´í•˜ê²Œ í•œë‹¤. ì¶”ì²œ ìŠ¤í† ë¦¬ì§€ì— ë”°ë¼ ìŠ¤í† ë¦¬ì§€ êµ¬ì„±í•  ê²ƒì¸ë° ë„ì»¤ ì´ë¯¸ì§€ ì €ì¥ì†Œë¡œëŠ” Minio ì˜¤ë¸Œì íŠ¸ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ê·¸ë¦¬ê³  ë‚˜ë¨¸ì§€ ì €ì¥ì†ŒëŠ” AWS EBSë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ë˜í•œ ë°±ì—…ì„ ìœ„í•´ ì˜¤í”ˆì†ŒìŠ¤ ë°±ì—… ì†”ë£¨ì…˜ì¸ Veleroë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ì¢…í•©í•˜ì—¬ AWS ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì„±í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\ní†µì‹  ì‹œë‚˜ë¦¬ì˜¤ì— ë”°ë¼ ìƒ‰ê¹”ì„ ë‹¬ë¦¬ í‘œí˜„í–ˆë‹¤.ì´ì–´ì„œ í†µì‹  ì‹œë‚˜ë¦¬ì˜¤ ë° ì„¸ë¶€ ì»´í¬ë„ŒíŠ¸(MiniO)ì„ ì•Œì•„ë³´ê² ë‹¤.\nusers (ë³´ë¼ì„ ) : Harborì— ì ‘ì†í•´ì„œ ë„ì»¤ ì´ë¯¸ì§€ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ” ê°œë°œì ë° ë ˆì§€ìŠ¤íŠ¸ë¦¬ ê´€ë¦¬ìì´ë‹¤. Harbor ë„ë©”ì¸ì„ í†µí•´ ELBë¥¼ ê±°ì³ harbor ingress ë¡œ í†µì‹ í•œë‹¤. Storage(íŒŒë‘ì„ ) : ìŠ¤í† ë¦¬ì§€ ë³¼ë¥¨ ì—°ê³„ë„ì´ë‹¤. ì„¤ê³„ ëª©ì ê³¼ ê°™ì´ Harbor Registry ì €ì¥ì†ŒëŠ” Minioë¡œ ë‚˜ë¨¸ì§€ ì €ì¥ì†ŒëŠ” PV(EBS) ë¡œ ì ì¬í–ˆë‹¤. Backup(ì´ˆë¡ì„ ) : ë°±ì—… íˆ´ì¸ Veleroë¥¼ í†µí•´ S3 ì— ë°ì´í„°ë¥¼ ë°±ì—…ì‹œí‚¨ë‹¤. Admin(ë¹¨ê°•ì„ ) : ì¸í”„ë¼ ê´€ë¦¬ìëŠ” Bestion serverì— ì ‘ì†í•˜ì—¬ ì¿ ë²„ë„¤í‹°ìŠ¤ ë° ì¸í”„ë¼ë¥¼ ê´€ë¦¬í•œë‹¤. Minio MinIO ëŠ”Â AWSì˜ S3 SDKì™€ í˜¸í™˜ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ Object Storageì´ë‹¤. Minio ëª¨ë“œ ì¤‘ Distributed ModeëŠ” Minioì˜ ë¶„ì‚° ëª¨ë“œë¡œ, ì—¬ëŸ¬ ì„œë²„ ë˜ëŠ” ë…¸ë“œ ê°„ì— ë°ì´í„°ë¥¼ ë¶„ì‚° ì €ì¥í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. ë¶„ì‚° ëª¨ë“œëŠ” ë†’ì€ ê°€ìš©ì„±, ë‚´êµ¬ì„±, ê·¸ë¦¬ê³  ìŠ¤ì¼€ì¼ ì•„ì›ƒ í™•ì¥ì„±ì„ ì œê³µí•œë‹¤.\nêµ¬ì„±ì‹œ ì¤‘ìš”í•œ ì ìœ¼ë¡œ Distributed MinIO ì˜ ë””ìŠ¤í¬ì´ë‹¤. ë¶„ì‚° ëª¨ë“œì—ì„œëŠ” ìµœì†Œ 4ê°œì˜ ë””ìŠ¤í¬ê°€ í•„ìš”í•˜ë‹¤. ë¶„ì‚°ìŠ¤í† ë¦¬ì§€ì˜ ë°ì´í„° ë³µêµ¬ ê¸°ëŠ¥ìœ¼ë¡œ Erasure Coding ì•Œê³ ë¦¬ì¦˜ì„ ì±„íƒí•˜ê¸° ë•Œë¬¸ì¸ë° ì›ë³¸ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì¡°ê°ìœ¼ë¡œ ë‚˜ëˆ„ê³ , ê° ì¡°ê°ì— ëŒ€í•´ íŒ¨ë¦¬í‹° ì •ë³´ë¥¼ ìƒì„±í•˜ì—¬ ë¶„ì‚° ì €ì¥í•œë‹¤. ì´ì—ë”°ë¼ ë°ì´í„° ë³µêµ¬ì— N/2 ë°ì´í„° ë¸”ë¡ê³¼ N/2 íŒ¨ë¦¬í‹° ë¸”ë¡ ì¡°ê±´ì„ ë§Œì¡±í•´ì•¼ í•˜ë©° ìµœì†Œ 4ê°œ ì´ìƒì˜ ë””ìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´ë ‡ê²Œ êµ¬ì„±í•˜ë©´ ìµœëŒ€ íŒ¨ë¦¬í‹°ì—ì„œ MinIOëŠ” ì‚­ì œ ì„¸íŠ¸ë‹¹ ìµœëŒ€ ì ˆë°˜ì˜ ë“œë¼ì´ë¸Œ ì†ì‹¤ì„ í—ˆìš©í•  ìˆ˜ ìˆë‹¤.\në°°í¬ ì„¤ì¹˜ í™˜ê²½ : EKS í´ëŸ¬ìŠ¤í„° (k8s 1.24), AWS Ubuntu ì¸ìŠ¤í„´ìŠ¤ ì†”ë£¨ì…˜ ìµœì†Œ ìš”êµ¬ ì‚¬í•­ Harbor (CPU 2 core , 4GB, 40 GB) Distributed MinIO ( CPU 1~2 core, 2~4GB, ë¶„ì‚° Minio) Velero ( CPU 1 core, 1GB, ë””ìŠ¤í¬ ê³µê°„ ì•Œì•„ì„œ..) ì›í™œí•œ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì•½ CPU 5 core ì´ìƒ, ë©”ëª¨ë¦¬ 8ê¸°ê°€ ì´ìƒì´ í•„ìš”í•˜ë‹¤. í•„ìì˜ ê²½ìš° ì›Œí¬ë…¸ë“œë¥¼ c5a.2xlarge ë¡œ 3ê°œ($0.344 *2) ì„¤ì„±í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.\nDistributed MinIO ë°°í¬ ì„¤ì¹˜ëŠ” minio helm ì°¸ê³ í•˜ì—¬ êµ¬ì„±í•˜ì˜€ë‹¤.\n1 2 3 4 helm repo add minio https://charts.bitnami.com/bitnami helm repo update helm fetch minio/minio --untar --version 12.2.1 êµ¬ì„± ì˜µì…˜ë³„ë¡œ ìˆ˜ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # values-minio.yaml mode: distributed auth: rootUser: admin rootPassword: \u0026#34;admin1234\u0026#34; statefulset: replicaCount: 2 zones: 2 drivesPerNode: 1 provisioning: config: - name: region options: name: ap-northeast-2 ingress: enabled: true hostname: minio.hanhorang.link path: /* annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}, {\u0026#34;HTTPS\u0026#34;:9090}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: {ACM arn ì…ë ¥} persistence: storageClass: \u0026#34;kops-csi-1-21\u0026#34; ë¶„ì‚° ëª¨ë“œì—ì„œ ì¸ìŠ¤í„´ìŠ¤ ì„¤ì •ì€ statuefulsetì—ì„œ ì„¤ì •í•œë‹¤. replicaCount: ê° zonesë‹¹ ì‹¤í–‰ë˜ëŠ” ì‹¤í–‰ë˜ëŠ” íŒŒë“œì˜ ìˆ˜ë¥¼ ì„¤ì •í•œë‹¤. zones: AWSì˜ ê°€ìš©ì˜ì—­ì´ë¼ ìƒê°í•˜ë©´ ëœë‹¤. ë¶„ì‚°ìŠ¤í† ë¦¬ì§€ë¡œ ì‚¬ìš©í•  ì˜ì—­ ê°œìˆ˜ë¥¼ ì§€ì •í•œë‹¤. drivesPerNode: ê° ì›Œì»¤ ë…¸ë“œì— ì—°ê²°ëœ ë””ìŠ¤í¬ ìˆ˜ë¥¼ 1ê°œë¡œ ì„¤ì •í•œë‹¤. ì´ ì„¤ì •ì— ë”°ë¼ ê° MinIO íŒŒë“œëŠ” í•˜ë‚˜ì˜ ë””ìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ê²Œ ëœë‹¤. ë°°í¬\n1 2 kubectl create ns minio helm install minio minio/minio -f values-minio.yaml -n minio --version 12.2.1 ë°°í¬ ì™„ë£Œí›„, ë„ë©”ì¸ìœ¼ë¡œ ì ‘ì†í•˜ì—¬ í™•ì¸í•´ë³´ì. ë„ë©”ì¸ì€ í—¬ë¦„ ì°¨íŠ¸ì˜ ingress.hostnameì— ì…ë ¥í•œ ê°’ì´ë‹¤.\nì–´ë“œë¯¼ ê³„ì •ì€ ì°¨íŠ¸ì—ì„œ admin / admin1234 ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤. ë¡œê·¸ì¸ì„ í•˜ì.\në¡œê·¸ì¸ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nHarbor ì—°ë™ì„ ìœ„í•˜ì—¬ ì ‘ì†í•œ Minio ì—ì„œ ë²„í‚· ìƒì„±ê³¼ Access Keyë¥¼ ë°œê¸‰ë°›ì•„ì•¼ í•œë‹¤. ë²„í‚· ì´ë¦„ê³¼ Access keysëŠ” Harbor êµ¬ì„± í—¬ë¦„ ì°¨íŠ¸ì—ì„œ í•„ìš”í•˜ë‹¤.\në²„í‚· ìƒì„±\nì´ˆê¸° í™”ë©´ Object Brower ì—ì„œ ë²„í‚· ìƒì„±ì´ ê°€ëŠ¥í•˜ë‹¤.\nAccess Key ë°œê¸‰\nAccess Keys ì—ì„œ ë°œê¸‰ë°›ì.\nCreate ë²„íŠ¼ ìŠì§€ë§ê³  í´ë¦­í•˜ì.\nAccess Key ë°œê¸‰ í›„ MINIO ë™ì‘ ê¶Œí•œì„ ë“±ë¡í•´ì•¼ í•œë‹¤. ìƒì„±í•œ í‚¤ë¥¼ í´ë¦­í•˜ë©´ ì •ì±… ì…ë ¥ ì¹¸ì´ ë‚˜ì˜¨ë‹¤. ì•„ë˜ ì •ì±…ì„ ì…ë ¥í•˜ë„ë¡ í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;admin:*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::*\u0026#34; ] } ] } Harbor ë°°í¬ Harbor êµ¬ì„±ë„ ë§ˆì°¬ê°€ì§€ë¡œ helmë¡œ ë°°í¬í•  ê²ƒì´ë‹¤. ë¨¼ì € í—¬ë¦„ ì°¨íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê² ë‹¤.\n1 2 3 4 helm repo add harbor https://helm.goharbor.io helm repo update # ì°¨íŠ¸ ì–»ê¸° helm show values **harbor/harbor** \u0026gt; values.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 #values-harbor.yaml # network ì„¤ì • expose: tls: certSource: none ingress: hosts: core: harbor.hanhorang.link notary: notary.hanhorang.link controller: alb className: alb annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: {ACM arn ì…ë ¥} externalURL: https://harbor.hanhorang.link # Storage ì„¤ì • persistence: persistentVolumeClaim: registry: storageClass: \u0026#34;kops-csi-1-21\u0026#34; chartmuseum: storageClass: \u0026#34;kops-csi-1-21\u0026#34; database: storageClass: \u0026#34;kops-csi-1-21\u0026#34; imageChartStorage: disableredirect: true type: s3 s3: region: ap-northeast-2 bucket: registry accesskey: \u0026lt;minio-access-key\u0026gt; secretkey: \u0026lt;minio-secret-key\u0026gt; regionendpoint: http://minio.minio.svc.cluster.local:9000 # HA core: replicas: 3 ìŠ¤í† ë¦¬ì§€ ì—°ë™ì€ persistenceì—ì„œ ì§„í–‰í•œë‹¤. registry ë¶€ë¶„ ì—°ë™ì€ imageChartStorageì—ì„œ ì„¤ì •í•œë‹¤. imageChartStorage.s3 ì—ì„œ minio ì—ì„œ ë°œê¸‰ë°›ì€ í‚¤ë¥¼ ì…ë ¥í•œë‹¤. imageChartStorage.s3.regionpoint ëŠ” minio ì˜ DNS ì •ë³´ë¥¼ ì…ë ¥í–ˆë‹¤. ì¸ê·¸ë˜ìŠ¤ë¡œ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‚˜, ë‹¤ìŒê³¼ ê°™ì€ ì—ëŸ¬ë¡œ DNS ë¡œ ì„¤ì •í•˜ì˜€ë‹¤. ë„¤íŠ¸ì›Œí¬ ì„¤ì •ìœ¼ë¡œ ì˜¤ë¥˜ ë°œìƒì‹œ ë‹¤ìŒì˜ ë©”ì„¸ì§€ë¥¼ í™•ì¸í•˜ì. ğŸ§Â minio ë„¤íŠ¸ì›Œí¬ ì„¤ì • ê´€ë ¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…\nregionendpoint ì„¤ì •ì— ë”°ë¼ ì—ëŸ¬ê°€ ë°œìƒí•˜ì—¬ ì •ë¦¬í•œë‹¤.\n1 kubectl logs harbor-core-5b7864c575-rnfm9 -n harbor regionendpoint: minio.hanhorang.link ì˜ ê²½ìš° ë„ë©”ì¸ì€ minioì˜ ALB ë„ë©”ì¸ ì£¼ì†Œì´ë‹¤. Minio ëŠ” S3ì™€ í˜¸í™˜ë˜ëŠ” SDKë¥¼ ê°€ì§€ê³  ìˆë‹¤. ì•„ë˜ ë¡œê·¸ ë©”ì„¸ì§€ì˜ ê²½ìš° í¬íŠ¸ë¥¼ ì§€ì •í•˜ì§€ ì•Šì•„ ìƒê¸´ ì˜¤ë¥˜ë‹¤.\n1 2 3 4 5 2023-03-21T16:59:40Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;2236a0c4-55cd-4e5c-989d-1b9f941efb25\u0026#34;]: failed to populate properties for project library, error: get chart count of project 1 failed: http error: code 500, message InvalidArgument: S3 API Requests must be made to API port. status code: 400, request id: , host id: 2023-03-21T16:59:40Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;2236a0c4-55cd-4e5c-989d-1b9f941efb25\u0026#34;]: failed to populate properties for project test, error: get chart count of project 2 failed: http error: code 500, message InvalidArgument: S3 API Requests must be made to API port. status code: 400, request id: , host id: 2023-03-21T16:59:42Z [ERROR] [/lib/http/error.go:56]: {\u0026#34;errors\u0026#34;:[{\u0026#34;code\u0026#34;:\u0026#34;UNKNOWN\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;get chart count of project 2 failed: http error: code 500, message InvalidArgument: S3 API Requests must be made to API port.\\n\\tstatus code: 400, request id: , host id: \u0026#34;}]} regionendpoint: minio.hanhorang.link:9000 ê²½ìš° í¬íŠ¸ 9000ì„ ì¶”ê°€í•˜ë‹ˆ Timeoutì´ ë°œìƒí•œë‹¤. harbor ALBì—ì„œ ë‹¤ì‹œ minio ALBë¡œ ê±°ì¹˜ëŠ” ê³¼ì •ì—ì„œ ì‹œê°„ì´ ì´ˆê³¼ëœ ê²ƒìœ¼ë¡œ ì˜ˆìƒëœë‹¤.\n1 2 3 4 5 2023-03-21T16:55:40Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;a0aed46e-4d11-4459-af04-2efa9f94cbf3\u0026#34;]: failed to populate properties for project library, error: get chart count of project 1 failed: get content failed: send request GET /library/index.yaml failed: Get \u0026#34;http://harbor-chartmuseum/library/index.yaml\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2023-03-21T16:55:40Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;a0aed46e-4d11-4459-af04-2efa9f94cbf3\u0026#34;]: failed to populate properties for project test, error: get chart count of project 2 failed: get content failed: send request GET /test/index.yaml failed: Get \u0026#34;http://harbor-chartmuseum/test/index.yaml\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2023-03-21T16:55:56Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;8e0c7248-9425-4862-b066-9b4b29151105\u0026#34;]: failed to populate properties for project test, error: get chart count of project 2 failed: get content failed: send request GET /test/index.yaml failed: Get \u0026#34;http://harbor-chartmuseum/test/index.yaml\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2023-03-21T16:55:56Z [ERROR] [/server/v2.0/handler/project.go:509][requestID=\u0026#34;8e0c7248-9425-4862-b066-9b4b29151105\u0026#34;]: failed to populate properties for project library, error: get chart count of project 1 failed: get content failed: send request GET /library/index.yaml failed: Get \u0026#34;http://harbor-chartmuseum/library/index.yaml\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers) 2023-03-21T16:56:29Z [ERROR] [/lib/http/error.go:56]: {\u0026#34;errors\u0026#34;:[{\u0026#34;code\u0026#34;:\u0026#34;UNKNOWN\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;get chart count of project 2 failed: get content failed: send request GET /test/index.yaml failed: Get \\\u0026#34;http://harbor-chartmuseum/test/index.yaml\\\u0026#34;: context deadline exceeded (Client.Timeout exceeded while awaiting headers)\u0026#34;}]} regionendpoint: minio.minio.svc.cluster.local:9000 ê²½ìš°\në„ë©”ì¸ ì—°ê²°ì˜ ìµœì†Œë¡œ í•˜ê¸° ìœ„í•´ CoreDNSë¥¼ ì‚¬ìš©í–ˆë‹¤. ê·¸ëŸ¬ë‚˜ HTTP ì„¤ì •ìœ¼ë¡œ ì—ëŸ¬ê°€ ë°œìƒí–ˆë‹¤.\n1 2023-03-21T16:35:45Z [ERROR] [/lib/http/error.go:56]: {\u0026#34;errors\u0026#34;:[{\u0026#34;code\u0026#34;:\u0026#34;UNKNOWN\u0026#34;,\u0026#34;message\u0026#34;:\u0026#34;get chart count of project 2 failed: http error: code 500, message RequestError: send request failed\\ncaused by: Get \\\u0026#34;https://minio.minio.svc.cluster.local:9000/minio-test?prefix=test\\\u0026#34;: http: server gave HTTP response to HTTPS client\u0026#34;}]} regionendpoint: http://minio.hanhorang.link:9000\nHTTPë¥¼ ë¶™ì´ë‹ˆ ì •ìƒì ìœ¼ë¡œ ì—°ë™ì´ í™•ì¸ëœë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ ë‚´ë¶€ì—ì„œ ì—°ê²°í•˜ëŠ” ê²ƒì´ë¼ HTTPS íŠ¸ë˜í”½ ë¶€í•˜ë¥¼ ìµœì†Œí™”í•˜ëŠ” ëª©ì ìœ¼ë¡œ HTTPë¥¼ ì‚¬ìš©í•˜ì—¬ ì„¤ì •í–ˆë‹¤.\n1 2 3 kubectl create ns harbor helm install harbor harbor/harbor -f values-harbor.yaml --namespace harbor --version 1.11.0 ë°°í¬ í™•ì¸ í—¬ë¦„ì°¨íŠ¸ì—ì„œ ì…ë ¥ harbor ë„ë©”ì¸ìœ¼ë¡œ ì ‘ê·¼í•˜ë©´ ë¡œê·¸ì¸ í™”ë©´ì´ ë‚˜ì˜¨ë‹¤. ì´ˆê¸° admin ìœ ì €ì˜ ì ‘ì† ì •ë³´ëŠ” admin / Harbor12345 ì´ë‹¤. ë¡œê·¸ì¸í•˜ë©´ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì •ë³´ê°€ ë‚˜ì˜¨ë‹¤.\nNew Project ë²„íŠ¼ì„ ëˆŒëŸ¬ ë ˆì§€ìŠ¤íŠ¸ë¦¬ í”„ë¡œì íŠ¸ì— ë²„í‚·ì„ ìƒì„±í•˜ì\nì—°ë™ í…ŒìŠ¤íŠ¸ ì„ì˜ì˜ ë„ì»¤ ì´ë¯¸ì§€ PULL \u0026amp; PUSH í•˜ì—¬ Harbor ë ˆì§€ìŠ¤íŠ¸ë¦¬, Minio ë²„í‚·ì— ë°ì´í„°ê°€ ì €ì¥ë˜ëŠ” ì§€ í™•ì¸í•´ë³´ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 docker pull nginx \u0026amp;\u0026amp; docker pull busybox \u0026amp;\u0026amp; docker images docker tag busybox harbor.$KOPS_CLUSTER_NAME/test/busybox:0.1 echo \u0026#39;Harbor12345\u0026#39; \u0026gt; harborpw.txt cat harborpw.txt | docker login harbor.$KOPS_CLUSTER_NAME -u admin --password-stdin WARNING! Your password will be stored unencrypted in /root/.docker/config.json. Configure a credential helper to remove this warning. See https://docs.docker.com/engine/reference/commandline/login/#credentials-store Login Succeeded docker push harbor.$KOPS_CLUSTER_NAME/test/busybox:0.1 The push refers to repository [harbor.hanhorang.link/test/busybox] baacf561cfff: Pushed 0.1: digest: sha256:acaddd9ed544f7baf3373064064a51250b14cfe3ec604d65765a53da5958e5f5 size: 528 Harborì— ì´ë¯¸ì§€ê°€ ì €ì¥ë˜ê³  ì´ì–´ì„œ minio ë²„í‚·ì— í•˜ë²„ ë°ì´í„°ê°€ ì €ì¥ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤!\nì´ì–´ì„œ ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” Harborì™€ minioë¥¼ í†µí•´ EKSì—ì„œ ê³ ê°€ìš©ì„± Private Docker Registry(Harbor) êµ¬ì¶•ì„ í•˜ì˜€ë‹¤. ì•„í‚¤í…ì²˜ ì„¤ê³„ë¥¼ í•˜ë©´ì„œ ìŠ¤í† ë¦¬ì§€ íŠ¹ì„±ì— ëŒ€í•´ ë”¥í•˜ê²Œ ë‹¤ë£° ìˆ˜ ìˆëŠ” ê³„ê¸°ê°€ ë˜ì—ˆê³ , CNCFì˜ ì¡¸ì—… ë ˆë²¨ì˜ ì‹œìŠ¤í…œ(Harbor)ì˜ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë¶„ì„í•  ìˆ˜ ìˆì—ˆë‹¤. ëŠë¼ëŠ” ê±°ì§€ë§Œ ê°„ë‹¨í•˜ë©´ì„œë„ ê° ì»´í¬ë„ŒíŠ¸ê°€ ì„¸ë¶€ì ìœ¼ë¡œ ë¶„ì‚°ë˜ì–´ ì²˜ë¦¬ëœë‹¤ëŠ” ì ê³¼ ìŠ¤í† ë¦¬ì§€ ì—°ë™ ë¶€ë¶„ì—ì„œ ì‚¬ë¡€ ì°¸ê³ ê°€ ë˜ì—ˆë‹¤.\nì•„í‚¤í…ì²˜ êµ¬ì¶•ì´ ëì´ ì•„ë‹ˆë‹¤. ìš´ì˜ ë ˆë²¨ì˜ ê¸°ëŠ¥ë“¤ì´ ë‚¨ì•˜ë‹¤. ë‹¤ìŒ ê¸€ì—ì„œëŠ” Veleroë¥¼ í†µí•œ ë°±ì—…ê³¼ LDAP ì„œë²„ì™€ì˜ ì—°ë™, Harborì˜ ê¸°ëŠ¥ë“¤ì— ëŒ€í•´ ì‚´í´ë³´ê² ë‹¤.\n","date":"Apr 21","permalink":"https://HanHoRang31.github.io/post/tech-private-docker/","tags":["eks","cloud","AWS","kubernetes","harbor","minio"],"title":"[í…Œí¬ ë”°ë¼ì¡ê¸°] EKSì—ì„œ ê³ ê°€ìš©ì„± Private Docker Registry(Harbor) êµ¬ì¶•í•˜ê¸°"},{"categories":null,"contents":"ì „ê¸€ Loki ìµœì‹  ë²„ì „ ì„¤ì¹˜í•˜ê¸°ì—ì„œ ì¸ë±ìŠ¤ DBë¥¼ Dynamodbë¡œ ì—°ë™í•˜ì§€ ëª»í–ˆë‹¤. ë¯¸ë ¨ì´ ë‚¨ì•„ ìŠ¤í„°ë””ê°€ ëë‚œ ì´í›„ì—ë„ ì—¬ëŸ¬ í…ŒìŠ¤íŠ¸ë¥¼ í•´ë³´ì•˜ê³ , ë§ˆì¹¨ë‚´ ì—°ë™ì„ ì„±ê³µí•˜ì—¬ ê´€ë ¨ ê²½í—˜ì„ ê³µìœ í•œë‹¤.\në¨¼ì €, Lokiì—ì„œ DynamoDBë¡œ ì—°ë™í•´ì•¼ í•˜ëŠ” ëª©ì ë¶€í„° ì•Œê³  ê°€ì. ë°°ê²½ ì§€ì‹ ì„¤ëª…ì„ ìœ„í•´ Loki ì˜ ì§€ì› ìŠ¤í† ë¦¬ì§€ë¥¼ ë‹¤ì‹œ í™•ì¸í•˜ê² ë‹¤.\nhttps://grafana.com/docs/loki/latest/operations/storage/\nìŠ¤í† ë¦¬ì§€ ì—°ë™ ëª©ë¡ì„ ì‚´í´ë³´ë©´ Loki 2.0 ì´ìƒì—ì„œ ì‹±ê¸€ ìŠ¤í† ì–´(boltdb-shipper)ê°€ ì¶”ê°€ë˜ì—ˆê³  ì—°ë™ìœ¼ë¡œ ì¶”ì²œí•˜ê³  ìˆë‹¤. (ê¸°ë³¸ ìŠ¤í† ë¦¬ì§€ë„ ì‹±ê¸€ ìŠ¤í† ì–´ì´ë‹¤.) ì´ìœ ë¥¼ ì‚´í´ë³´ë‹ˆ ë¹„ìš© ê°ì†Œì¸ë° ë¡œì»¬ì—ì„œ ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ê¸° ë•Œë¬¸ì— ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì— ëŒ€í•œ ì¢…ì†ì„±ì´ ì¤„ê¸° ë•Œë¬¸ì´ë¼ í•œë‹¤. ë‹¤ë§Œ, ì›ê²© ì €ì¥ì†Œë¡œ ë°±ì—…í•˜ê³  ë³µì›í•˜ëŠ”ë° ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. (ì• ê¸€ì—ì„œëŠ” S3ë¡œ ì—°ë™í–ˆìœ¼ë‚˜ ì‹œê°„ í…€ì´ 15ë¶„ ì •ë„ ìˆì—ˆìŒ)\në¹„ìš©ì€ ë°œìƒí•˜ì§€ë§Œ, DyanmoDB ì—°ë™ ëª©ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\në³µì›ë ¥ : ì‹¤ì‹œê°„ìœ¼ë¡œ ë°ì´í„°ê°€ ì ì¬ë˜ì–´ ë¡œí‚¤ íŒŒë“œê°€ ì£½ì–´ë„ ë°ì´í„°ê°€ ìœ ì§€ëœë‹¤. í™•ì¥ì„± : ë©€í‹° í´ëŸ¬ìŠ¤í„°ì—ì„œì˜ ì‹¤ì‹œê°„ ë¡œê¹… í™•ì¸ (ë¡œì»¬ì¸ ê²½ìš° S3ì— ì ì¬ê°€ ê°€ëŠ¥í•˜ì§€ë§Œ ì‹œê°„ í…€ì´ ìˆë‹¤.) ê²°ë¡ ì ìœ¼ë¡œ, ì†Œê·œëª¨ í”„ë¡œì íŠ¸ë‚˜ ì´ˆê¸° ì„¤ì •ì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° BoltDB \u0026amp; S3 ì˜µì…˜ì„ ê³ ë ¤í•  ìˆ˜ ìˆë‹¤. ë°˜ë©´, ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ë‚˜ ì¥ê¸°ì ì¸ ìš´ì˜ì— ì´ˆì ì„ ë§ì¶”ëŠ” ê²½ìš° S3 \u0026amp; DynamoDB ì˜µì…˜ì´ ë” ì í•©í•˜ë‹¤.\nì—°ë™ íŠ¸ëŸ¬ë¸”ìŠˆíŒ… DynamoDB ì—°ë™ì„ ìœ„í•´ í•´ê²°í–ˆë˜ ë¬¸ì œì ì€ ë‘ê°€ì§€ì˜€ë‹¤. í•­ëª©ë³„ë¡œ ì‚´í´ë³´ê² ë‹¤.\nHelm Value Override ë¬¸ì œ Loki ìŠ¤í† ë¦¬ì§€ ì—°ë™ ì„¤ì • ë¬¸ì œ Helm Value Override ë¬¸ì œ ì§€ë‚œ ê¸€ì—ì„œ ìŠ¤í† ë¦¬ì§€ ì„¤ì •ì„ S3 ë° ê¸°íƒ€ ìŠ¤í† ë¦¬ì§€ë¡œ ì„¤ì •í–ˆìŒì—ë„ ê¸°ë³¸ ìŠ¤í† ë¦¬ì§€ (boltdb \u0026amp; snipper) ê°€ ì„¤ì •ë˜ì–´ ê´€ë ¨ ë¬¸ì œë¥¼ í™•ì¸í•˜ì˜€ë‹¤. helm template ëª…ë ¹ì–´ë¥¼ í†µí•´ì„œ ìŠ¤í† ë¦¬ì§€ ì°¨íŠ¸ ëœë”ë§ì„ í™•ì¸í•˜ë‹ˆ Values ì˜¤ë²„ë¼ì´ë“œ ê°’ì´ ì•„ë‹Œ ê¸°ë³¸ ê°’(boltdb \u0026amp; snipper)ì´ ì…ë ¥ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 helm template loki grafana/loki -f loki.yaml -n loki --version 4.8.0 \u0026gt; result.yaml 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 # Source: loki/templates/configmap.yaml apiVersion: v1 kind: ConfigMap metadata: name: loki labels: helm.sh/chart: loki-4.8.0 app.kubernetes.io/name: loki app.kubernetes.io/instance: loki app.kubernetes.io/version: \u0026#34;2.7.3\u0026#34; app.kubernetes.io/managed-by: Helm data: # override ì ìš© ì•ˆëœë‹¤! config.yaml: | auth_enabled: false common: compactor_address: \u0026#39;loki-read\u0026#39; path_prefix: /var/loki replication_factor: 3 storage: s3: bucketnames: chunks insecure: false s3forcepathstyle: false limits_config: enforce_metric_name: false max_cache_freshness_per_query: 10m reject_old_samples: true reject_old_samples_max_age: 168h split_queries_by_interval: 15m memberlist: join_members: - loki-memberlist query_range: align_queries_with_step: true ruler: storage: s3: bucketnames: ruler insecure: false s3forcepathstyle: false type: s3 runtime_config: file: /etc/loki/runtime-config/runtime-config.yaml schema_config: configs: - from: \u0026#34;2022-01-11\u0026#34; index: period: 24h prefix: loki_index_ object_store: s3 schema: v12 store: boltdb-shipper server: grpc_listen_port: 9095 http_listen_port: 3100 storage_config: hedging: at: 250ms max_per_second: 20 up_to: 3 table_manager: retention_deletes_enabled: false retention_period: 0 --- ìŠ¤í† ë¦¬ì§€ ì—°ë™ ë¶€ë¶„ì¸ data.config.yaml.schema_config ì™€ data.config.yaml.storage_config ì— ê¸°ë³¸ ê°’ì´ ì ìš©ë˜ì–´ ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì›ì¸ì€ Loki í—¬ë¦„ ì°¨íŠ¸ì—ì„œ if ë¬¸ë²•ê³¼ override ê°’ì—ì„œ ìƒê¸´ ëœë”ë§ ë¬¸ì œë¡œ í™•ì¸ëœë‹¤. ê´€ë¦¬ì„± ë¬¸ì œë¡œ overrider íŒŒì¼ì˜ ê°’ì„ ì ìš©ì‹œí‚¤ë ¤ í–ˆì§€ë§Œ, ì ìš©ë˜ì§€ ì•Šì•˜ë‹¤. (í—¬ë¦„ ì°¨íŠ¸ì— ì •í™•í•œ ìˆœì„œ ë° ë¬¸ë²•ì„ ê²€ì‚¬í–ˆìŒì—ë„..)\nìš°íšŒì  í•´ê²° ë°©ë²•ìœ¼ë¡œ ê¸°ë³¸ ì°¨íŠ¸ vaules.yaml ì— ê°’ì„ ì§ì ‘ ì…ë ¥í•˜ì˜€ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 # vaule.yaml Loki: ... config: | .... table_manager: retention_deletes_enabled: true retention_period: 336h index_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 chunk_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 ... # vaule.yaml Loki: ... # -- Check https://grafana.com/docs/loki/latest/configuration/#schema_config for more info on how to configure schemas schemaConfig: configs: - from: \u0026#34;2022-01-11\u0026#34; store: aws object_store: s3 schema: v12 index: prefix: loki_ # -- Check https://grafana.com/docs/loki/latest/configuration/#ruler for more info on configuring ruler rulerConfig: {} # -- Structured loki configuration, takes precedence over `loki.config`, `loki.schemaConfig`, `loki.storageConfig` structuredConfig: {} # -- Additional query scheduler config query_scheduler: {} # -- Additional storage config storage_config: hedging: at: \u0026#34;250ms\u0026#34; max_per_second: 20 up_to: 3 aws: s3: s3.ap-northeast-2.amazonaws.com bucketnames: han-loki region: ap-northeast-2 access_key_id: \u0026lt;access-key\u0026gt; secret_access_key: \u0026lt;aws-secret-key\u0026gt; dynamodb: dynamodb_url: dynamodb.ap-northeast-2.amazonaws.com ... config: | .... table_manager: retention_deletes_enabled: true retention_period: 336h index_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 chunk_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 ... ## Loki ìŠ¤í† ë¦¬ì§€ ì—°ë™ ì„¤ì • ë¬¸ì œ DynamoDB ìŠ¤í† ë¦¬ì§€ë¡œ ì„ íƒì´ ë˜ë‚˜, loki-read Podì—ì„œ ë‹¤ìŒì˜ ì—°ë™ ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤. ```bash level=info ts=2023-04-16T13:31:40.414190216Z caller=http.go:279 org_id=fake msg=\u0026#34;ended tailing logs\u0026#34; tenant=fake selectors=\u0026#34;{stream=\\\u0026#34;stdout\\\u0026#34;,pod=\\\u0026#34;loki-canary-c8s22\\\u0026#34;}\u0026#34; level=info ts=2023-04-16T13:31:50.419151688Z caller=http.go:276 org_id=fake msg=\u0026#34;starting to tail logs\u0026#34; tenant=fake selectors=\u0026#34;{stream=\\\u0026#34;stdout\\\u0026#34;,pod=\\\u0026#34;loki-canary-c8s22\\\u0026#34;}\u0026#34; level=error ts=2023-04-16T13:31:50.422289139Z caller=series_index_store.go:583 org_id=fake msg=\u0026#34;error querying storage\u0026#34; err=\u0026#34;QueryPages error: table=loki_: MissingRegion: could not find region configuration\u0026#34; level=error ts=2023-04-16T13:31:50.422642663Z caller=series_index_store.go:583 org_id=fake msg=\u0026#34;error querying storage\u0026#34; err=\u0026#34;QueryPages error: table=loki_: MissingRegion: could not find region configuration\u0026#34; level=info ts=2023-04-16T13:31:50.422757665Z caller=http.go:279 org_id=fake msg=\u0026#34;ended tailing logs\u0026#34; tenant=fake selectors=\u0026#34;{stream=\\\u0026#34;stdout\\\u0026#34;,pod=\\\u0026#34;loki-canary-c8s22\\\u0026#34;}\u0026#34; level=info ts=2023-04-16T13:32:00.112792136Z caller=http.go:276 org_id=fake msg=\u0026#34;starting to tail logs\u0026#34; tenant=fake selectors=\u0026#34;{stream=\\\u0026#34;stdout\\\u0026#34;,pod=\\\u0026#34;loki-canary-q52t8\\\u0026#34;}\u0026#34; level=error ts=2023-04-16T13:32:00.11538504Z caller=series_index_store.go:583 org_id=fake msg=\u0026#34;error querying storage\u0026#34; err=\u0026#34;QueryPages error: table=loki_: MissingRegion: could not find region configuration\u0026#34; level=error ts=2023-04-16T13:32:00.115479121Z caller=series_index_store.go:583 org_id=fake msg=\u0026#34;error querying storage\u0026#34; err=\u0026#34;QueryPages error: table=loki_: MissingRegion: could not find region configuration\u0026#34; í•´ë‹¹ ì´ìŠˆëŠ” Loki ê¹ƒí—ˆë¸Œì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í–ˆìœ¼ë‚˜ ë‹µë³€ì´ ì—†ì—ˆë‹¤.\nhttps://github.com/grafana/loki/issues/1957\nì›ì¸ì€ Loki DynamoDB ìŠ¤í† ë¦¬ì§€ ì„¤ì •ìœ¼ë¡œ ìƒê¸´ ë¬¸ì œì˜€ë‹¤. ê¹ƒ ì´ìŠˆë¥¼ í™•ì¸í•˜ë©´ Loki ê³µì‹ë¬¸ì„œì—ì„œ ì œê³µí•˜ëŠ” íŒŒë¼ë¯¸í„°ë¥¼ í†µí•´ ì„¤ì •í•œ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆëŠ”ë°, ê·¸ëŒ€ë¡œ ë”°ë¼í•˜ë©´ ì˜¤ë¥˜ê°€ ë°œìƒí•œë‹¤.\nhttps://grafana.com/docs/loki/latest/configuration/#aws_storage_config\ní•„ìì˜ ê²½ìš° ì—ëŸ¬ ë©”ì„¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì†ŒìŠ¤ ì½”ë“œë¥¼ ë¶„ì„í–ˆë‹¤. ê²°ë¡ ì ìœ¼ë¡œëŠ” DynamoDB Structì— Region ì„¤ì •ê°’ì´ ì—†ì–´ì„œ ìƒê¸´ ì˜¤ë¥˜ì˜€ë‹¤. ì½”ë“œ ë¶„ì„ ê³¼ì •ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nì—ëŸ¬ ë©”ì„¸ì§€ì„ ì°¾ì•„ í™•ì¸í•˜ë‹ˆ ValidateEndpointHandler í•¨ìˆ˜ì—ì„œ ë°œìƒí•˜ëŠ” ì—ëŸ¬ì˜€ë‹¤. í•´ë‹¹ í•¨ìˆ˜ëŠ” AWS SDKì˜ ì¼ë¶€ë¡œ AWS ì„œë¹„ìŠ¤ ìš”ì²­ì— ëŒ€í•œ ì—”ë“œí¬ì¸íŠ¸ì™€ ë¦¬ì „ ì •ë³´ë¥¼ ê²€ì¦í•˜ëŠ” í•¨ìˆ˜ì´ë‹¤.\ní•´ë‹¹ í•¨ìˆ˜ì˜ í˜¸ì¶œì€ AWS í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•˜ê³ , ì´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì„œë¹„ìŠ¤ ìš”ì²­ì„ ì‹œì‘í•  ë•Œ ë°œìƒí•œë‹¤. ê° ìŠ¤í† ë¦¬ì§€ S3, DyanmoDB í´ë¼ì´ì–¸íŠ¸ êµ¬ì¡°ì²´ëŠ” ë‹¤ìŒê³¼ ê°™ì€ë° S3ì—ëŠ” regionì´ ìˆì§€ë§Œ, Dynamodb ì—ì„œëŠ” í•´ë‹¹ ë³€ìˆ˜ê°€ ì—†ì—ˆë‹¤.\nì•„ë˜ì™€ ê°™ì´ DynamoDBëŠ” ë³€ìˆ˜ dynamdb.dynamodb_url ì´ Endpoint ë° ì‹œí¬ë¦¿ í‚¤ë¥¼ ì…ë ¥ë°›ë„ë¡ ë˜ì–´ ìˆë‹¤. ì´ëŠ” Loki ë²„ì „ ì—…ë°ì´íŠ¸ ì „(Version 2.0 ì´í•˜)ì˜ ë³€ìˆ˜ ì…ë ¥ê³¼ ë™ì¼í•˜ë‹¤. í•„ìê°€ ì¶”ì •í•˜ê±´ë° ì°¨íŠ¸ì™€ ì—°ë™í•˜ì—¬ ìŠ¤í† ë¦¬ì§€ ë³€ìˆ˜ ì„¤ì • ë¶€ë¶„ì€ S3, GCS, Azure ë§Œ ì—…ë°ì´íŠ¸ë˜ì–´ ìˆëŠ” ê²ƒ ê°™ë‹¤.\nì˜¤ë¥˜ í•´ê²°ì€ ê°„ë‹¨í•˜ë‹¤. Loki ìŠ¤í† ë¦¬ì§€ ì˜ˆì œë¥¼ ì°¸ê³ í•˜ì—¬ DynamoDB_URLì— Region ê³¼ AWS í‚¤ ê°’ í˜•ì‹ì„ í™•ì¸í•˜ë©° ì°¨íŠ¸ì— ë°˜ì˜í•˜ë©´ ëœë‹¤. Loki ìŠ¤í† ë¦¬ì§€ ì˜ˆì œëŠ” ë‹¤ìŒê³¼ ê°™ì´ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤.\nhttps://grafana.com/docs/loki/latest/configuration/examples/\nì´ë¥¼ ë°˜ì˜í•˜ì—¬ ìµœì¢…ì ìœ¼ë¡œ ìˆ˜ì •í•œ ì°¨íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # values.yaml Loki: ... ... config: | .... table_manager: retention_deletes_enabled: true retention_period: 336h index_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 chunk_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 ... # -- Check https://grafana.com/docs/loki/latest/configuration/#schema_config for more info on how to configure schemas schemaConfig: configs: - from: \u0026#34;2022-01-11\u0026#34; store: aws object_store: s3 schema: v12 index: prefix: loki_ ... # -- Check https://grafana.com/docs/loki/latest/configuration/#ruler for more info on configuring ruler rulerConfig: {} # -- Structured loki configuration, takes precedence over `loki.config`, `loki.schemaConfig`, `loki.storageConfig` structuredConfig: {} # -- Additional query scheduler config query_scheduler: {} # -- Additional storage config storage_config: hedging: at: \u0026#34;250ms\u0026#34; max_per_second: 20 up_to: 3 aws: s3: s3://\u0026lt;AWS-ACCESS-KEY\u0026gt;:\u0026lt;AWS-SECRET-KEY\u0026gt;@ap-northeast-2/han-loki dynamodb: dynamodb_url: dynamodb:///\u0026lt;AWS-ACCESS-KEY\u0026gt;:\u0026lt;AWS-SECRET-KEY\u0026gt;@ap-northeast-2 ì•ì„  ê¹ƒ ì´ìŠˆì—ì„œ dynamodb_urlì— inmemory:/// ë¡œ ë³€ìˆ˜ë¥¼ ì„¤ì •í•˜ëŠ” ê²ƒì´ ìˆì—ˆëŠ”ë° ì´ëŠ” ê°€ìƒì˜ ì¸ë©”ëª¨ë¦¬ë¡œ êµ¬í˜„ì‹œ ì‚¬ìš©ëœë‹¤ê³  í•œë‹¤. ì—°ë™ì‹œ í—·ê°ˆë¦¬ì§€ ë§ì 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 # values-loki.yaml tableManager: enabled: true test: enabled: true monitoring: lokiCanary: enabled: true selfMonitoring: enabled: true loki: auth_enabled: false Loki Config ë¶€ë¶„ì„ ì œì™¸í•˜ê³ ëŠ” ì˜¤ë²„ë¼ì´ë“œê°€ ê°€ëŠ¥í•˜ì—¬ ë‚˜ë¨¸ì§€ ì„¤ì • ë¶€ë¶„ì€ ë‹¤ìŒê³¼ ê°™ì´ ì„¤ì •í•˜ì˜€ë‹¤. ë°°í¬ í™•ì¸ ì°¨íŠ¸ ë°°í¬ë¥¼ í†µí•´ ì—°ë™ì„ í•´ë³´ì.\n1 2 3 4 kubectl create ns loki helm repo add grafana https://grafana.github.io/helm-charts helm repo update helm install loki grafana/loki -f values.yaml -f values-loki.yaml -n loki --version 4.8.0 ë°°í¬ í›„ AWS ì½˜ì†”ì—ì„œ í™•ì¸í•˜ë©´ S3ì—ëŠ” ì²­í¬ê°€ DynamoDBì—ëŠ” ì¸ë±ìŠ¤ê°€ ì €ì¥ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nS3 Chunk í™•ì¸\nDynamoDB ì¸ë±ìŠ¤ ì¡°íšŒ í™•ì¸\nì„±ê³µì´ë‹¤..! ëŒê³  ëŒì•„ ê³µì‹ ë¬¸ì„œì—ì„œì˜ ì˜ˆì œë¡œ ì—°ë™ì— ì„±ê³µí•˜ì˜€ë‹¤. í—¬ë¦„ ì°¨íŠ¸ ëœë”ë§ê³¼ã…Š íŒŒë¼ë¯¸í„° ë³€ìˆ˜ì˜ ì˜ˆì œë¥¼ ê¼­ í™•ì¸í•˜ë„ë¡ í•˜ì!\nìš´ì˜ì‹œ ê³ ë ¤ì‚¬í•­ ë°°í¬ ê³¼ì •ì—ì„œ ê³ ë ¤ì‚¬í•­ì´ ìˆì–´ ì¶”ê°€ë¡œ ë‚¨ê²¨ë‘”ë‹¤.\nìŠ¤í† ë¦¬ì§€ ì‚¬ìš© ë¹„ìš© ì²« ì¨°ë¡œ ë¹„ìš©ì´ë‹¤. DynamoDB ì—°ë™ì‹œ ê¸°ë³¸ ì½ê¸°ìš©ëŸ‰ì´ 100, ì“°ê¸°ìš©ëŸ‰ì´ 25ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤. ë¹„ìš© ê³„ì‚°ë¥¼ í™•ì¸ í•˜ìë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\ní•œêµ­ DynamoDB ë¹„ìš©\nì“°ê¸° ìš”ì²­ ìœ ë‹›(WRU): 1,000,000 ê±´ë‹¹ $1.3556 ì½ê¸° ìš”ì²­ ìœ ë‹›(RRU): 1,000,000 ê±´ë‹¹ $0.271 ê¸°ë³¸ ì½ê¸°ìš©ëŸ‰ì´ 100, ì“°ê¸°ìš©ëŸ‰ì´ 25ë¡œ ì„¤ì •ëœ ê²½ìš°, ìš©ëŸ‰ ë‹¨ìœ„ì— ëŒ€í•œ ì‹¤ì œ ìš”ì²­ ìˆ˜ë¥¼ ì•Œì•„ì•¼ í•œë‹¤.\nì˜ˆë¥¼ ë“¤ì–´, ì‹œê°„ë‹¹ 10,000ê±´ì˜ ì“°ê¸° ìš”ì²­ê³¼ 50,000ê±´ì˜ ì½ê¸° ìš”ì²­ì´ ìˆë‹¤ê³  ê°€ì •í•˜ê² ë‹¤.\nì“°ê¸° ìš”ì²­ ë¹„ìš©: 10,000 WRU x ($1.3556 / 1,000,000) = $0.013556 ì½ê¸° ìš”ì²­ ë¹„ìš©: 50,000 RRU x ($0.271 / 1,000,000) = $0.01355 ì´ ë¹„ìš©ì€ $0.013556 + $0.01355 = $0.027106 (1h) ì´ë‹¤.\nìš´ì˜ í™˜ê²½ì—ì„œ ë°°í¬ì‹œ ì‹œìŠ¤í…œ ê·œëª¨ë¥¼ íŒŒì•…í•˜ì—¬ ì“°ê¸° ë° ì½ê¸° ìš”ì²­ì— ë”°ë¼ ìš©ëŸ‰ì„ ì„¤ì •í•˜ë„ë¡ í•˜ì. ìš©ëŸ‰ ì„¤ì •ì€ ìœ„ ì°¨íŠ¸ì—ì„œì˜ table_manager ì—ì„œ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. í•„ìëŠ” 5ë¡œ ì„¤ì •í–ˆì—ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # values.yaml Loki: ... ... config: | .... table_manager: retention_deletes_enabled: true retention_period: 336h index_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 chunk_tables_provisioning: provisioned_write_throughput: 5 provisioned_read_throughput: 5 ... ","date":"Apr 14","permalink":"https://HanHoRang31.github.io/post/loki-2-8-0/","tags":["KANS","kops","cloud","AWS","kubernetes","PLG","loki","promtail"],"title":"Loki ìµœì‹ ë²„ì „(V2.8.0) DyanmoDB ì—°ë™í•˜ê¸°"},{"categories":null,"contents":" 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. 5ì£¼ì°¨ ì‹œê°„ì—ëŠ” ëª¨ì„ì¥ë‹˜ê»˜ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆì„ ì£¼ì œë¡œ í•™ìŠµ ë‚´ìš©ì„ ê³µìœ í•´ ì£¼ì…¨ë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆì— ëŒ€í•´ ìŠ¤í„°ë””í•œ ë‚´ìš©ì„ ê³µìœ í•˜ê³ ì í•œë‹¤.\nKubernetes 4C Layer ì¿ ë²„ë„¤í‹°ìŠ¤ ê³µì‹ë¬¸ì„œì— ë”°ë¥´ë©´ ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆì€ 4ê³„ì¸µ(í´ë¼ìš°ë“œ/ í´ëŸ¬ìŠ¤í„° / ì»¨í…Œì´ë„ˆ / ì½”ë“œ)ìœ¼ë¡œ êµ¬ì„±ë˜ë©°, ê° ê³„ì¸µì— ëŒ€í•´ ë³´ì•ˆ ê´€ì ì´ í•„ìš”í•˜ë‹¤ê³  í•œë‹¤.\nhttps://kubernetes.io/docs/concepts/security/overview/\nCloud, Infra : í´ë¼ìš°ë“œ ê³„ì¸µì—ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ê°€ ì‹¤í–‰ë˜ëŠ” ê¸°ë°˜ ì¸í”„ë¼ì— ì´ˆì ì„ ë§ì¶˜ë‹¤. ì´ ê³„ì¸µì—ì„œëŠ” ê°€ìƒ ë¨¸ì‹ , ë„¤íŠ¸ì›Œí¬, ìŠ¤í† ë¦¬ì§€ ë° ê¸°íƒ€ ìì›ì— ëŒ€í•œ ë³´ì•ˆì„ ê°•í™”í•˜ê³ , í´ë¼ìš°ë“œ ì œê³µ ì—…ì²´ì˜ ë³´ì•ˆ ë„êµ¬ ë° ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” ê²ƒìœ¼ë¡œ ì´ˆì ì´ ë§ì¶°ì ¸ ìˆë‹¤. ì¸í”„ë¼ ë³´í˜¸ ëŒ€ìƒê³¼ í´ë¼ìš°ë“œ ì œê³µ ì—…ì²´(AWS) ì˜ ì œê³µ ë³´ì•ˆì€ ë‹¤ìŒì˜ í‘œë¥¼ ì°¸ê³ í•˜ì. ë³´í˜¸ ëŒ€ìƒ AWS EKSì—ì„œì˜ ë³´ì•ˆ ê¸°ëŠ¥ API ì„œë²„ì— ëŒ€í•œ ë„¤íŠ¸ì›Œí¬ ì•¡ì„¸ìŠ¤ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì‹œ ì•¡ì„¸ìŠ¤ ì§€ì ì— ëŒ€í•´ Elastic Load Balancerë¥¼ êµ¬ì„±í•œë‹¤. ì´ë¥¼ í†µí•´ API ì„œë²„ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ VPC ë‚´ë¶€ë¡œ ì œí•œí•˜ê±°ë‚˜ ì¸í„°ë„· ê²Œì´íŠ¸ì›¨ì´ë¥¼ í†µí•´ ì¸í„°ë„·ì—ì„œë„ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, AWS Identity and Access Management (IAM)ì„ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì™€ ì—­í• ì— ëŒ€í•œ ì ‘ê·¼ ì œì–´ë¥¼ êµ¬ì„±í•  ìˆ˜ ìˆë‹¤. ë…¸ë“œì— ëŒ€í•œ ë„¤íŠ¸ì›Œí¬ ì•¡ì„¸ìŠ¤ VPC ì„œë¹„ìŠ¤ë¥¼ ì´ìš©í•˜ì—¬ ë…¸ë“œì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ VPC ë‚´ë¶€ë¡œ ì œí•œí•˜ê±°ë‚˜ ì¸í„°ë„· ê²Œì´íŠ¸ì›¨ì´ë¥¼ í†µí•´ ì¸í„°ë„·ì—ì„œë„ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•  ìˆ˜ ìˆë‹¤. ë˜í•œ ë³´ì•ˆ ê·¸ë£¹ì„ í†µí•´ IP ì£¼ì†Œ ë²”ìœ„ì— ëŒ€í•œ ì¸ë°”ìš´ë“œ ë° ì•„ìš´ë°”ìš´ë“œ íŠ¸ë˜í”½ì„ ì œì–´í•  ìˆ˜ ìˆë‹¤. í´ë¼ìš°ë“œ ì œê³µ ì—…ì²´ API ì— ëŒ€í•œ ì¿ ë²„ë„¤í‹°ìŠ¤ ì•¡ì„¸ìŠ¤ IAM ê¶Œí•œì˜ ì ‘ê·¼ í‚¤ë¥¼ ë‹¤ë£¬ë‹¤. ì ‘ê·¼ í‚¤ê°€ íƒˆì·¨ë˜ë©´ í•´ë‹¹ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ ì œì–´ê°€ íƒˆì·¨ëœë‹¤. ê³µì‹ ë¬¸ì„œì—ì„œëŠ” ìµœì†Œ ê¶Œí•œ ì›ì¹™ì„ ì•¡ì„¸ìŠ¤ ê¶Œí•œì„ ë¶€ì—¬í•  ê²ƒì„ ê¶Œê³ í•œë‹¤. etcdì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ etcd ë°ì´í„°ë² ì´ìŠ¤ê°€ EKS ì™„ì „ ê´€ë¦¬í˜• ì»¨íŠ¸ë¡¤ í”Œë ˆì¸ ë‚´ë¶€ì— ìˆ¨ê²¨ì ¸ ìˆìœ¼ë©°, ì‚¬ìš©ìëŠ” etcdì— ì§ì ‘ ì•¡ì„¸ìŠ¤í•  ìˆ˜ ì—†ë‹¤. etcd ì•”í˜¸í™” ê¸°ë³¸ì ìœ¼ë¡œ EKS í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±í•  ë•Œ, etcd ë°ì´í„°ë¥¼ ì•”í˜¸í™”í•˜ëŠ” ì˜µì…˜ì„ ì„ íƒí•  ìˆ˜ ìˆë‹¤. ì´ë ‡ê²Œ ì„¤ì •í•˜ë©´, í´ëŸ¬ìŠ¤í„°ì˜ etcd ë°ì´í„°ëŠ” AWS Key Management Service (KMS)ì—ì„œ ì œê³µí•˜ëŠ” ê³ ê° ê´€ë¦¬í˜• í‚¤ (CMK)ë¥¼ ì‚¬ìš©í•˜ì—¬ ì•”í˜¸í™”ë˜ì–´ ê¸°ë°€ì„±ì´ ë³´ì¥ëœë‹¤. Cluster: í´ëŸ¬ìŠ¤í„° ê³„ì¸µì—ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ìì²´ì˜ ë³´ì•ˆì— ì¤‘ì ì„ ë‘”ë‹¤. í´ëŸ¬ìŠ¤í„° ìƒì˜ ì¤‘ìš”í•œ ì„œë¹„ìŠ¤ Aì™€ ë³´ì•ˆì´ ì·¨ì•½í•œ ì„œë¹„ìŠ¤ Bì— ëŒ€í•´ ê²©ë¦¬ë¥¼ ìœ„í•œ ê³„ì¸µì´ë¼ê³  ë³´ë©´ ëœë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œëŠ” ê²©ë¦¬ì— ë°©ë²•ìœ¼ë¡œ ë‹¤ì–‘í•œ ë°©ë²•ì„ ì œì•ˆí•œë‹¤. ëŒ€í‘œì ìœ¼ë¡œ RBAC ì¸ì¦, ë„¤íŠ¸ì›Œí¬ ì •ì±…, íŒŒë“œ ë³´ì•ˆ í‘œì¤€, ì¸ê·¸ë˜ìŠ¤ìš© TLS ë“±ì´ ìˆë‹¤. í•­ëª© ì„¤ëª… RBAC ì¸ì¦ ì—­í• (Role) ë° í´ëŸ¬ìŠ¤í„° ì—­í• (ClusterRole)ì„ ì‚¬ìš©í•˜ì—¬ ì¿ ë²„ë„¤í‹°ìŠ¤ ì‚¬ìš©ìì™€ ì„œë¹„ìŠ¤ ê³„ì •ì— ê¶Œí•œì„ ë¶€ì—¬í•˜ëŠ” Role-Based Access Control ë°©ì‹ì´ë‹¤. ì´ë¥¼ í†µí•´ ì„¸ë¶„í™”ëœ ê¶Œí•œ ì œì–´ë¡œ í´ëŸ¬ìŠ¤í„°ì˜ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ë„¤íŠ¸ì›Œí¬ ì •ì±… ì¿ ë²„ë„¤í‹°ìŠ¤ ë„¤íŠ¸ì›Œí¬ ì •ì±…ì€ íŠ¹ì • íŒŒë“œ, ë„¤ì„ìŠ¤í˜ì´ìŠ¤, ë˜ëŠ” IP ë²”ìœ„ì™€ ê°™ì€ ì†ŒìŠ¤ë¡œë¶€í„° ë“¤ì–´ì˜¤ê±°ë‚˜ ë‚˜ê°€ëŠ” íŠ¸ë˜í”½ì„ í—ˆìš©í•˜ê±°ë‚˜ ì°¨ë‹¨í•˜ëŠ” ê·œì¹™ì„ ì •ì˜í•œë‹¤. ì´ë¥¼ í†µí•´ ë„¤íŠ¸ì›Œí¬ ë³´ì•ˆì„ ê°•í™”í•˜ê³ , ë¯¼ê°í•œ ë°ì´í„°ë¥¼ ì²˜ë¦¬í•˜ëŠ” íŒŒë“œì— ëŒ€í•œ ì ‘ê·¼ì„ ì œí•œí•  ìˆ˜ ìˆë‹¤. íŒŒë“œ ë³´ì•ˆ í‘œì¤€ íŒŒë“œ ë³´ì•ˆ í‘œì¤€ì€ ì»¨í…Œì´ë„ˆì™€ íŒŒë“œê°€ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë˜ë„ë¡ í•˜ëŠ”ë° ë„ì›€ì´ ë˜ëŠ” ì¼ë ¨ì˜ ë³´ì•ˆ ì§€ì¹¨ ë° êµ¬ì„±ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸(Security Context), ë„¤íŠ¸ì›Œí¬ í´ë¦¬ì‹œ, ë¦¬ì†ŒìŠ¤ ì œí•œ, íŒŒë“œ ì•ˆí‹°-ì–´í”¼ë‹ˆí‹° ë“±ì„ ì‚¬ìš©í•˜ì—¬ íŒŒë“œì˜ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ì¸ê·¸ë˜ìŠ¤ìš© TLS ì¿ ë²„ë„¤í‹°ìŠ¤ ì¸ê·¸ë˜ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ì™¸ë¶€ì—ì„œ ë‚´ë¶€ ì„œë¹„ìŠ¤ë¡œì˜ ìš”ì²­ì„ ì¤‘ì•™ ì§‘ì¤‘ì‹ìœ¼ë¡œ ê´€ë¦¬í•  ë•Œ, TLS(Transport Layer Security)ë¥¼ ì‚¬ìš©í•˜ì—¬ í´ë¼ì´ì–¸íŠ¸ì™€ ì„œë²„ ê°„ í†µì‹ ì„ ì•”í˜¸í™”í•˜ì—¬ ë°ì´í„°ë¥¼ ë³´í˜¸í•  ìˆ˜ ìˆë‹¤. ì¸ì¦ì„œì™€ ê°œì¸ í‚¤ë¥¼ ì œê³µí•˜ê³  í˜¸ìŠ¤íŠ¸ ì´ë¦„ê³¼ ì¸ì¦ì„œì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ í™•ì¸í•´ì•¼ í•œë‹¤. Container: ì»¨í…Œì´ë„ˆ ê³„ì¸µì—ì„œëŠ” ì‹¤í–‰ë˜ëŠ” ì›Œí¬ë¡œë“œì— ì§ì ‘ì ìœ¼ë¡œ ì˜í–¥ì„ ì£¼ëŠ” ì»¨í…Œì´ë„ˆì— ì´ˆì ì„ ë§ì¶˜ë‹¤. ì´ ê³„ì¸µì—ì„œëŠ” ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë³´ì•ˆ, ë¦¬ì†ŒìŠ¤ ê²©ë¦¬, ì‹œí¬ë¦¿ ê´€ë¦¬ ë° ë„¤íŠ¸ì›Œí¬ ì •ì±…ì„ í¬í•¨ëœë‹¤. ì—¬ê¸°ì—ì„œëŠ” ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸, ë„¤íŠ¸ì›Œí¬ í´ë¦¬ì‹œ, ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì˜ ë³´ì•ˆ ê¸°ëŠ¥(ì´ë¯¸ì§€ ìŠ¤ìº”) ë“±ì„ ì‚¬ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆì˜ ë³´ì•ˆì„ ê°•í™”í•œë‹¤. í•­ëª© ì„¤ëª… ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸ (Security Context) ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ì»¨í…Œì´ë„ˆ ë˜ëŠ” íŒŒë“œì— ì ìš©ë˜ëŠ” ë³´ì•ˆ ì„¤ì •ì„ ì •ì˜í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. ë³´ì•ˆ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆì˜ íŒŒì¼ ì‹œìŠ¤í…œì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ ê¶Œí•œ, í”„ë¡œì„¸ìŠ¤ ID, ì‚¬ìš©ì ID, ê·¸ë£¹ ID ë“±ì„ ì œì–´í•  ìˆ˜ ìˆë‹¤. ì´ë¥¼ í†µí•´ ì»¨í…Œì´ë„ˆì™€ íŒŒë“œê°€ ì•ˆì „í•˜ê²Œ ì‹¤í–‰ë˜ë„ë¡ í•  ìˆ˜ ìˆìœ¼ë©°, í˜¸ìŠ¤íŠ¸ ì‹œìŠ¤í…œê³¼ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆë¡œë¶€í„° ë¶„ë¦¬ë˜ì–´ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì˜ ë³´ì•ˆ ê¸°ëŠ¥ ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„(ì˜ˆ: Docker, containerd, CRI-O ë“±)ì€ ì»¨í…Œì´ë„ˆë¥¼ ì‹¤í–‰í•˜ê³  ê´€ë¦¬í•˜ëŠ”ë° ì‚¬ìš©ë˜ëŠ” ì†Œí”„íŠ¸ì›¨ì–´ì´ë‹¤. ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì€ ë‹¤ì–‘í•œ ë³´ì•ˆ ê¸°ëŠ¥ì„ ì œê³µí•˜ì—¬ ì»¨í…Œì´ë„ˆì˜ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ì»¨í…Œì´ë„ˆ ëŸ°íƒ€ì„ì€ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆ í”„ë¡œì„¸ìŠ¤ë¥¼ ê²©ë¦¬í•  ìˆ˜ ìˆìœ¼ë©°, cgroupsì„ ì‚¬ìš©í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì‚¬ìš©ëŸ‰ì„ ì œí•œí•˜ê³ , seccomp, AppArmor, SELinuxì™€ ê°™ì€ ë³´ì•ˆ í”„ë¡œíŒŒì¼ì„ ì ìš©í•˜ì—¬ ì»¨í…Œì´ë„ˆì˜ ì‹œìŠ¤í…œ í˜¸ì¶œì„ ì œí•œí•  ìˆ˜ ìˆë‹¤. Code: ì½”ë“œ ê³„ì¸µì—ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì†ŒìŠ¤ ì½”ë“œ ë° êµ¬ì„±ì— ì´ˆì ì„ ë§ì¶˜ë‹¤. ì´ ê³„ì¸µì—ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì·¨ì•½ì  ë° ë³´ì•ˆ ê²°í•¨ì„ ì°¾ê³  ìˆ˜ì •í•˜ì—¬ ì›Œí¬ë¡œë“œì˜ ë³´ì•ˆì„ í–¥ìƒì‹œì¼œì•¼ í•œë‹¤. ë°©ë²•ìœ¼ë¡œëŠ” TLS ì•¡ì„¸ìŠ¤, í†µì‹  í¬íŠ¸ ì œí•œ, ì¢…ì†ì„± ë³´ì•ˆ, ì •ì  ë° ë™ì  ì†ŒìŠ¤ ì½”ë“œ ë¶„ì„, ì˜ì¡´ì„± ìŠ¤ìº” ë° ì•ˆì „í•œ ì½”ë”© ê¸°ë²• ë“±ì´ ìˆë‹¤. í•­ëª© ì„¤ëª… í†µì‹  í¬íŠ¸ ì œí•œ í†µì‹  í¬íŠ¸ ì œí•œì€ ì„œë²„, ì»¨í…Œì´ë„ˆ, ì• í”Œë¦¬ì¼€ì´ì…˜ ë“±ì´ ì‚¬ìš©í•˜ëŠ” ë„¤íŠ¸ì›Œí¬ í¬íŠ¸ë¥¼ ì œí•œí•˜ì—¬ ë³´ì•ˆì„ ê°•í™”í•˜ëŠ” ë°©ë²•ì´ë‹¤. ë¶ˆí•„ìš”í•œ í¬íŠ¸ë¥¼ ì°¨ë‹¨í•˜ê³ , í•„ìš”í•œ í¬íŠ¸ì— ëŒ€í•´ì„œë§Œ í—ˆìš©í•˜ë©´ ì•…ì˜ì ì¸ ê³µê²©ìê°€ ì‹œìŠ¤í…œì— ì•¡ì„¸ìŠ¤í•˜ëŠ” ê²ƒì„ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. ì¢…ì†ì„± ë³´ì•ˆ ì¢…ì†ì„± ë³´ì•ˆì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œ ì‚¬ìš©í•˜ëŠ” ì™¸ë¶€ ë¼ì´ë¸ŒëŸ¬ë¦¬ ë° íŒ¨í‚¤ì§€ì— ëŒ€í•œ ë³´ì•ˆì„ ê´€ë¦¬í•˜ëŠ” ë°©ë²•ì´ë‹¤. ì·¨ì•½í•œ ì¢…ì†ì„±ì„ ì‚¬ìš©í•˜ë©´ ì‹œìŠ¤í…œì´ ê³µê²©ì— ë…¸ì¶œë  ìˆ˜ ìˆë‹¤. ë”°ë¼ì„œ, ì¢…ì†ì„±ì„ ìµœì‹  ìƒíƒœë¡œ ìœ ì§€í•˜ê³ , ë³´ì•ˆ ì·¨ì•½ì ì´ ë°œê²¬ë  ê²½ìš° ì ì ˆí•œ ì¡°ì¹˜ë¥¼ ì·¨í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•˜ë‹¤. ì •ì  ë° ë™ì  ì†ŒìŠ¤ ì½”ë“œ ë¶„ì„ ì •ì  ì†ŒìŠ¤ ì½”ë“œ ë¶„ì„ì€ ì½”ë“œë¥¼ ì‹¤í–‰í•˜ì§€ ì•Šê³  ì†ŒìŠ¤ ì½”ë“œë¥¼ ê²€ì‚¬í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ëŠ” ë°©ë²•ì´ë‹¤. ë™ì  ì†ŒìŠ¤ ì½”ë“œ ë¶„ì„ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ì‹¤í–‰í•˜ë©´ì„œ ì½”ë“œë¥¼ ë¶„ì„í•˜ì—¬ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ëŠ” ë°©ë²•ì´ë‹¤. ì´ëŸ¬í•œ ë¶„ì„ ë°©ë²•ë“¤ì„ ì‚¬ìš©í•˜ì—¬ ì• í”Œë¦¬ì¼€ì´ì…˜ ì½”ë“œì˜ ë³´ì•ˆ ì·¨ì•½ì ì„ ë°œê²¬í•˜ê³  ìˆ˜ì •í•  ìˆ˜ ìˆë‹¤. ì˜ì¡´ì„± ìŠ¤ìº” ë° ì•ˆì „í•œ ì½”ë”© ê¸°ë²• ì˜ì¡´ì„± ìŠ¤ìº”ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ì¢…ì†ì„±ì— ëŒ€í•œ ë³´ì•ˆ ì·¨ì•½ì ì„ ì°¾ê¸° ìœ„í•œ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. ì•ˆì „í•œ ì½”ë”© ê¸°ë²•ì€ ê°œë°œìê°€ ì½”ë“œë¥¼ ì‘ì„±í•  ë•Œ ê³ ë ¤í•´ì•¼ í•˜ëŠ” ë³´ì•ˆ ì§€ì¹¨ ë° ì›ì¹™ì´ë‹¤. ì´ëŸ¬í•œ ê¸°ë²•ì„ ì‚¬ìš©í•˜ë©´ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë³´ì•ˆì„ ê°•í™”í•˜ê³ , ì·¨ì•½ì ì„ ì¤„ì¼ ìˆ˜ ìˆë‹¤. ë³´ì•ˆì ìœ¼ë¡œ ì‹ ê²½ì¨ì•¼í•  ìš”ì†Œê°€ ë§ë‹¤. ìœ„ì˜ ì„¤ëª…í•œ ë³´ì•ˆ ê¸°ëŠ¥ë“¤ì„ ì „ë¶€ ë‹¤ë£¨ë©´ ì¢‹ê² ì§€ë§Œ ë‚´ìš©ì´ ë°©ëŒ€í•˜ë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ë³´ì•ˆ íˆ´ì¸ kubescapeë¥¼ ì´ìš©í•˜ì—¬ ì•ì„œ 4Cì—ì„œ Cluster, Container, Code ê³„ì¸µì˜ ë³´ì•ˆ ê²€ì¦ ê³¼ì •ì„ ë‹¤ë¤„ë³´ê² ë‹¤.\nKubescape ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ë³´ì•ˆ ì„¤ì •ì„ í‰ê°€í•˜ê³  ê²€ì¦í•˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ì´ë‹¤. NSAì™€ MITREì˜ Kubernetes Hardening Guidanceë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ë™í•˜ë©° ì›¹ ëŒ€ì‹œë³´ë“œë¥¼ í†µí•´ ê²€ì¦ ë° ì·¨ì•½ì  ì ê²€ì„ í•  ìˆ˜ ìˆë‹¤. ë˜í•œ, ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬, ì´ë¯¸ì§€ ì·¨ì•½ì  ìŠ¤ìº”ì´ ê°€ëŠ¥í•˜ë‹¤. 23ë…„ 4ì›” ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸ê°€ ê³„ì† ì§„í–‰ ì¤‘ì´ë©° ê³µì‹ ë¬¸ì„œ ë˜í•œ ì •ë¦¬ê°€ ì˜ ë˜ì–´ ìˆë‹¤.\nê·¸ë ‡ì§€ë§Œ ì œí•œì ì¸ ìš”ì†Œë„ ì¡´ì¬í•œë‹¤. í´ëŸ¬ìŠ¤í„°ë¥¼ ARMO ì›¹ ëŒ€ì‹œë³´ë“œë¡œ ì—°ê²°í•´ì•¼í•œë‹¤ëŠ” ì ìœ¼ë¡œ ì˜¨í”„ë ˆë¯¸ìŠ¤ì—ì„œ ë„ì…ì‹œ ê³ ë ¤í•´ì•¼ í•œë‹¤. ë˜í•œ í”„ë¦¬í‹°ì–´ ê¸°ì¤€ ì›Œí¬ ë…¸ë“œê°€ 10ê°œë¡œ ì œí•œëœë‹¤.\në³´ì•ˆ ê¸°ëŠ¥ì„ ì „ë¶€ ì‚¬ìš©í•˜ë ¤ë©´ Operator ì„¤ì¹˜ê°€ ë™ë°˜ëœë‹¤. ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ êµ¬ì„±ëœë‹¤.\nhttps://github.com/kubescape/helm-charts/blob/master/charts/kubescape-cloud-operator/README.md\nMaster Gateway: ARMO ë°±ì—”ë“œì—ì„œ ì‹¤í–‰ ì¤‘ì¸ ë§ˆìŠ¤í„° ê²Œì´íŠ¸ì›¨ì´ì´ë©° ì‚¬ìš©ìê°€Â ë“±ë¡í•œ ëª¨ë“  ê²Œì´íŠ¸ì›¨ì´ì— ë©”ì‹œì§€ë¥¼ ë¸Œë¡œë“œìºìŠ¤íŠ¸í•˜ì—¬ ëª¨ë“  í´ëŸ¬ìŠ¤í„° ê²Œì´íŠ¸ì›¨ì´ì— ëŸ°íƒ€ì„ ì‘ì—…ì„ ì „ë‹¬í•œë‹¤. In-cluster Gateway: í´ëŸ¬ìŠ¤í„° ë‚´ì—ì„œ ë‹¤ë¥¸ êµ¬ì„± ìš”ì†Œì™€ í†µì‹ í•˜ê¸° ìœ„í•´ ë§ˆìŠ¤í„° ê²Œì´íŠ¸ì›¨ì´ì™€ ì—°ê²°ë˜ë©°, ì›¹ì†Œì¼“(Websocket)ì„ ì‚¬ìš©í•˜ì—¬ ë“±ë¡ëœë‹¤. ë¸Œë¡œë“œìºìŠ¤íŠ¸ ë©”ì„¸ì§€ë¥¼ ì „ë‹¬ë°›ì•„ ë‹¤ë¥¸ ì»´í¬ë„ŒíŠ¸ì— ì „ë‹¬í•œë‹¤. Operator : íŠ¸ë¦¬ê±° ì—”ì§„ìœ¼ë¡œ ê²Œì´íŠ¸ì›¨ì´ì—ì„œ ì”ë‹¬ë°›ì€ ì‘ì—…ì„ ì‹¤í–‰í•˜ê±°ë‚˜ ìŠ¤ì¼€ì¤„ë§í•˜ëŠ” ì—­í• ì„ ë‹´ë‹¹í•œë‹¤. Kubevuln : ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ì·¨ì•½ì ì„ ìŠ¤ìº”í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì·¨ì•½ì  ìŠ¤ìº”ì€ grypeì„ í†µí•´ ì§„í–‰í•œë‹¤. Kubescape : í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ ê²€ì¦ì„ ìŠ¤ìº”í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. Kollector : kubernetes API Serverì™€ í†µì‹ í•˜ì—¬ í´ëŸ¬ìŠ¤í„° ì •ë³´ì™€ ë³€ê²½ ì •ë³´ë¥¼ í™•ì¸í•˜ë©° ì •ë³´ë¥¼ ë°±ì—”ë“œ CloudEndpointë¡œ ì „ë‹¬í•œë‹¤. ì„¤ì¹˜ ë°°í¬ í™˜ê²½ : kops í´ëŸ¬ìŠ¤í„° (k8s 1.24), AWS Ubuntu ì¸ìŠ¤í„´ìŠ¤\në¨¼ì € https://cloud.armosec.io/ íšŒì›ê°€ì…ì´ í•„ìš”í•˜ë‹¤. íšŒì›ê°€ì… ì´í›„ íšŒì› ID ê°’ì— ë§ê²Œ helm ì„¤ì¹˜ ëª…ë ¹ì–´ê°€ ë‚˜ì˜¨ë‹¤. ë³µì‚¬í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì— ì„¤ì¹˜í•˜ì.\nì„¤ì¹˜ ì´í›„ Verfiy installation ë²„íŠ¼ì„ ëˆ„ë¥´ë©´ ì•„ë˜ì™€ ê°™ì´ ì—°ê²°ì´ ì•ˆëœë‹¤ê³  ë‚˜ì˜¤ë‚˜ kops í´ëŸ¬ìŠ¤í„°ì—ì„œ ì„¤ì¹˜í–ˆì„ ë•Œì˜ ë²„ê·¸ê°™ë‹¤.\nì•„ë˜ì™€ ê°™ì´ ë¡œê·¸ í™•ì¸ ë° ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ë“±ë¡ì´ ë˜ì–´ ìˆë‹¤.\n1 kubectl -n kubescape logs -f $(kubectl -n kubescape get pods | grep kollector | awk \u0026#39;{print $1}\u0026#39;) ê¸°ëŠ¥ í™•ì¸ ëŒ€ì‹œë³´ë“œë¥¼ ì ‘ì†í•˜ë©´ ì™¼ìª½ì˜ ë©”ë‰´ë¥¼ í†µí•´ì„œ ë³´ì•ˆ ê²€ì¦ì´ ê°€ëŠ¥í•˜ë‹¤.\nCompliance : ì¿ ë²„ë„¤í‹°ìŠ¤ ì¤€ìˆ˜ ì •ì±… ê²€ì¦ Vulnerabilities : ì»¨í…Œì´ë„ˆ íŒŒë“œ ì·¨ì•½ì  ì ê²€ RBAC Visualizer : RBAC ì‹œê°í™” Repository Scanning : ë ˆíŒŒì§€í† ë¦¬ ìŠ¤ìºë‹ Registry Scanning : ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ìŠ¤ìºë‹ Compliance ì¿ ë²„ë„¤í‹°ìŠ¤ ëª¨ë²” ì‚¬ë¡€ë¥¼ ì²´ê³„í™”í•˜ì—¬ ìˆ˜ë°± ê°œì˜ í•­ëª©ë“¤ì„ í†µí•´ í´ëŸ¬ìŠ¤í„° ê²€ì¦ì‹œì¼œì£¼ëŠ” ê¸°ëŠ¥ì´ë‹¤. ê²€ì¦ í•­ëª©ì€ MITRA ì™€ NSA ì—ì„œ ì œì‹œí•˜ëŠ” ë³´ì•ˆ ê°€ì´ë“œë¼ì¸ì´ë©° ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ í”„ë ˆì„ì›Œí¬ë³„ ì œì–´ê°€ ê°€ëŠ¥í•˜ë‹¤.\në˜í•œ, ë³´ì•ˆì´ í•„ìš”í•œ í•­ëª©ì—ëŠ” fixë²„íŠ¼ì„ í†µí•´ êµ¬ì„±ì ìœ¼ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nì•„ë˜ëŠ” í•„ì í´ëŸ¬ìŠ¤í„° í™˜ê²½ì—ì„œ high ë ˆë²¨ í•­ëª©ì´ë©° ëª‡ ê°€ì§€ í•­ëª© ì›ì¸ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nC-0057(Privileged container) : í˜¸ìŠ¤íŠ¸ ì‹œìŠ¤í…œì˜ ëª¨ë“  ê¸°ëŠ¥ì„ í¬í•¨í•˜ëŠ” ì»¨í…Œì´ë„ˆê°€ ìˆì–´ì„œ ë°œìƒí•œ í•­ëª©ì´ë‹¤. íŒŒë“œ êµ¬ì„± ì¤‘ spec.container.securityContext.privileged == true ì¼ ë•Œ ë°œìƒí•œë‹¤. í•„ìì˜ ê²½ìš° ë³¼ë¥¨ ê´€ë¦¬ íŒŒë“œ(ebs-csi-node) ì—ì„œ ë°œìƒí–ˆë‹¤. C-0045(Writable hostPath mount) : ì“°ê¸° ê°€ëŠ¥í•œ hostPath ë³¼ë¥¨ìœ¼ë¡œ ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í–ˆì„ ë•Œ ë°œìƒí•˜ëŠ” ì•ŒëŒì´ë‹¤. ì„¤ëª…ì—ì„œëŠ” ì´ë¥¼ í†µí•´ í˜¸ìŠ¤íŠ¸ ë³¼ë¥¨ì˜ ì •ë³´ë¥¼ ì–»ì„ ìˆ˜ ìˆë‹¤ í•œë‹¤. íŒŒë“œ êµ¬ì„± ì¤‘ mount.readOnly == false ì´ ëì„ ë•Œ ë°œìƒí•œë‹¤. C-0015 (kubernetes secret list) : ì¿ ë²„ë„¤í‹°ìŠ¤ ì‚¬ìš©ìê°€ ì‹œí¬ë¦¿ì— ëŒ€í•´ ì ‘ê·¼ì´ ê°€ëŠ¥í•  ë•Œ ë°œìƒí•˜ëŠ” ì•ŒëŒì´ë‹¤. C-0041(HostNetwork access) : í˜¸ìŠ¤íŠ¸ ë„¤íŠ¸ì›Œí¬ì— ì—°ê²°í•  ê²½ìš° ë°œìƒí•˜ëŠ” ì•ŒëŒì´ë‹¤. í•„ìì˜ ê²½ìš° external-dns íŒŒë“œì—ì„œ ë°œìƒí–ˆë‹¤. í•­ëª©ì„ ì‚´í´ë³´ë‹ˆ ëŒ€ë¶€ë¶„ add-on íŒŒë“œë“¤ì— ëŒ€í•´ ë°œìƒí•œ ê²½ê³ ì´ë‹¤. ì´ëŸ¬í•œ ê²½ìš° ignore ë¡œ ì•ŒëŒ ë¬´ì‹œê°€ ê°€ëŠ¥í•˜ë‹¤.\nê° ëª¨ë²” ì‚¬ë¡€ ê¸°ì¤€ì´ ì—„ê²©í•˜ê³  ì„œë“œ íŒŒí‹° ë ˆë²¨ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ êµ¬ì„± ì •ë³´ í™•ì¸ì‹œ ê²€ì¦ ê³¼ì •ì—ì„œ ìœ ìš©í•˜ê²Œ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ê²ƒ ê°™ë‹¤.\nVulnerabilities ì·¨ì•½ì  ì ê²€ìœ¼ë¡œ ë°°í¬ ì»¨í…Œì´ë„ˆë“¤ì— ëŒ€í•´ ì·¨ì•½ì  ì ê²€ì„ ì§„í–‰í•œë‹¤. ì·¨ì•½ì  ì ê²€ì€ grype ì—”ì§„ì„ í†µí•´ ì§„í–‰ë˜ë©° CVE(Common Vulnerabilities and Exposures, ë¯¸êµ­ NSA, CISAì—ì„œ ì œê³µí•˜ëŠ” ë³´ì•ˆ ê°€ì´ë“œë¼ì¸) ì‹ë³„ìë¡œ ê²€ì‚¬ê°€ ì§„í–‰ëœë‹¤.\nìœ„ì™€ ë§ˆì°¬ê°€ì§€ë¡œ í•„ìì˜ í´ëŸ¬ìŠ¤í„°ì—ì„œ CRITICALí•œ ë ˆë²¨ì˜ ì·¨ì•½ì ì„ ì‚´í´ë³´ê² ë‹¤.\nGHSA-r48q-9g5r-8q2h(CVE-2022-1996) : emicklei/go-restfulì˜ ë²„ì „ 3.8.0 ì´ì „ì—ì„œ ë°œê²¬ëœ ì·¨ì•½ì ì´ë‹¤. ì‚¬ìš©ìê°€ ì œì–´í•  ìˆ˜ ìˆëŠ” í‚¤ë¥¼ í†µí•´ ê¶Œí•œì„ ìš°íšŒí•  ìˆ˜ ìˆëŠ” ë³´ì•ˆ ë¬¸ì œê°€ ìˆë‹¤ê³  í•œë‹¤. í•œ ê°€ì§€ ì˜ë¬¸ì€ kubescape ë‚´ íŒŒë“œì¸ kollector ì—ì„œ ë°œìƒí•˜ëŠ” ê²ƒì¸ë°, ê¹ƒí—ˆë¸Œ ì´ìŠˆì™€ ì»¤ë°‹ì—ë„ ì—†ëŠ” ì‚¬í•­ì´ë¼ ê¹ƒí—ˆë¸Œ ì´ìŠˆë¡œ ë“±ë¡í–ˆë‹¤.\nê·¸ ì™¸ì—ë„ metrics-server, coredns íŒŒë“œì—ì„œë„ ë°œìƒí–ˆìœ¼ë©° ê´€ë ¨ ê¹ƒ ì´ìŠˆë¥¼ ê³µìœ í•œë‹¤. ëŒ€ë¶€ë¶„ í•´ë‹¹ íŒ¨í‚¤ì§€ ë²„ì „ ì—…ë°ì´íŠ¸ë¡œ í”¼ë“œë°±í•˜ë©° ì—…ë°ì´íŠ¸í•˜ëŠ” ê²ƒ ê°™ë‹¤.\nRBAC Visualizer ì¿ ë²„ë„¤í‹°ìŠ¤ role ì— ë¶€ì—¬ëœ ì˜¤ë¸Œì íŠ¸ ì ‘ê·¼ ì œì–´ ê¶Œí•œì— ëŒ€í•´ ì‹œê°í™” ê¸°ëŠ¥ì„ ì œê³µí•´ì¤€ë‹¤. ìš´ì˜ì ìœ¼ë¡œ ë§¤ë ¥ì ì¸ ê¸°ëŠ¥ì´ë‹¤. ì•„ë˜ ê·¸ë¦¼ì²˜ëŸ¼ ì¿ ë²„ë„¤í‹°ìŠ¤ ServiceAccount ë³„ë¡œ ì ‘ê·¼ ì œì–´ ëª©ë¡ì„ í•œ ëˆˆì— í™•ì¸í•  ìˆ˜ ìˆì–´ ë¶ˆí•„ìš”í•œ ê¶Œí•œ ë° ì ‘ê·¼ ì œì–´ì— ëŒ€í•´ ê²€ì¦ì´ ê°€ëŠ¥í•  ê²ƒ ê°™ë‹¤.\nRepository scanning ì½”ë“œ ê´€ë¦¬ ì €ì¥ì†Œì¸ ê¹ƒí—ˆë¸Œ, ê¹ƒë© ë“±ì˜ ë ˆíŒŒì§€í† ë¦¬ì— ìŠ¤ìºë‹ ê²€ì‚¬ë¥¼ ì‹œì¼œì¤€ë‹¤.\në ˆíŒŒì§€í† ë¦¬ ë“±ë¡ì€ ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì. í•„ìëŠ” mac í™˜ê²½ì—ì„œ ì§„í–‰í–ˆë‹¤.\nê¹ƒí—ˆë¸Œ í† í°ì„ í™˜ê²½ ë³€ìˆ˜ë¡œ ë“±ë¡í•˜ê³ , kubescape CLI ë¥¼ í†µí•´ ì·¨ì•½ì  ê²€ì‚¬ ë° ì›¹ ëŒ€ì‹œë³´ë“œë¡œ ì •ë³´ë¥¼ ì „ë‹¬í•œë‹¤.\n1 export GITHUB_TOKEN=my-access-token Location ì€ ì €ì¥ì†Œ URL ì´ë‹¤. kubescape CLI ë¥¼ í†µí•´ ê²€ì‚¬í•˜ë©´ ì›¹ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. ì•„ë˜ í™”ë©´ì€ í•„ìì˜ ê¹ƒí—ˆë¸Œ ë ˆíŒŒì§€í† ë¦¬ë¥¼ ë“±ë¡í•´ì„œ ê²€ì‚¬í•˜ì˜€ë‹¤.\në ˆíŒŒì§€í† ë¦¬ì˜ ì½”ë“œì™€ í—¬ë¦„ ì°¨íŠ¸ì˜ value ê°’ë“¤ì—ë„ ì·¨ì•½ì  ê²€ì‚¬ê°€ ì§„í–‰ëœë‹¤.\ní•„ìì˜ ë ˆíŒŒì§€í† ë¦¬ì˜ ê²½ìš° C-0009(Resource limits) í•­ëª©ì´ ë§ì•„ í™•ì¸í•´ë³´ë‹ˆ resource limit ì„¤ì • ë¬¸ì œì˜€ë‹¤. í…ŒìŠ¤íŠ¸ í™˜ê²½ì—ì„œ ì§„í–‰í•¨ìœ¼ë¡œ ë¦¬ì†ŒìŠ¤ ì œí•œì„ í’€ì—ˆì§€ë§Œ ìš´ì˜ í™˜ê²½ì—ì„œ ë„ì…ì‹œ íŒŒë“œ êµ¬ì„± í™˜ê²½ì— ë”°ë¼ ì„¤ì •í•´ì•¼ê² ë‹¤.\nRegistry Scanning ì´ë¯¸ì§€ ë ˆíŒŒì§€í† ë¦¬ì—ë„ ê²€ì‚¬ê°€ ê°€ëŠ¥í•˜ë‹¤. í•˜ë²„ì—ì„œë„ ì´ë¯¸ì§€ ì·¨ì•½ì  ì ê²€ì´ ê°€ëŠ¥í•˜ëŠ” ê²ƒìœ¼ë¡œ ì•Œê³  ìˆëŠ”ë° ì°¨ì´ì ì„ í™•ì¸í•´ë³´ê² ë‹¤. ê¸°ëŠ¥ í™•ì¸ì„ ìœ„í•´ í•˜ë²„ë¥¼ í´ëŸ¬ìŠ¤í„°ì— ì„¤ì¹˜í•˜ì—¬ ìŠ¤ìºë‹ ê¸°ëŠ¥ì„ í…ŒìŠ¤íŠ¸í•˜ì˜€ë‹¤. ë“±ë¡ì‹œ ìŠ¤ìºë‹ ì£¼ê¸°ì™€ íƒœê·¸ ê°œìˆ˜ë¥¼ ì„¤ì •í•  ìˆ˜ ìˆë‹¤.\nì‹œê°„ë³„ë¡œ ì´ë¯¸ì§€ ë ˆíŒŒì§€í† ë¦¬ì— ì·¨ì•½ ì ê²€ì´ ê°€ëŠ¥í•˜ë‹¤. ë§ˆì°¬ê°€ì§€ë¡œ grype ì—”ì§„ì„ í†µí•´ ì´ë¯¸ì§€ ì·¨ì•½ì  ì ê²€ì„ ì§„í–‰í•œë‹¤.\nINTEGRATIONS kubescape íˆ´ì€ Code, CI / CD ì—ë„ í™œìš©ì´ ê°€ëŠ¥í•˜ë‹¤.\nhttps://github.com/kubescape/kubescape\nê³µì‹ë¬¸ì„œë¥¼ í™•ì¸í•˜ë‹ˆ jenkins, gitlab CI / CD ì—ì„œë„ job ìŠ¤ì¼€ì¥´ë§ìœ¼ë¡œ ì·¨ì•½ì  ì ê²€ì´ ê°€ëŠ¥í•˜ë‹¤. CI / CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ì´í›„ ê³ ë ¤í•´ë³´ë„ë¡ í•˜ì.\n3rd party ì• í”Œë¦¬ì¼€ì´ì…˜ ì—°ë™ì„ í†µí•´ ì•ŒëŒ êµ¬ì„±ë„ ì‰½ê²Œ ê°€ëŠ¥í•˜ë‹¤. ìŠ¬ë™ì—ì„œë„ ì•ŒëŒ ì„¤ì •ì´ ì‰½ê²Œ ê°€ëŠ¥í•œë°, ìŠ¤ìºë‹ê³¼ ì ê²€ ë ˆë²¨ì— ë”°ë¼ ì•ŒëŒ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤.\në§ˆì¹˜ë©° ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆ ê³„ì¸µê³¼ ë³´ì•ˆ íˆ´ì¸ kubescapeë¥¼ ì‚´í´ë³´ì•˜ë‹¤. ê°œì¸ì ìœ¼ë¡œ ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ë³´ì•ˆ ìƒíƒœê³„ë¥¼ ê²½í—˜í•˜ì—¬ ì—­ëŸ‰ í–¥ìƒì— ë„ì›€ì´ ë˜ì—ˆë‹¤. í•„ìê°€ ìƒê°í•˜ê¸°ì— kubescape íˆ´ì€ ë¯¸êµ­ ê°€ì´ë“œë¼ì¸ì˜ ì‚¬ë¡€ë‚˜ ì·¨ì•½ì  ì ê²€ê³¼ grype ì—”ì§„ì„ í†µí•©í•´ì„œ í‰ê°€í•´ì£¼ëŠ” operator íˆ´ ëŠë‚Œì´ ê°•í–ˆë‹¤. ë¹„ì¦ˆë‹ˆìŠ¤ ëª¨ë¸ì— ë”°ë¼ ë‹¬ë¼ì§€ê² ì§€ë§Œ ë¹„ìŠ·í•œ operator íˆ´ì„ ëŒ€ì•ˆìœ¼ë¡œ ì°¾ìœ¼ë©´ ì¢‹ì„ ê²ƒ ê°™ë‹¤.\n","date":"Apr 07","permalink":"https://HanHoRang31.github.io/post/pkos-5-security/","tags":["KANS","kops","cloud","AWS","kubernetes","security","kubescape"],"title":"[PKOS] ì¿ ë²„ë„¤í‹°ìŠ¤ ë³´ì•ˆê³¼ Kubescape DeepDive"},{"categories":null,"contents":" 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. ìŠ¤í„°ë”” 4ì£¼ì°¨ ì‹œê°„ì—ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ëª¨ë‹ˆí„°ë§ê³¼ ë¡œê¹… ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì—¬ ê¸°ëŠ¥ë“¤ì„ ì‚´í´ë³´ì•˜ë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì— ëŒ€í•´ ì‹¬í™” í•™ìŠµí•œ ë‚´ìš©ë“¤ì„ ê³µìœ í•˜ê³ ì í•œë‹¤.\nëª¨ë‹ˆí„°ë§ì€ ì–´ë–¤ ëŒ€ìƒì„ ê°ì‹œ, ê°ì°°í•œë‹¤ëŠ” ëœ»ìœ¼ë¡œ ëª¨ë‹ˆí„°ë§ì˜ ëª©ì ì€ ì§€ì†ì ì¸ ê°ì‹œ, ê°ì°°ì„ í†µí•´ ëŒ€ìƒì˜ ìƒíƒœë‚˜ ê°€ìš©ì„±, ë³€í™” ë“±ì„ í™•ì¸í•˜ê³  ëŒ€ë¹„í•˜ëŠ” ê²ƒì´ë‹¤. ëª¨ë‹ˆí„°ë§ì˜ ê°œë…ì²˜ëŸ¼ ì¿ ë²„ë„¤í‹°ìŠ¤ ëª¨ë‹ˆí„°ë§ë„ ë˜‘ê°™ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ íŠ¹ì • ê¸°ê°„ì— ì¸¡ì •í•œ ì¼ë ¨ì˜ ìˆ«ì(ë©”íŠ¸ë¦­)ì— ëŒ€í•´ ê°ì‹œì™€ ê°ì°°ì„ í†µí•´ ëŒ€ìƒì˜ ìƒíƒœë‚˜ ê°€ìš©ì„± ë³€í™”ë¥¼ í™•ì¸í•˜ê³  ëŒ€ë¹„í•œë‹¤ê³  ë³´ë©´ ë˜ê² ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œìœ¼ë¡œëŠ” Prometheus, InfluxDB, DataDog, í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë” ë“±ì´ ìˆìœ¼ë‚˜ ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ì˜¤í”ˆì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì¸ Prometheusì™€ ê¸°ëŠ¥ í™•ì¥ ì‹œìŠ¤í…œì¸ Thanosë¥¼ ë‹¤ë£¨ê² ë‹¤.\nPrometheus ì˜¤í”ˆ ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì´ë‹¤. ì‹œê³„ì—´ ë°ì´í„° ìˆ˜ì§‘, ì €ì¥ ë° ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ì œê³µí•˜ê³  ë‹¤ì–‘í•œ ê²½ê³  ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ì˜¤í”ˆì†ŒìŠ¤ ì§„ì˜ì—ì„œ ê°€ì¥ ë§ì´ ì‚¬ìš©í•˜ëŠ” ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œìœ¼ë¡œ ì‚¬ì‹¤ìƒ ê±°ì˜ í‘œì¤€ì²˜ëŸ¼ ì‚¬ìš©í•˜ê³  ìˆë‹¤. ì•„í‚¤í…ì²˜ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. (ê³µì‹ë¬¸ì„œ)\nhttps://prometheus.io/docs/introduction/overview/\në¹¨ê°„ ë„¤ëª¨ë¡œ í‘œì‹œëœ ê²ƒì´ í”„ë¡œë©”í…Œìš°ìŠ¤ êµ¬ì„± ì»´í¬ë„ŒíŠ¸ì´ë‹¤.\nPrometheus Server : Prometheus ì„œë²„ëŠ” ë©”íŠ¸ë¦­ ìˆ˜ì§‘, ì €ì¥, ì²˜ë¦¬ ë° ì¿¼ë¦¬ ê¸°ëŠ¥ì„ ìˆ˜í–‰í•œë‹¤. ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë°©ì‹ìœ¼ë¡œ Pull ë°©ì‹ì„ ê¸°ë³¸ì ìœ¼ë¡œ ì‚¬ìš©í•œë‹¤. í•´ë‹¹ ì„œë²„ê°€ ëŒ€ìƒ ì„œë¹„ìŠ¤ë¡œë¶€í„° ë©”íŠ¸ë¦­ì„ ì£¼ê¸°ì ìœ¼ë¡œ ìˆ˜ì§‘í•˜ê³ , ì‹œê³„ì—´ ë°ì´í„°ë² ì´ìŠ¤(TSDB, HDD/SDD)ì— ì €ì¥í•œë‹¤. ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•œ ë°ì´í„°ëŠ” ì¿¼ë¦¬ ì–¸ì–´ PromQLì„ í†µí•´ ë°ì´í„°ë¥¼ í•„í„°ë§, ì§‘ê³„ ì‹œê°í™”í•˜ëŠ”ë° ì‚¬ìš©í•œë‹¤. Pushgateway : PushgatewayëŠ” Push ë°©ì‹ì„ ì‚¬ìš©í•˜ëŠ” ì¼ë¶€ ìœ í˜•ì˜ ë©”íŠ¸ë¦­ì„ Prometheusì—ì„œ ìˆ˜ì§‘í•˜ê¸° ìœ„í•œ ì¤‘ê°„ ì„œë²„ì´ë‹¤. ì£¼ë¡œ ì¼íšŒì„± ì‘ì—…(ì˜ˆ: ë°°ì¹˜ ì‘ì—…)ìœ¼ë¡œë¶€í„° ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ëŠ” ë° ì‚¬ìš©ëœë‹¤. ì‘ì—…ì´ ì¢…ë£Œë˜ë”ë¼ë„ ë©”íŠ¸ë¦­ì´ ë³´ì¡´ë˜ì–´ Prometheus ì„œë²„ê°€ í•´ë‹¹ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•  ìˆ˜ ìˆê²Œ í•œë‹¤. Alertmanager: AlertmanagerëŠ” Prometheus ì„œë²„ì—ì„œ ë°œìƒí•œ ê²½ê³ ë¥¼ ê´€ë¦¬í•˜ê³ , ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼ì„ ì „ë‹¬í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. Prometheus UI : ë‚´ì¥ëœ ì›¹ ì¸í„°í˜ì´ìŠ¤ë¡œ, ì‚¬ìš©ìê°€ Prometheus ì„œë²„ì—ì„œ ë©”íŠ¸ë¦­ì„ ì¿¼ë¦¬í•˜ê³ , ì‹œê°í™”ëœ ê·¸ë˜í”„ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì‚¬ìš©ìëŠ” PromQLì„ ì‚¬ìš©í•˜ì—¬ ì›í•˜ëŠ” ë©”íŠ¸ë¦­ì„ ê²€ìƒ‰í•˜ê³  ë¶„ì„í•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ë³¸ì ì¸ ëŒ€ì‹œë³´ë“œ ë° ê²½ê³  ì„¤ì •ì„ ê´€ë¦¬í•  ìˆ˜ ìˆë‹¤. ì•„í‚¤í…ì²˜ë¥¼ ì‚´í´ë³´ì•˜ëŠ”ë° í”„ë¡œë©”í…Œìš°ìŠ¤ëŠ” ë‹¨ì¼ ë…¸ë“œ ì‹œìŠ¤í…œìœ¼ë¡œ ì„¤ê³„ë˜ì–´ ìˆì–´ í´ëŸ¬ìŠ¤í„°ë§ êµ¬ì¡°ë¥¼ ì§ì ‘ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ë¡œì¸í•´ í™•ì¥ì„±ê³¼ ê³ ê°€ìš©ì„±ì— ì¼ë¶€ ë³´ì™„ì´ í•„ìš”í•˜ë‹¤.\ní™•ì¥ì„± ë¬¸ì œ ë‹¨ì¼ ë…¸ë“œì—ì„œ ëª¨ë“  ë©”íŠ¸ë¦­ì„ ì²˜ë¦¬í•˜ë ¤ í•  ë•Œ ë…¸ë“œì˜ ìì›ì´ ê³ ê°ˆë˜ì–´ ì„±ëŠ¥ ì €í•˜ë¥¼ ì´ˆë˜í•  ìˆ˜ ìˆë‹¤. ëŒ€ê·œëª¨ ì¸í”„ë¼ì—ì„œ ë§ì€ ìˆ˜ì˜ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•˜ê³  ì²˜ë¦¬í•˜ëŠ” ë° ìˆì–´ ì„±ëŠ¥ ì €í•˜ì™€ ì €ì¥ì†Œ ë¶€ì¡± ë¬¸ì œê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ ì—°ê²°ì´ í•„ìš”í•˜ë‹¤. ê³ ê°€ìš©ì„± ë¬¸ì œ ë‹¨ì¼ ë…¸ë“œì—ì„œ ë°œìƒí•˜ëŠ” ì¥ì• ë‚˜ ë‹¤ìš´íƒ€ì„ì´ ìƒê²¨ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ê°€ ë‚´ë ¤ê°€ë©´ ê·¸ ì‹œê°„ ë™ì•ˆì—ëŠ” ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•  ìˆ˜ ì—†ë‹¤. ë³¼ë¥¨ì´ AWS EBS ë¥¼ ì‚¬ìš©í•´ë„ ë‹¨ì¼ ë…¸ë“œì—ì„œë§Œ ì—°ê²°ì´ ê°€ëŠ¥í•˜ë‹¤. ì—°ê²° ë…¸ë“œì— ë‹¤ìš´ íƒ€ì„ì´ ë°œìƒí•˜ë©´ ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ë‹¤. ì´ëŸ¬í•œ ë¬¸ì œë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ë„êµ¬ë¡œ Thanosë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤.\nThanos í”„ë¡œë©”í…Œìš°ìŠ¤ì˜ í™•ì¥ì„±ê³¼ ê³ ê°€ìš©ì„±ì„ ê°œì„ í•˜ê¸° ìœ„í•œ ì‹œìŠ¤í…œì´ë‹¤. ì‚¬ì´íŠ¸ ì •ë¬¸ì— ëŒ€ë†“ê³  í”„ë¡œë©”í…Œìš°ìŠ¤ë¥¼ ì €ê²©í•˜ê³  ìˆë‹¤. íƒ€ë…¸ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ í†µí•´ ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìˆëŠ” í™•ì¸í•´ë³´ê² ë‹¤.\nhttps://thanos.io/v0.6/thanos/getting-started.md/\níŒŒë€ ë„¤ëª¨ê°€ íƒ€ë…¸ìŠ¤ êµ¬ì„± ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì„¤ê³„ ë””ìì¸ì€ ê³µì‹ ë¬¸ì„œì—ì„œë„ ì°¸ê³ ê°€ ê°€ëŠ¥í•˜ë‹¤.\nThanos Sidecar : Prometheusì— ì—°ê²°ë˜ì–´ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ì¿¼ë¦¬í•˜ê³  í´ë¼ìš°ë“œ ìŠ¤í† ë¦¬ì§€ì— ì—…ë¡œë“œí•œë‹¤. ë…¸ë“œë§ˆë‹¤ ì‚¬ì´ë“œì¹´ê°€ ì—°ê²°ë˜ë©° ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ ì €ì¥ì„ í†µí•´ í™•ì¥ì„±ì„ ê°œì„ ì‹œí‚¤ëŠ” ì—­í• ì˜ ì»´í¬ë„ŒíŠ¸ì´ë‹¤. Thanos Store Gateway : ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì— ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ ì½ì–´ Thanos Queryë¡œ ì „ë‹¬í•œë‹¤. í•´ë‹¹ ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•´ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì—ì„œ ê³¼ê±° ë°ì´í„°ë„ ì¿¼ë¦¬í•  ìˆ˜ ìˆê²Œ ëœë‹¤. Thanos Query : ì‚¬ìš©ì ì¿¼ë¦¬ë¥¼ ìš”ì²­ ì²˜ë¦¬í•˜ë©° ì§§ì€ ì‹œê°„ì˜ ë°ì´í„°ëŠ” íƒ€ë…¸ìŠ¤ ì‚¬ì´ë“œì¹´ì—ì„œ ê°€ì ¸ì˜¤ë©°, ì˜¤ë˜ëœ ë°ì´í„°ëŠ” ìŠ¤í† ì–´ ê²Œì´íŠ¸ì›¨ì´ë¥¼ í†µí•´ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì—ì„œ ê°€ì ¸ì˜¨ë‹¤. Prometheus Query APIë¥¼ êµ¬í˜„í•˜ì—¬ ì‚¬ìš©ìê°€ ê¸°ì¡´ì˜ Prometheus ì¿¼ë¦¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆê²Œ í•œë‹¤. í”„ë¡œë©”í…Œìš°ìŠ¤ë‹¨ì—ì„œ ê³ ê°€ìš©ì„±ì„ ì œê³µí•´ì£¼ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. í†µí•© ë°ì´í„°ê°„ì˜ ì¤‘ë³µ ì œê±° (de-duplication) ê¸°ëŠ¥ì„ ê¸°ë³¸ìœ¼ë¡œ ì œê³µí•˜ì—¬ ì—¬ëŸ¬ í”„ë¡œë©”í…Œìš°ìŠ¤ ë° ì›ê²© ìŠ¤í† ë¦¬ì§€ì˜ ë©”íŠ¸ë¦­ ë°ì´í„°ë¥¼ í†µí•©í•˜ì—¬ ì¿¼ë¦¬í•  ìˆ˜ ìˆê²Œ í•´ì¤€ë‹¤. í•œ ê°€ì§€ ì£¼ì˜í•  ì ì€ Thanos query ë„ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•´ì¤˜ì•¼ í•œë‹¤. ê³µì‹ ë¬¸ì„œì— ë”°ë¥´ë©´ íƒ€ë…¸ìŠ¤ êµ¬ì„± íŒŒë“œë“¤ì€ ìƒ¤ë”© ìˆ˜ë‹¨ì„ ì œê³µí•˜ì§€ ì•Šì•„, ëª¨ë‘ ìˆ˜í‰ì  í™•ì¥ì´ ê°€ëŠ¥í•˜ë‹¤. íƒ€ë…¸ìŠ¤ ë°°í¬ì‹œ ì¿¼ë¦¬ íŒŒë“œ ê°œìˆ˜ë¥¼ 2ê°œ ì´ìƒìœ¼ë¡œ ì¡°ì ˆí•˜ì—¬ ê°€ìš©ì„±ì„ ë³´ì¥ì‹œí‚¤ì.\nhttps://observability.thomasriley.co.uk/prometheus/using-thanos/high-availability/\nhttps://thanos.io/tip/thanos/design.md/#metric-sources\nThanos Compactor : íƒ€ë…¸ìŠ¤ ì¿¼ë¦¬ì™€ëŠ” ë³„ê°œì˜ í”„ë¡œì„¸ìŠ¤ë¡œ, ê°ì²´ ìŠ¤í† ë¦¬ì§€ ë²„í‚·ë§Œ ê°€ë¦¬í‚¤ë©° ì—¬ëŸ¬ ê°œì˜ ì‘ì€ ë¸”ë¡ì„ ë” í° ë¸”ë¡ìœ¼ë¡œ ì§€ì†ì ìœ¼ë¡œ í†µí•©ì‹œì¼œì£¼ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ë¸”ë¡ì„ í†µí•©ì‹œí‚¤ë©´ ë°ì´í„°ê°€ ì••ì¶•í•˜ê²Œ ë˜ë¯€ë¡œ ë²„í‚·ì˜ ì´ ìŠ¤í† ë¦¬ì§€ í¬ê¸°, ìŠ¤í† ì–´ ë…¸ë“œì˜ ë¡œë“œ ë° ë²„í‚·ì—ì„œ ì¿¼ë¦¬ ë°ì´í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë° í•„ìš”í•œ ìš”ì²­ ìˆ˜ê°€ í¬ê²Œ ì¤„ì–´ë“ ë‹¤. Thanos Ruler : í”„ë¡œë©”í…Œìš°ìŠ¤ ì¸ìŠ¤í„´ìŠ¤ë“¤ë¡œë¶€í„° ì•Œë¦¼ ê·œì¹™ ì •ë³´ë¥¼ ê°€ì ¸ì™€ í†µí•©í•˜ê³ , í”„ë¡œë©”í…Œìš°ìŠ¤ì™€ í•¨ê»˜ ì‘ë™í•˜ëŠ” ì™¸ë¶€ ì•Œë¦¼ ì‹œìŠ¤í…œì—ê²Œ ì•Œë¦¼ì„ ì „ì†¡í•˜ëŠ” ì—­í• ì˜ ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì—°ê³„ ë°°í¬ ë°°í¬ í™˜ê²½ : kops í´ëŸ¬ìŠ¤í„° (k8s 1.24), AWS Ubuntu ì¸ìŠ¤í„´ìŠ¤\ní”„ë¡œë©”í…Œìš°ìŠ¤ \u0026amp; íƒ€ë…¸ìŠ¤ë¥¼ ì—°ê³„í•˜ì—¬ ë°°í¬í•œë‹¤. ë°°í¬ë¥¼ ìœ„í•´ í—¬ë¦„ ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•  ì˜ˆì •ì´ë©° í”„ë¡œë©”í…Œìš°ìŠ¤ ë°°í¬ëŠ” kube-prometheus-stack(ê·¸ë¼íŒŒë‚˜, ì¶”ê°€ ë©”íŠ¸ë¦­ ìë™ êµ¬ì„±) ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•  ê²ƒì´ë‹¤. ë˜í•œ íƒ€ë…¸ìŠ¤ëŠ” bitnami/thanos ì°¨íŠ¸ë¥¼ ì‚¬ìš©í•  ê²ƒì´ë©° íƒ€ë…¸ìŠ¤ ì™¸ë¶€ìŠ¤í† ë¦¬ì§€ëŠ” MinIOë¥¼ ë°°í¬í•˜ì—¬ ì—°ê²°í•  ê²ƒì´ë‹¤. ì „ì²´ ë°°í¬ ìˆœì„œëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤. êµ¬ì„± ì°¨íŠ¸ëŠ” í•„ìì˜ ê¹ƒí—ˆë¸Œì—ì„œ ì°¸ê³ ê°€ ê°€ëŠ¥í•˜ë‹¤.\nMInIO ë°°í¬ kube-promethes-statck ì„¤ì • \u0026amp; ë°°í¬ íƒ€ë…¸ìŠ¤ ì„¤ì • \u0026amp; ë°°í¬ ê·¸ë¼íŒŒë‚˜ ì„¤ì • ë° ëŒ€ì‹œë³´ë“œ í™•ì¸ 1. MinIO ë°°í¬ íƒ€ë…¸ìŠ¤ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ë¡œ MinIOë¥¼ ì„¤ì •í•  ê²ƒì´ë‹¤. ì´ë¥¼ ìœ„í•œ ì‚¬ì „ ì‘ì—…ìœ¼ë¡œ MinIOë¥¼ ë¨¼ì € ë°°í¬í•˜ê² ë‹¤.\nì°¨íŠ¸ ê°€ì ¸ì˜¤ê¸°\n1 2 3 helm repo add minio https://charts.bitnami.com/bitnami helm repo update helm fetch minio/minio --untar --version 12.2.1 ì°¨íŠ¸ ì„¤ì •\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 # values-minio.yaml mode: distributed auth: rootUser: admin rootPassword: \u0026#34;admin1234\u0026#34; statefulset: replicaCount: 4 zones: 1 drivesPerNode: 1 provisioning: config: - name: region options: name: ap-northeast-2 ingress: enabled: true hostname: minio.hanhorang.link path: /* annotations: kubernetes.io/ingress.class: alb alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}, {\u0026#34;HTTPS\u0026#34;:9090}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: \u0026#34;$ACM arn \u0026#34; persistence: storageClass: \u0026#34;kops-csi-1-21\u0026#34; ë¶„ì‚°ìŠ¤í† ë¦¬ì§€ ëª¨ë“œë¡œ ì„¤ì • (í…ŒìŠ¤íŠ¸í™˜ê²½ ë…¸ë“œ 4ê°œ) ë…¸ë“œë‹¹ íŒŒë“œ í•˜ë‚˜ë¥¼ í• ë‹¹ Ingress(ë„¤íŠ¸ì›Œí¬) : AWS ALB ì„¤ì • persistence(ë³¼ë¥¨) : AWS gp2 ê¸°ë³¸ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ ì„¤ì • ë°°í¬\n1 2 kubectl create ns minio helm install minio minio/minio -f values-minio.yaml -n minio --version 12.2.1 ë²„í‚· ìƒì„± ë° ì ‘ê·¼ í‚¤ ë°œê¸‰\níƒ€ë…¸ìŠ¤ì—ì„œ minio ë²„í‚·ì— ì ‘ê·¼í•˜ê¸° ìœ„í•œ ì ‘ê·¼ í‚¤ë¥¼ ë°œê¸‰ë°›ì\nminio ë„ë©”ì¸ ì ‘ì†\nì–´ë“œë¯¼ ê³„ì •ì€ ì°¨íŠ¸ì—ì„œ admin / admin1234 ë¡œ ì„¤ì •ë˜ì–´ ìˆë‹¤. ë¡œê·¸ì¸ì„ í•˜ì.\në¡œê·¸ì¸ì´ ì™„ë£Œë˜ë©´ ë‹¤ìŒê³¼ ê°™ì€ í™”ë©´ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\në²„í‚· ìƒì„± í›„ ë²„í‚· ì ‘ê·¼ì„ ìœ„í•œ ì•¡ì„¸ìŠ¤ í‚¤ ë°œê¸‰ì´ í•„ìš”í•˜ë‹¤. ì™¼ìª½ ë©”ë‰´ [Access Keys] ì—ì„œ í‚¤ë¥¼ ë°œê¸‰ë°›ì.\nAccess Key ë°œê¸‰ í›„ MINIO ë™ì‘ ê¶Œí•œì„ ë“±ë¡í•´ì•¼ í•œë‹¤. ìƒì„±í•œ í‚¤ë¥¼ í´ë¦­í•˜ë©´ ì •ì±… ì…ë ¥ ì¹¸ì´ ë‚˜ì˜¨ë‹¤. ì•„ë˜ ì •ì±…ì„ ì…ë ¥í•˜ë„ë¡ í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;admin:*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;kms:*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:*\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::*\u0026#34; ] } ] } í•„ìì˜ ê²½ìš° ì ‘ê·¼ í‚¤ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ìƒì„±ë˜ì—ˆë‹¤.\naccess_key : aajl91wFPCRVmfWR\nsecret_key: SfP4woqjY3fcyh1cuwF1CNQFEe6hs4X6\në°œê¸‰ë°›ì€ í‚¤ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Secretì„ ìƒì„±í•˜ì.\n1 2 3 4 5 6 7 #minio-key.yaml type: s3 config: bucket: thanos endpoint: minio.hanhorang.link access_key: aajl91wFPCRVmfWR secret_key: SfP4woqjY3fcyh1cuwF1CNQFEe6hs4X6 1 2 kubectl create ns monitoring kubectl create secret generic thanos-minio-secret -n monitoring --from-file=minio-key.yaml 2. kube-promethes-statck ì„¤ì • \u0026amp; ë°°í¬ í”„ë¡œë©”í…Œìš°ìŠ¤ ë°°í¬ ë° ì‚¬ì´ë“œ ì¹´ì— íƒ€ë…¸ìŠ¤ ì—°ë™ì„ ìœ„í•œ ì„¤ì •ì„ ì§„í–‰í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 helm repo add prometheus-community https://prometheus-community.github.io/helm-charts helm repo update helm fetch prometheus-community/kube-prometheus-stack --untar --version 45.7.1 # ì‚¬ìš© ë¦¬ì „ì˜ ì¸ì¦ì„œ ARN í™•ì¸ CERT_ARN=`aws acm list-certificates --query \u0026#39;CertificateSummaryList[].CertificateArn[]\u0026#39; --output text` echo \u0026#34;alb.ingress.kubernetes.io/certificate-arn: $CERT_ARN\u0026#34; KOPS_CLUSTER_NAME=\u0026#34;hanhorang.link\u0026#34; 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 # values-kube-prometheus-stack.yaml cat \u0026lt;\u0026lt;EOT \u0026gt; ./values-kube-prometheus-stack.yaml alertmanager: enabled: false grafana: defaultDashboardsTimezone: Asia/Seoul adminPassword: admin1234 ingress: enabled: true ingressClassName: alb annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: $CERT_ARN alb.ingress.kubernetes.io/success-codes: 200-399 alb.ingress.kubernetes.io/group.name: \u0026#34;monitoring\u0026#34; hosts: - grafana.$KOPS_CLUSTER_NAME paths: - /* prometheus: # ì‚¬ì´ë“œì¹´ ë…¸ì¶œ ì„œë¹„ìŠ¤ ì„¤ì • thanosService: enabled: true ingress: enabled: true ingressClassName: alb annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: $CERT_ARN alb.ingress.kubernetes.io/success-codes: 200-399 alb.ingress.kubernetes.io/group.name: \u0026#34;monitoring\u0026#34; hosts: - prometheus.$KOPS_CLUSTER_NAME paths: - /* prometheusSpec: podMonitorSelectorNilUsesHelmValues: false serviceMonitorSelectorNilUsesHelmValues: false retention: 5d retentionSize: \u0026#34;10GiB\u0026#34; scrapeInterval: \u0026#34;15s\u0026#34; # alert ê´€ë ¨ ì„¤ì •ìœ¼ë¡œ ì£¼ì„ ì²˜ë¦¬ # evaluationInterval: 15s # ê°€ìš©ì„± ì„¤ì • replicas: 3 # íƒ€ë…¸ìŠ¤ ì„¤ì • thanos: image: \u0026#34;quay.io/thanos/thanos:v0.27.0\u0026#34; objectStorageConfig: key: minio-key.yaml name: thanos-minio-secret version: v0.27.0 # ë³¼ë¥¨ ì„¤ì • storageSpec: {} ## Using PersistentVolumeClaim ## # volumeClaimTemplate: # spec: # storageClassName: gluster # accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] # resources: # requests: # storage: 50Gi # selector: {} EOT ì•ŒëŒì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŒìœ¼ë¡œ alertmanager falseë¡œ ì„¤ì •í•˜ì˜€ë‹¤. í—¬ë¦„ ì°¨íŠ¸ë¥¼ ë³´ë©´ prometheus.thanos ì— ì„¤ì •í•˜ëŠ” ë¶€ë¶„ì´ ìˆëŠ”ë° ì—¬ê¸°ì„œ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë‹¤! ì›ê²© ìŠ¤í† ë¦¬ì§€ ì ‘ê·¼ì— ëŒ€í•œ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë¯€ë¡œ prometheus.prometheusSpec.thanos ì— ì•ì„œ ìƒì„±í•œ ì‹œí¬ë¦¿ í‚¤ë¥¼ ì…ë ¥í•˜ì. (ìœ„ì— ì°¨íŠ¸ ê·¸ëŒ€ë¡œ ì…ë ¥í•˜ë©´ ë¬¸ì œì—†ìŠµë‹ˆë‹¤.) 1 2 3 4 kubectl create ns monitoring helm install kube-prometheus-stack prometheus-community/kube-prometheus-stack --version 45.7.1 \\ -f values-kube-prometheus-stack.yaml --namespace monitoring ë°°í¬ ì´í›„ íƒ€ë…¸ìŠ¤ ì‚¬ì´ë“œì¹´ ì—°ë™ì„ í™•ì¸í•˜ì.\n1 kubectl describe pods prometheus-kube-prometheus-stack-prometheus-0 -n monitoring ì„±ê³µì´ë‹¤!\n3. íƒ€ë…¸ìŠ¤ ì„¤ì • \u0026amp; ë°°í¬ íƒ€ë…¸ìŠ¤ ì‚¬ì´ë“œì¹´ë¥¼ ì œì™¸í•œ ì»´í¬ë„ŒíŠ¸ë¥¼ ì„¤ì¹˜í•˜ê³  thnaos query ê°€ í”„ë¡œë©”í…Œìš°ìŠ¤ ì‚¬ì´ë“œì¹´ë¡œ, store gatewayê°€ ì›ê²© ìŠ¤í† ë¦¬ì§€ì¸ minio ë¡œ ì—°ë™í•  ìˆ˜ ìˆë„ë¡ ì„¤ì •í•´ì•¼ í•œë‹¤. ì°¨íŠ¸ë¶€í„° ê°€ì ¸ì˜¤ë„ë¡ í•˜ì.\n1 2 3 helm repo add bitnami https://charts.bitnami.com/bitnami helm repo update helm fetch bitnami/thanos --untar --version 12.3.2 íƒ€ë…¸ìŠ¤ ì—°ë™ì„ ìœ„í•´ ì„¤ì •ì„ ì§„í–‰í•œë‹¤. ë©”íŠ¸ë¦­ì„ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ë²„í‚· ì •ë³´ì™€ í”„ë¡œë©”í…Œìš°ìŠ¤ ë°°í¬ì‹œ ê°™ì´ ë°°í¬ëœ íƒ€ë…¸ìŠ¤ ì‚¬ì´ë“œì¹´ ì„œë¹„ìŠ¤ ì£¼ì†Œë¥¼ ì…ë ¥í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 objstoreConfig: |- type: s3 config: bucket: monitoring endpoint: minio.minio.svc.cluster.local:9000 access_key: aajl91wFPCRVmfWR secret_key: SfP4woqjY3fcyh1cuwF1CNQFEe6hs4X6 insecure: true querier: stores: - kube-prometheus-stack-thanos-discovery.monitoring.svc.cluster.local:10901 - thanos-storegateway.monitoring.svc.cluster.local:10901 replicaCount: 2 ingress: enabled: true hostname: thanos.hanhorang.link ingressClassName: \u0026#34;alb\u0026#34; annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: arn:aws:acm:ap-northeast-2:955963799952:certificate/7569648c-bfd5-4860-b2c1-16ef02acbb58 alb.ingress.kubernetes.io/success-codes: 200-399 alb.ingress.kubernetes.io/group.name: \u0026#34;monitoring\u0026#34; path : /* bucketweb: enabled: true compactor: enabled: true storegateway: enabled: true ruler: enabled: false objstoreConfig.config.endpoint ë¥¼ ì„œë¹„ìŠ¤ DNSë¡œ ëŒ€ì²´í–ˆë‹¤. ALB ë„ë©”ì¸ ì…ë ¥ì‹œ Timeout ìœ¼ë¡œ íŒŒë“œê°€ ì˜¬ë¼ê°€ì§€ ì•Šê¸° ë•Œë¬¸ì´ë‹¤. querier.store ì— ì¿¼ë¦¬í•  ëŒ€ìƒì„ ë“±ë¡í•œë‹¤. ëŒ€ìƒìœ¼ë¡œ íƒ€ë…¸ìŠ¤ ì‚¬ì´ë“œì¹´ì˜ ì„œë¹„ìŠ¤ ì£¼ì†Œì™€ ìŠ¤í† ì–´ê²Œì´íŠ¸ì›¨ì´ë¥¼ ë“±ë¡í•œë‹¤. ë°°í¬\n1 2 3 helm install thanos bitnami/thanos --version 12.3.2 \\ -f values-thanos.yaml --namespace monitoring ë°°í¬ ì™„ë£Œ í›„ íƒ€ë…¸ìŠ¤ ì¿¼ë¦¬ í˜¸ìŠ¤íŠ¸ ë„ë©”ì¸ì„ í†µí•´ ì ‘ì†í•˜ì. Storeì™€ Status/Targetë¥¼ í™•ì¸í•˜ì—¬ ì‚¬ì´ë“œì¹´ ì—°ë™ì„ í™•ì¸í•œë‹¤.\níƒ€ë…¸ìŠ¤ê°€ ì •ìƒì ìœ¼ë¡œ ë°°í¬ëœ ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. ë°°í¬ ì´í›„ì—ëŠ” í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ë¥¼ 2ê°œ ì´ìƒ ë„ì–´ì„œ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ê°€ ê³ ê°€ìš©ì„±ì„ ê°–ë„ë¡ êµ¬ì„±í•˜ì. (ì•ì„œ í”„ë¡œë©”í…Œìš°ìŠ¤ ë°°í¬ì‹œ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ë¥¼ 3ê°œë¥¼ ë°°í¬í•˜ì˜€ë‹¤)\n3ê°œì˜ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ê°€ ì„œë¡œ ë…ë¦½ì ìœ¼ë¡œ ë©”íŠ¸ë¦­ì„ ìˆ˜ì§‘í•œë‹¤. íƒ€ë…¸ìŠ¤ ì¿¼ë¦¬ëŠ” í”„ë¡œë©”í…Œìš°ìŠ¤ì— ë“±ë¡ëœ ì‚¬ì´ë“œì¹´ë¥¼ í†µí•´ ë©”íŠ¸ë¦­ì„ í†µí•© ìˆ˜ì§‘í•œë‹¤. ì´ ë•Œ ê³ ê°€ìš©ì„±ì´ ë³´ì¥ë˜ëŠ”ë° í•˜ë‚˜ì˜ í”„ë¡œë©”í…Œìš°ìŠ¤ê°€ ë‹¤ìš´íƒ€ì„ì´ ê°€ì§„ë‹¤í•œë“¤ ë‹¤ë¥¸ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„œë²„ì—ì„œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ ë° ì§‘ê³„ë¥¼ ìˆ˜í–‰í•  ìˆ˜ ìˆê¸°ë•Œë¬¸ì´ë‹¤. ë¬¼ë¡  ì¤‘ë³µ ì¤‘ë³µëœ ë©”íŠ¸ë¦­ì— ëŒ€í•´ì„  íƒ€ë…¸ìŠ¤ ë‚´ Use Deduplication ê¸°ëŠ¥ì„ í†µí•´ ì†Œê±°ê°€ ê°€ëŠ¥í•˜ë‹¤. ì¤‘ë³µ ë©”íŠ¸ë¦­ ì„¤ì •ì€ í”„ë¡œë©”í…Œìš°ìŠ¤ ë¼ë²¨ ì„¤ì •ì„ í†µí•´ ê°€ëŠ¥í•˜ë‚˜ ìë™ìœ¼ë¡œ ì„¤ì •ì´ ë˜ì–´ ìƒëµí•˜ê² ë‹¤.\n4. ê·¸ë¼íŒŒë‚˜ ì„¤ì • ê·¸ë¼íŒŒë‚˜ëŠ” ì‹œê°í™” ëŒ€ì‹œë³´ë“œì´ë‹¤. ì•ì„œ êµ¬ì¶•í•œ ëª¨ë‹ˆí„°ë§ ì‹œìŠ¤í…œì„ ê¸°ë°˜ìœ¼ë¡œ ë©”íŠ¸ë¦­ ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸ì„ êµ¬ì„±í•˜ê³  ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ê² ë‹¤. ê·¸ë¼íŒŒë‚˜ ë„ë©”ì¸ì— ì ‘ì†í•˜ì—¬ ë¡œê·¸ì¸ì„ ì§„í–‰í•œë‹¤. (ì´ˆê¸° ì•„ì´ë””: admin, ë¹„ë°€ë²ˆí˜¸: admin1234)\në¨¼ì €, ìˆ˜ì§‘ ë©”íŠ¸ë¦­ URLì„ í”„ë¡œë©”í…Œìš°ìŠ¤ì—ì„œ íƒ€ë…¸ìŠ¤ ì¿¼ë¦¬ë¡œ ìˆ˜ì •í•  ê²ƒì´ë‹¤. ì™¼ìª½ í•˜ë‹¨ì˜ í†±ë‹ˆë°”í€´ ë©”ë‰´ì—ì„œ Configurationì— ë“¤ì–´ê°„ ë‹¤ìŒ í”„ë¡œë©”í…Œìš°ìŠ¤ ì„¤ì • URLì„ thanos-query:9090 ìœ¼ë¡œ ìˆ˜ì •í•˜ì.\në°”ê¾¸ê³  ë‚˜ì„œ ëŒ€ì‹œë³´ë“œë¥¼ í™•ì¸í•˜ë©´ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\në§ˆì¹˜ë©° kube-prometheus-stack ìì²´ì ìœ¼ë¡œë„ í”„ë¡œë©”í…Œìš°ìŠ¤ ê³ ê°€ìš©ì„±ì„ ë³´ì¥í•œë‹¤. í•˜ì§€ë§Œ ì´ë ‡ê²Œ êµ¬ì„±í•œ í”„ë¡œë©”í…Œìš°ìŠ¤ HAëŠ” ì—¬ì „íˆ ì¤‘ë³µ ë°ì´í„°ì™€ ì¿¼ë¦¬ ì§‘ê³„, í™•ì¥ì„±ì— ëŒ€í•œ ë³´ì™„ ìš”ì†Œê°€ ìˆë‹¤. ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ Thanosì„ ì†Œê°œí•˜ì˜€ê³  ì—°ë™ ë°©ë²•ê³¼ êµ¬ì„± ìš”ì†Œë¥¼ í™•ì¸í•˜ì˜€ë‹¤.\nì°¸ê³  https://aws.amazon.com/ko/blogs/opensource/improving-ha-and-long-term-storage-for-prometheus-using-thanos-on-eks-with-s3/\nhttps://velog.io/@seokbin/Kube-Prometheus-Thanos-êµ¬ì„±#4-í”„ë¡œë©”í…Œìš°ìŠ¤-ha-êµ¬ì„±\n","date":"Apr 01","permalink":"https://HanHoRang31.github.io/post/pkos2-4-monitoring/","tags":["KANS","kops","cloud","AWS","kubernetes","monitoring","prometheus","thanos"],"title":"[PKOS] Thanosë¥¼ í†µí•œ ê³ ê°€ìš©ì„± ëª¨ë‹ˆí„°ë§(í”„ë¡œë©”í…Œìš°ìŠ¤) ì‹œìŠ¤í…œ êµ¬ì¶•í•˜ê¸°"},{"categories":null,"contents":" ë¡œê¹… (Loki \u0026amp; Promtail ) 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. Logging? ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹¤í–‰ ì¤‘ ë°œìƒí•˜ëŠ” ì´ë²¤íŠ¸, ì‘ì—…, ì˜¤ë¥˜ ë“±ì˜ ì •ë³´ë¥¼ ê¸°ë¡í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ì´ë‹¤. ë¡œê¹…ì˜ ì£¼ìš” ëª©ì ì€ í”„ë¡œê·¸ë¨ì˜ ì‹¤í–‰ ìƒíƒœë¥¼ ì¶”ì í•˜ê³ , ë¬¸ì œ ë°œìƒ ì‹œ ì›ì¸ì„ ì°¾ê¸°ê³ , ë‚´ë¶€ ê°ì‚¬ë¥¼ ê¸°ë¡í•˜ê¸° ìœ„í•¨ì´ë‹¤. ë¡œê·¸ íŒŒì¼ì€ ì‹œê°„ ìˆœì„œëŒ€ë¡œ ì €ì¥ë˜ë©°, ëŒ€ë¶€ë¶„ì˜ ê²½ìš° í…ìŠ¤íŠ¸ íŒŒì¼ ë˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœë‹¤.\nì»¨í…Œì´ë„ˆí™”ëœ ì• í”Œë¦¬ì¼€ì´ì…˜ì— ê°€ì¥ ì‰½ê³  ê°€ì¥ ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ë¡œê¹… ë°©ë²•ì€ í‘œì¤€ ì¶œë ¥(stdout)ê³¼ í‘œì¤€ ì—ëŸ¬(stderr) ìŠ¤íŠ¸ë¦¼ì— ì‘ì„±í•˜ëŠ” ê²ƒì´ë‹¤. ì´ë¥¼ ì´ìš©í•˜ë©´ ë¡œê¹… ëª…ë ¹ì–´ë¥¼ í†µí•´ ì¡°íšŒê°€ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 4 5 6 # ë¡œê·¸ í™•ì¸ ì˜ˆ kubectl logs metrics-server-5f65d889cd-znqw5 -n kube-system I0328 00:14:31.072509 1 serving.go:342] Generated self-signed cert (/tmp/apiserver.crt, /tmp/apiserver.key) I0328 00:14:31.477085 1 requestheader_controller.go:169] Starting RequestHeaderAuthRequestController .. ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì—ì„œë„ ì»¨í…Œì´ë„ˆ ì—”ì§„ì´ë‚˜ ëŸ°íƒ€ì„ì´ ì œê³µí•˜ëŠ” ê¸°ë³¸ì ì¸ ë¡œê¹… ê¸°ëŠ¥ì´ ìˆìœ¼ë‚˜ ì¶©ë¶„í•˜ì§€ ì•Šë‹¤. ì»¨í…Œì´ë„ˆê°€ í¬ë˜ì‹œë˜ê±°ë‚˜, íŒŒë“œê°€ ì¶•ì¶œë˜ê±°ë‚˜, ë…¸ë“œê°€ ì¢…ë£Œëœ ê²½ìš°ì—ë„ ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ë¡œê·¸ì— ì ‘ê·¼í•  ìˆ˜ ì—†ê¸° ë•Œë¬¸ì´ë‹¤.\në”°ë¼ì„œ, ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ë¡œê·¸ëŠ” ë…¸ë“œ, íŒŒë“œ ë˜ëŠ” ì»¨í…Œì´ë„ˆì™€ëŠ” ë…ë¦½ì ìœ¼ë¡œ ë³„ë„ì˜ ìŠ¤í† ë¦¬ì§€ì™€ ë¼ì´í”„ì‚¬ì´í´ì„ ê°€ì ¸ì•¼ í•œë‹¤. ì´ ê°œë…ì„Â í´ëŸ¬ìŠ¤í„°-ë ˆë²¨-ë¡œê¹… ì´ë¼ í•˜ë©° ì´ë¥¼ ìœ„í•´ ë³„ë„ì˜ ë²¡ì—”ë“œ ì†”ë£¨ì…˜ì´ í•„ìš”í•˜ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì— ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ë¡œê¹… ì†”ë£¨ì…˜ì€ 3ê°€ê°€ì§€ ì˜¤í”ˆì†ŒìŠ¤ í”„ë¡œì íŠ¸ë¥¼ ê²°í•©í•œ PLG ìŠ¤íƒ(Promtail, Loki, Grafana) ë˜ëŠ” ELK(Elasticsearch, Logstash, Kibana)ìˆë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” PLG ìŠ¤íƒì„ ì•Œì•„ë³¼ ê²ƒì´ë©° ë¡œê¹… ì‹œìŠ¤í…œì¸ Loki ì™€ ë¡œê·¸ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ì¸ Promtail ì„ ì„¤ì¹˜í•˜í•˜ì—¬ í´ëŸ¬ìŠ¤í„°-ë ˆë²¨-ë¡œê¹…ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ë‹¤.\nLoki LokiëŠ” Grafana Labsì—ì„œ ê°œë°œí•œ ê²½ëŸ‰ ë¡œê¹… ì‹œìŠ¤í…œìœ¼ë¡œ, ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì—ì„œ ë©”íƒ€ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ê³  ë¹ ë¥´ê²Œ ì²˜ë¦¬í•  ìˆ˜ ìˆë‹¤. ê·¸ë¦¬ê³  Prometheusì™€ í˜¸í™˜ë˜ëŠ” ë ˆì´ë¸” ê¸°ë°˜ ì§ˆì˜ ë° í•„í„°ë§ ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, Grafanaì™€ í†µí•©ì„ í†µí•´ ë¡œê¹… ë°ì´í„°ë¥¼ ëŒ€ì‹œë³´ë“œì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. ë¡œê¹… ìˆ˜ì§‘ ì—ì´ì „íŠ¸ì¸ Promtailì„ ì‚¬ìš©í•˜ì—¬ ë¡œê¹…ì„ ìˆ˜ì§‘í•˜ë©° ì´ë¥¼ í†µí•´ ì¿ ë²„ë„¤í‹°ìŠ¤ ë¦¬ì†ŒìŠ¤(ë…¸ë“œ, íŒŒë“œ ë˜ëŠ” ì»¨í…Œì´ë„ˆ)ì™€ëŠ” ë…ë¦½ì ìœ¼ë¡œ ë³„ë„ì˜ ìŠ¤í† ë¦¬ì§€ì™€ ë¼ì´í”„ì‚¬ì´í´ì„ ê°€ì§„ë‹¤.\nhttps://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/\në©”íƒ€ë°ì´í„° ì¸ë±ì‹±?\nhttps://grafana.com/oss/loki/\në¡œí‚¤ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ì¸ë±ì‹±ì„ í†µí•´ ê²½ëŸ‰í™” ë° ë¹ ë¥¸ ì¿¼ë¦¬ ì„±ëŠ¥ì„ ê°€ì§„ë‹¤. ë©”íƒ€ì¸ë±ì‹± ì›ë¦¬ëŠ” ìœ„ì˜ ê·¸ë¦¼ê³¼ ê°™ì€ë° ë¡œê·¸ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” ê²ƒì´ ì•„ë‹ˆë¼ íƒ€ì„ìŠ¤íƒ¬í”„ì™€ ë¼ë²¨ì„ ë¬¶ì–´ ì¸ë±ìŠ¤(index) ë¡œ ê·¸ ì™¸ ë‚˜ë¨¸ì§€ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬(chunk)ë¡œ ë‚˜ëˆ  ì €ì¥ëœë‹¤.\nì¸ë±ìŠ¤: ë¡œê·¸ ì‹œê°„ê³¼ ë ˆì´ë¸”ì„ ë¬¶ì–´ í•´ì‹±ì„ í†µí•´ ê³ ìœ í•œ ì‹ë³„ìë¥¼ ë§Œë“ ë‹¤. ì´ ì‹ë³„ìë¥¼ í†µí•´ ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì„ ì°¸ì¡°í•˜ê³  ê²€ìƒ‰í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. ì¸ë±ìŠ¤ëŠ” ì¼ë°˜ì ìœ¼ë¡œ NoSQL DBì— ì €ì¥í•˜ëŠ”ë° Key ê°’ì—ëŠ” ì¸ë±ìŠ¤ë¥¼ values ê°’ì—ëŠ” í•´ë‹¹ ì²­í¬ì˜ ë°ì´í„°ë¥¼ ì €ì¥í•œë‹¤. ì²­í¬: ì²­í¬ëŠ” ì‹¤ì œ ë¡œê·¸ ë°ì´í„°ì´ë‹¤. ì²­í¬ëŠ” ë°ì´í„°ë¥¼ ì••ì¶• ë° ì €ì¥í•˜ê¸° ìœ„í•´ ì—¬ëŸ¬ ì••ì¶• ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìœ¼ë©°, ê¸°ë³¸ì ìœ¼ë¡œ ì••ì¶•ì´ ì ìš©ë˜ì–´ ì €ì¥ ê³µê°„ì„ ìµœì í™”í•©ë‹ˆë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ì˜¤ë¸Œì íŠ¸ ìŠ¤í† ë¦¬ì§€ì— ì €ì¥í•œë‹¤. ì•„í‚¤í…ì²˜ https://grafana.com/blog/2018/12/12/loki-prometheus-inspired-open-source-logging-for-cloud-natives/\nê·¸ë¦¼ì—ì„œ í™”ì‚´í‘œ ë¹¨ê°•ì€ ë¡œê·¸ Write, íŒŒë‘ì€ Readë¥¼ ì˜ë¯¸í•œë‹¤. ë˜í•œ, ê° êµ¬ì„± ì»´í¬ë„ŒíŠ¸ë“¤ì€ HAë¥¼ ì§€ì›í•˜ì—¬ ì»´í¬ë„ŒíŠ¸ ë‚´ë¶€ êµ¬ì„± í•˜ë‚˜ì— ì¥ì• ê°€ ë°œìƒí•˜ë”ë¼ë„ ì„œë¹„ìŠ¤ê°€ ì¤‘ë‹¨ë˜ì§€ ì•ŠëŠ”ë‹¤.\nYour Jobs : ë¡œê·¸ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ë¡œ ì‚¬ìš©ì ì •ì˜ì— ë§ê²Œ ë¡œê·¸ë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¡œí‚¤ ì„œë²„(Distributor)ì— ì „ë‹¬í•œë‹¤. ë¡œê·¸ ìˆ˜ì§‘ ì—ì´ì „íŠ¸ë¡œ Promtailë¥¼ ì‚¬ìš©í•˜ë‚˜ fluent, fluentbit ê³¼ í˜¸í™˜ì´ ê°€ëŠ¥í•˜ë‹¤. Distributor(ë””ìŠ¤íŠ¸ë¦¬ë·°í„°): DistributorëŠ” ë¡œê·¸ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³ , í•´ë‹¹ ë°ì´í„°ë¥¼ ì¸ì œìŠ¤í„°(Ingester)ì— ë¶„ì‚°ì‹œí‚¤ëŠ” ì—­í• ì„ í•œë‹¤. ë˜í•œ, ë ˆì´ë¸”ì˜ í•´ì‹œ ê°’ì„ ì‚¬ìš©í•˜ì—¬ ë°ì´í„°ë¥¼ ì ì ˆí•œ ì¸ì œìŠ¤í„°ì— ì „ë‹¬í•˜ë©° ë¡œë“œë°¸ëŸ°ì‹±ì„ í†µí•´ ë¡œê·¸ ë°ì´í„°ë¥¼ ì—¬ëŸ¬ ì¸ì œìŠ¤í„°ì— ê³ ë¥´ê²Œ ë¶„ì‚°ì‹œì¼œì¤€ë‹¤. Ingester(ì¸ì œìŠ¤í„°): IngesterëŠ” Distributorë¡œë¶€í„° ë¡œê·¸ ë°ì´í„°ë¥¼ ë°›ì•„ì„œ, ë¡œê·¸ ìŠ¤íŠ¸ë¦¼ì„ ì²­í¬ë¡œ ë‚˜ëˆ„ê³  ì••ì¶•í•œ í›„ ì €ì¥ì‹œí‚¨ë‹¤. ì¸ì œìŠ¤í„°ëŠ” ë©”ëª¨ë¦¬ ë˜ëŠ” ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ì— ì²­í¬ë¥¼ ì €ì¥í•  ìˆ˜ ìˆìœ¼ë©°, ì¿¼ë¦¬ì–´(Querier)ì—ê²Œ ì €ì¥ëœ ì²­í¬ì— ëŒ€í•œ ì§ˆì˜ ê²°ê³¼ë¥¼ ì œê³µí•œë‹¤. ì²­í¬ê°€ ì¼ì • ì‹œê°„ ë˜ëŠ” í¬ê¸°ì— ë„ë‹¬í•˜ë©´ ì¸ì œìŠ¤í„°ëŠ” ì´ë¥¼ ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ì— ì €ì¥ì‹œí‚¨ë‹¤. Querier(ì¿¼ë¦¬ì–´): QuerierëŠ” ì‚¬ìš©ìë¡œë¶€í„° ì§ˆì˜ë¥¼ ë°›ì•„ ì²˜ë¦¬í•œë‹¤. ì§ˆì˜ë¥¼ ì²˜ë¦¬í•  ë•Œ, ì¿¼ë¦¬ì–´ëŠ” ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ë ¨ëœ ì²­í¬ë¥¼ ì°¾ê³ , ì¸ì œìŠ¤í„° ë° ì˜êµ¬ ìŠ¤í† ë¦¬ì§€ì—ì„œ í•´ë‹¹ ì²­í¬ë¥¼ ê°€ì ¸ì™€ ì§ˆì˜ ê²°ê³¼ë¥¼ ë°˜í™˜í•œë‹¤. loki ë²„ì „ 3.0 ì´ìƒë¶€í„°ëŠ” loki, loki-distributedê°€ í†µí•©ë˜ì—ˆë‹¤.\nhttps://grafana.com/docs/loki/latest/getting-started/\nLoki Write component : ë¡œê·¸ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ê³  ì €ì¥ì‹œì¼œì£¼ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì•ì„œ ì•„í‚¤í…ì²˜ì˜ ë¹¨ê°„ flowë¥¼ ë‹´ë‹¹í•˜ëŠ” Distributorì™€ Ingester ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. Loki Read component: ë¡œê·¸ ë°ì´í„°ë¥¼ ì¡°íšŒí•˜ê³  ì²˜ë¦¬í•˜ëŠ”ë° ì‚¬ìš©ëœë‹¤. ì•ì„œ ì•„í‚¤í…ì²˜ì˜ íŒŒë‘ flowë¥¼ ë‹´ë‹¹í•˜ëŠ” Querierì™€ Query Frontend ë¡œ êµ¬ì„±ë˜ì–´ ìˆë‹¤. gateway : Loki êµ¬ì„±ìš”ì†Œì— ëŒ€í•œ í”„ë¡ì‹œ ì„œë²„ì´ë‹¤. ë¡œê·¸ë¥¼ ê¹Œë³´ë©´ NGINX ê²Œì´íŠ¸ì›¨ì´ê°€ ì„¤ì¹˜ë˜ë©° ë¡œë“œë°¸ëŸ°ì‹± ê¸°ëŠ¥ì„ ìˆ˜í–‰í•˜ì—¬ ê° ì»´í¬ë„ŒíŠ¸ì— íŠ¸ë˜í”½ì„ ë¶„ì‚°ì‹œí‚¨ë‹¤. ì„¤ì¹˜ ì„¤ì¹˜ í™˜ê²½ : kops í´ëŸ¬ìŠ¤í„° (k8s 1.24), AWS Ubuntu ì¸ìŠ¤í„´ìŠ¤\nì„¤ì¹˜ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ì§„í–‰í•  ì˜ˆì •ì´ë‹¤.\nLoki (helm grafana/loki 4.8.0) Promtail (helm grafana/promtail 6.9.2) ì‚¬ì¡±ì´ì§€ë§Œ, ë¡œê·¸ ì €ì¥ì†Œë¡œ mongoDBë¥¼ í™œìš©í•˜ë ¤ í–ˆìœ¼ë‚˜ ì•ˆ ëœë‹¤! ë¡œí‚¤ í˜¸í™˜ ì €ì¥ì†Œê°€ ì •í•´ì ¸ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì˜¨í”„ë¡œë¯¸ìŠ¤ì—ì„œ êµ¬ì„±ì‹œ ì°¸ê³ í•˜ì.\në³¸ ë¸”ë¡œê·¸ì—ì„œëŠ” S3ì— ì˜¤ë¸Œì íŠ¸ ë°ì´í„°ë¥¼ DynamoDBì— ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ ì €ì¥ì‹œí‚¤ê² ë‹¤. (230402. DynamoDB ì¸ë±ìŠ¤ ì—°ë™ë¬¸ì œë¡œ S3ì— ì¸ë±ìŠ¤, ì˜¤ë¸Œì íŠ¸ ë°ì´í„° ì €ì¥)\nhttps://grafana.com/docs/loki/latest/operations/storage/\nLoki ì„¤ì¹˜ Loki ì €ì¥ì†Œë¡œ S3 ì™€ DyanmoDB ìŠ¤í† ë¦¬ì§€ ìƒì„±ê³¼ IAM role ê¶Œí•œ ì—°ê²°ì´ í•„ìš”í•˜ë‹¤. ë³¸ í…ŒìŠ¤íŠ¸ì—ì„œëŠ” S3 ì´ë¦„ì„ han-loki , DyanmoDB ì´ë¦„ì€ loki_ ë¡œ ìƒì„±í•˜ì˜€ë‹¤. DynamoDB ì‚¬ìš©ì‹œ ì£¼ì˜í•´ì•¼í•  ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nDynamoDB í…Œì´ë¸” ì´ë¦„ì„ í—¬ë¦„ ì°¨íŠ¸ì˜ schema_config.config DynamoDB íŒŒí‹°ì…˜ í‚¤ \u0026amp; ì •ë ¬ í‚¤ë¥¼ (ë¬¸ìì—´, ë°”ì´ë„ˆë¦¬)ë¡œ ì§€ì •í•´ì•¼ í•œë‹¤. IAM ê¶Œí•œì€ S3, DyanmoDBì— ëŒ€í•œ ì •ì±…ì„ ë¶€ì—¬í–ˆë‹¤.\nAmazonS3FullAccess AmazonDynamoDBFullAccess í•„ìëŠ” ì‚¬ìš©ìì— IAM ê¶Œí•œë¥¼ ë¶€ì—¬ í›„ access-key ì™€ secret-keyë¥¼ ê°€ì ¸ì™”ë‹¤. í•´ë‹¹ í‚¤ëŠ” ë°‘ì˜ í—¬ë¦„ ì°¨íŠ¸ ë²„í‚· ì—°ë™ì—ì„œ ì‚¬ìš©ëœë‹¤. ìš°ì„  í—¬ë¦„ì„ í†µí•´ ë¡œí‚¤ ì°¨íŠ¸ë¥¼ ê°€ì ¸ì˜¤ê² ë‹¤.\n1 2 3 4 kubectl create ns loki helm repo add grafana https://grafana.github.io/helm-charts helm repo update helm fetch grafana/loki --untar --version 4.8.0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 #values-loki.yaml schema_config: configs: - from: 2020-05-15 store: aws object_store: s3 schema: v11 index: prefix: loki period: 0 storage_config: aws: s3: s3://ap-northeast-2/han-loki dynamodb: dynamodb_url: dynamodb://ap-northeast-2 table_manager: retention_deletes_enabled: true retention_period: 336h index_tables_provisioning: write_scale: enabled: false read_scale: enabled: false chunk_tables_provisioning: write_scale: enabled: false read_scale: enabled: false table_prefix: \u0026#34;loki\u0026#34; tableManager: enabled: true monitoring: lokiCanary: enabled: true selfMonitoring: enabled: false loki: auth_enabled: false storage: bucketNames: chunks: han-loki ruler: han-loki admin: han-loki type: s3 s3: s3: han-loki endpoint: s3.ap-northeast-2.amazonaws.com region: ap-northeast-2 secretAccessKey: {SECRET KEY} accessKeyId: {ACCESS KEY} s3ForcePathStyle: false insecure: false http_config: {} access_key ì™€ Secret_access_key ë…¸ì¶œì— ì£¼ì˜í•˜ì! schema_config : ì¸ë±ìŠ¤ì™€ ì²­í¬ ë°ì´í„°ì— ëŒ€í•œ ì €ì¥ ìŠ¤í‚¤ë§ˆë¥¼ ì •ì˜í•œë‹¤. storage_config: ë°ì´í„° ì €ì¥í•  ìŠ¤í† ë¦¬ì§€ ì •ë³´ë¥¼ ì…ë ¥í•œë‹¤. table_manager, tableManager : í…Œì´ë¸” ê¸°ë°˜ ë°ì´í„° ì €ì¥ì†Œì— ì¸ë±ìŠ¤ ë° ì²­í¬ë¥¼ ì§€ì›í•˜ëŠ”ë° ë²„ì „ í˜¸í™˜ ë¬¸ì œë¡œ ì‘ë™ì´ ì•ˆë˜ì–´ dynamodb ì— ì¸ë±ìŠ¤ê°€ ì €ì¥ì´ ì•ˆëœë‹¤. (í˜„ì¬ S3ì— ì €ì¥ë¨) monitoring.lokicanary: ì‹œìŠ¤í…œ ê²€ì¦ì— ì‚¬ìš©ëœë‹¤. true ì„¤ì •ì‹œ ë³„ë„ì˜ ì¹´ë‚˜ë¦¬ íŒŒë“œê°€ ìƒì„±ë˜ì–´ ì¼ì •ì‹œê°„ë§ˆë‹¤ í…ŒìŠ¤íŠ¸ ë¡œê·¸ë¥¼ ì „ë‹¬í•œë‹¤. monitoring.selfMonitoring : ëŒ€ì‹œë³´ë“œì— Loki ê´€ë ¨ ëŒ€ì‹œë³´ë“œê°€ ì—…ë¡œë“œëœë‹¤í•˜ì§€ë§Œ, loki: ë¡œí‚¤ ì„œë²„ ì„¤ì •ì„ ì •ì˜í•œë‹¤. ìµœì‹  ë²„ì „ì—ëŠ” ìŠ¤í† ë¦¬ì§€ ì—°ë™ì„ ì—¬ê¸°ì„œ í•˜ëŠ”ë° dynamodbì— ëŒ€í•œ ì„¤ì • ì˜ˆì‹œê°€ ì—†ê³  í…ŒìŠ¤íŠ¸ê°€ ì•ˆë˜ì„œ s3 ë§Œ ì •ì˜í•˜ì˜€ë‹¤. 1 helm install loki grafana/loki -f values-loki.yaml -n loki --version 4.8.0 íŒŒë“œ ë°°í¬ëŠ” ì™„ë£Œë˜ì—ˆìœ¼ë‚˜, ë¡œí‚¤ ìŠ¤í† ë¦¬ì§€ ì—°ë™ìœ¼ë¡œ ì•ˆì •í™” ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.\nì•ˆì •í™” ì‘ì—…ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤.\nstorage_config ìŠ¤í† ë¦¬ì§€ ì—°ë™ ë¬¸ì œ\n1 2 level=error ts=2023-04-01T03:18:30.427197283Z caller=flush.go:144 org_id=self-monitoring msg=\u0026#34;failed to flush\u0026#34; err=\u0026#34;failed to flush chunks: store put chunk: NoCredentialProviders: no valid providers in chain. Deprecated.\\n\\tFor verbose messaging see aws.Config.CredentialsChainVerboseErrors, num_chunks: 1, labels: {app_kubernetes_io_component=\\\u0026#34;read\\\u0026#34;, app_kubernetes_io_instance=\\\u0026#34;loki\\\u0026#34;, app_kubernetes_io_name=\\\u0026#34;loki\\\u0026#34;, app_kubernetes_io_part_of=\\\u0026#34;memberlist\\\u0026#34;, cluster=\\\u0026#34;loki\\\u0026#34;, container=\\\u0026#34;loki\\\u0026#34;, controller_revision_hash=\\\u0026#34;loki-read-7749df4969\\\u0026#34;, filename=\\\u0026#34;/var/log/pods/loki_loki-read-2_a8fab5a2-e78b-4cff-9f8d-ba0ee5952a3c/loki/0.log\\\u0026#34;, job=\\\u0026#34;loki/loki-read\\\u0026#34;, namespace=\\\u0026#34;loki\\\u0026#34;, pod=\\\u0026#34;loki-read-2\\\u0026#34;, statefulset_kubernetes_io_pod_name=\\\u0026#34;loki-read-2\\\u0026#34;, stream=\\\u0026#34;stderr\\\u0026#34;}\u0026#34; level=info ts=2023-04-01T03:18:30.427244754Z caller=flush.go:168 msg=\u0026#34;flushing stream\u0026#34; user=self-monitoring fp=33d14d11bfd98f55 immediate=false num_chunks=1 labels=\u0026#34;{app_kubernetes_io_component=\\\u0026#34;read\\\u0026#34;, app_kubernetes_io_instance=\\\u0026#34;loki\\\u0026#34;, app_kubernetes_io_name=\\\u0026#34;loki\\\u0026#34;, app_kubernetes_io_part_of=\\\u0026#34;memberlist\\\u0026#34;, cluster=\\\u0026#34;loki\\\u0026#34;, container=\\\u0026#34;loki\\\u0026#34;, controller_revision_hash=\\\u0026#34;loki-read-7749df4969\\\u0026#34;, filename=\\\u0026#34;/var/log/pods/loki_loki-read-2_a8fab5a2-e78b-4cff-9f8d-ba0ee5952a3c/loki/0.log\\\u0026#34;, job=\\\u0026#34;loki/loki-read\\\u0026#34;, namespace=\\\u0026#34;loki\\\u0026#34;, pod=\\\u0026#34;loki-read-2\\\u0026#34;, statefulset_kubernetes_io_pod_name=\\\u0026#34;loki-read-2\\\u0026#34;, stream=\\\u0026#34;stderr\\\u0026#34;}\u0026#34; ê³µì‹ë¬¸ì„œ ì˜ˆì œ storage_config ê°€ ìµœì‹  ê¸°ì¤€ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœ ê²ƒ ê°™ì§€ ì•Šë‹¤. í•„ìì˜ ê²½ìš° ë°°í¬ yamlë¡œ êµ¬ì„±ì„ ì„¤ì •í•˜ë‹ˆ ì •ìƒì ìœ¼ë¡œ ì‘ë™í–ˆë‹¤.\nS3 ë””ë ‰í† ë¦¬ì— chunk í´ë”ê°€ ì—†ë‹¤? ì´ìŠˆ ì— ë”°ë¥´ë©´ ë©€í‹°í…Œë„ŒíŠ¸ êµ¬ì„±ì—ì„œ lokië¥¼ ì‹¤í–‰í• ë•Œ ì¸ì¦ì´ ë¹„í™œì„±í™”í•˜ë©´ ê¸°ë³¸ì ìœ¼ë¡œ fake í´ë”ì— ì €ì¥ëœë‹¤ê³  í•œë‹¤. fakeí´ë” ì•ˆì—ëŠ” ì •ìƒì ìœ¼ë¡œ chunkê°€ ë“¤ì–´ê°€ìˆëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìœ¼ë‚˜ ë‹¤ì¤‘ í´ëŸ¬ìŠ¤í„°ì—ì„œ ë°°í¬ì‹œ loki ë³„ë¡œ ì¸ì¦ì´ í•„ìš”í•  ê²ƒ ê°™ë‹¤.\ndynamoDBì— ì¸ë±ìŠ¤ë¥¼ ì €ì¥í•˜ê³  ì‹¶ì–´ìš”.\ní•´ê²°í•´ì•¼í•  ë¬¸ì œë‹¤. í˜„ì¬ S3ì— indexê°’ì´ ë“¤ì–´ê°€ëŠ”ë° dynamodbì— ì˜®ê²¨ì•¼ í•œë‹¤. í—¬ë¦„ì°¨íŠ¸ì— table-manager ì„¤ì •ì´ ë‘ê°œ(table-manager, tableManager)ì—¬ì„œ ì„¤ì •ì´ ì•ˆ ë¨¹íŒë‹¤. ì¶”ê°€ ì›ì¸ìœ¼ë¡œëŠ” ê¹ƒí—ˆë¸Œ ì´ìŠˆ( https://github.com/grafana/loki/issues/5070) ì„¤ì •ê°’( extraArgs)ì¸ë° ì ìš©ì´ ì•ˆëœë‹¤. ì¶”í›„ í•´ê²°ì‹œ ì—…ë°ì´íŠ¸í•˜ê² ë‹¤.\në°°í¬ë¥¼ ì™„ë£Œí•˜ë©´ ë¡œí‚¤ íŒŒë“œê°€ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\nhttp://loki-read-headless.loki.svc.cluster.local:3100\nPromtail ì„¤ì¹˜ 1 2 3 helm repo add grafana https://grafana.github.io/helm-charts helm repo update helm fetch grafana/promtail --untar --version 6.9.2 Promtail ì°¨íŠ¸ì—ì„œ ë”°ë¡œ ì„¤ì •í•  ê²ƒì€ ì—†ì§€ë§Œ, ë¡œí‚¤ ì—°ê²°ê³¼ ë¡œê·¸ ë¼ì¸ íŒŒì´í”„ë¼ì¸ êµ¬ì„± í™•ì¸ì„ ìœ„í•´ ì§‘ì–´ë„£ëŠ”ë‹¤.\nconfig.clients.url : ë¡œê·¸ ìˆ˜ì§‘ í›„ ì „ë‹¬í•œ ë¡œê·¸ ì„œë²„ë¥¼ ì…ë ¥í•œë‹¤. ë³´í†µ ë¡œí‚¤ ì„œë²„ ì„¤ì¹˜ì‹œ ì„¤ì •ë˜ëŠ” urlë¡œ ì§€ì •ëœë‹¤. config.snippets: ë¡œê·¸ ë¼ì¸ ë¶„ì„ê³¼ ì¶”ì¶œ, í•„í„°ë§í•˜ëŠ” ìŠ¤í…Œì´ì§€ë“¤ì˜ ì‘ì—…ì„ ì •ì˜í•œë‹¤. ì›í•˜ëŠ” ë¡œê·¸ ë°ì´í„° í˜•ì‹ì„ ì •ì˜í•´ì„œ ì…ë ¥í•˜ë©´ ëœë‹¤. scraping êµ¬ë¬¸ì€ í”„ë¡œë©”í…Œìš°ìŠ¤ì™€ ë™ì¼í•˜ë‹¤. 1 helm install promtail grafana/promtail -n loki --version 6.9.2 ë¡œê·¸ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ Promtail-Loki-Grafana ê¹Œì§€ì˜ ë¡œê·¸ ìˆ˜ì§‘ì„ í…ŒìŠ¤íŠ¸í•˜ê² ë‹¤. í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ nginx ë¥¼ ë°°í¬í•˜ê³  íŒŒë“œ ë¡œê·¸ í™•ì¸ê³¼ ê·¸ë¼íŒŒë‚˜(ë¡œí‚¤)ì—ì„œ ë¡œê·¸ë¥¼ í™•ì¸í•œë‹¤.\n1 2 helm repo add bitnami https://charts.bitnami.com/bitnami helm install nginx bitnami/nginx --version 13.2.23 -f nginx-values.yaml íŒŒë“œ ë¡œê·¸ëŠ” íŒŒë“œê°€ ì˜¬ë¼ê°„ ë…¸ë“œ /var/log/pods ì— ì €ì¥ë˜ì–´ ìˆë‹¤. íŒŒë“œì˜ ë¡œê·¸ë¥¼ í™•ì¸í•˜ê³  ê·¸ë¼íŒŒë‚˜ ëŒ€ì‹œë³´ë“œì—ì„œ ë¡œí‚¤ê°€ í•´ë‹¹ ë¡œê·¸ë¥¼ ê¸ì–´ì˜¤ëŠ”ì§€ í™•ì¸í•˜ì.\n[Explorer] â†’ Job = default/nginx ì„¤ì • í›„ ë¡œê·¸ í™•ì¸ ì˜ ë“¤ì–´ì˜¨ë‹¤! ì´ì–´ì„œ íŒŒë“œ ë¼ì´í”„ì‚¬ì´í´ê³¼ ë…ë¦½ì ìœ¼ë¡œ ë¡œê·¸ê°€ ê´€ë¦¬ë˜ëŠ” ì§€ í™•ì¸í•˜ê² ë‹¤. nginx íŒŒë“œë¥¼ ì‚­ì œí•˜ê³  íŒŒë“œ ë¡œê·¸ì™€ ë¡œí‚¤ë¥¼ í™•ì¸í•˜ê² ë‹¤.\n1 helm uninstall nginx ì•„ë˜ ë””ë ‰í† ë¦¬ë¥¼ í™•ì¸í•˜ë©´ nginx íŒŒë“œê°€ ì‚­ì œë˜ì–´ ë¡œê·¸ ë””ë ‰í† ë¦¬ê°€ ì‚­ì œëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\níŒŒë“œê°€ ì‚­ì œë˜ì—ˆì§€ë§Œ ê·¸ë¼íŒŒë‚˜(ë¡œí‚¤) ì—ì„œ nginx ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\në§ˆì¹˜ë©° ê·¸ë¼íŒŒë‚˜ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ë‹ˆ ì—”í„°í”„ë¼ì´ì¦ˆì— ëŒ€í•œ ì§€ì›ë§Œ í™œë°œí•œ ëŠë‚Œì´ë‹¤. ì˜¤í”ˆì†ŒìŠ¤ë¡œ ì„¤ì¹˜ì‹œ ì—°ë™ ë¶€ë¶„ê³¼ ìµœì‹  ë²„ì „ í˜¸í™˜ ë¬¸ì œë¡œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ë°ë„ ì˜¤ëœ ì‹œê°„ì´ ê±¸ë ¸ë‹¤. íŠ¹íˆ ì¸ë±ìŠ¤ ë°ì´í„°ë¥¼ dynamodb ì— ì—°ë™í•´ì•¼ í–ˆì§€ë§Œ ì„¤ì • ë¬¸ì œë¡œ ì‹¤íŒ¨í–ˆê³  S3ì— ì¸ë±ìŠ¤, ì²­í¬ ë°ì´í„°ë¥¼ ì €ì¥ì‹œì¼°ë‹¤. ì´ ë¶€ë¶„ì€ ê³µì‹ ë¬¸ì„œë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸ë¥¼ í•˜ê±°ë‚˜ ì˜ˆê°€ ë‚˜ì˜¤ë©´ ì—…ë°ì´íŠ¸í•˜ê² ë‹¤.\n","date":"Apr 01","permalink":"https://HanHoRang31.github.io/post/pkos2-4-logging/","tags":["KANS","kops","cloud","AWS","kubernetes","monitoring","PLG","loki","grafana","promtail"],"title":"[PKOS] ë¡œê¹… PLG ìŠ¤íƒ, ìµœì‹  ë²„ì „(Loki v2.8.0) ë°°í¬í•˜ê¸°"},{"categories":null,"contents":" 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. 3ì£¼ì°¨ ì‹œê°„ì—ëŠ” Gitlab ê³¼ ArgoCDë¥¼ ë°°í¬í•˜ì—¬ Gitops ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ì˜€ë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” GitOPS ì‹œìŠ¤í…œì— ëŒ€í•œ ì‹¤ìŠµ ë‚´ìš©ë“¤ì„ ì •ë¦¬í•˜ê³  ê³µìœ í•˜ê³ ì í•œë‹¤.\nGitOpsëŠ” GItì„ ì§„ì‹¤ì˜ ì›ì²œ(SSOT, Single Source of Truth) ìœ¼ë¡œ ì‚¬ìš©í•˜ëŠ” ì¸í”„ë¼ì™€ ì• í”Œë¦¬ì¼€ì´ì…˜ ë°°í¬ ê´€ë¦¬ ë°©ì‹ì´ë‹¤. ì§„ì‹¤ì˜ ì›ì²œì´ë¼ëŠ” ë§ì€ Gitì—ì„œë§Œ ì†ŒìŠ¤ë¥¼ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ í•˜ì—¬ ë‹¨ì¼ ì§„ì‹¤ ì›ì²œì„ êµ¬í˜„í•œë‹¤ëŠ” ë§ì´ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œëŠ” GItOpsë¥¼ ArgoCDë¥¼ ì´ìš©í•˜ì—¬ ê¹ƒ ì €ì¥ì†Œì— ìˆëŠ” ì†ŒìŠ¤ë¥¼ ì •ì˜ëœ í´ëŸ¬ìŠ¤í„° í™˜ê²½ì— ìë™ìœ¼ë¡œ ë°˜ì˜ì‹œì¼œ ì¤€ë‹¤.\nGitOps ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ë©´ ì–»ì„ ìˆ˜ ìˆëŠ” ì´ì ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\në²„ì „ ê´€ë¦¬: Gitì„ ì‚¬ìš©í•˜ë¯€ë¡œ ì¸í”„ë¼ ë° ì• í”Œë¦¬ì¼€ì´ì…˜ì˜ ëª¨ë“  ë³€ê²½ ì‚¬í•­ì´ ì¶”ì ë˜ê³  ë²„ì „ì´ ê´€ë¦¬ëœë‹¤. ì´ë¥¼ í†µí•´ ë¬¸ì œ ë°œìƒ ì‹œ ì´ì „ ìƒíƒœë¡œ ì‰½ê²Œ ë˜ëŒë¦´ ìˆ˜ ìˆë‹¤. ë””ì»¤í”Œë§: ì½”ë“œì™€ ì¸í”„ë¼ë¥¼ ë¶„ë¦¬í•¨ìœ¼ë¡œì¨ ê°œë°œìì™€ ìš´ì˜íŒ€ ê°„ì˜ í˜‘ì—…ì´ ì‰¬ì›Œì§„ë‹¤. ìë™í™”: ë³€ê²½ ì‚¬í•­ì´ ìë™ìœ¼ë¡œ ì ìš©ë˜ë¯€ë¡œ ìˆ˜ë™ ì¸í”„ë¼ ê´€ë¦¬ ì‘ì—…ì´ ì¤„ì–´ë“¤ê³ , ì‹¤ìˆ˜ë¥¼ ë°©ì§€í•  ìˆ˜ ìˆë‹¤. ë³´ì•ˆ: Git ì €ì¥ì†Œì— ì ‘ê·¼ ê¶Œí•œì„ ì œì–´í•¨ìœ¼ë¡œì¨ ì¸í”„ë¼ ë³€ê²½ì— ëŒ€í•œ ë³´ì•ˆì„ ê°•í™”í•  ìˆ˜ ìˆë‹¤. ì‹ ì†í•œ í”¼ë“œë°± ë£¨í”„: ë¬¸ì œê°€ ë°œìƒí•˜ë©´ ì†ŒìŠ¤ ì½”ë“œì— ëŒ€í•œ ë³€ê²½ì„ í†µí•´ ë¹ ë¥´ê²Œ í•´ê²°í•˜ê³  ì ìš©í•  ìˆ˜ ìˆë‹¤. ì´ì ë§Œ ì¡´ì¬í•˜ëŠ” ê²ƒì€ ì•„ë‹ˆë‹¤, ë‹¨ì ë„ ì¡´ì¬í•œë‹¤.\ní•™ìŠµ ê³¡ì„ : GitOps ë° ê´€ë ¨ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ë ¤ë©´ Git, ì„ ì–¸ì  ì¸í”„ë¼ ë„êµ¬ ë° ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜ í”Œë«í¼ì— ëŒ€í•œ ì§€ì‹ì´ í•„ìš”í•˜ë‹¤. ë³µì¡ì„±: GitOpsë¥¼ ì‚¬ìš©í•˜ë©´ ì´ˆê¸° ì„¤ì •ê³¼ ê´€ë¦¬ê°€ ë³µì¡í•  ìˆ˜ ìˆë‹¤. ì ì ˆí•œ ë„êµ¬ì™€ í”„ë¡œì„¸ìŠ¤ë¥¼ êµ¬ì¶•í•˜ê³  ìœ ì§€ ê´€ë¦¬í•˜ëŠ” ë° ì‹œê°„ê³¼ ë…¸ë ¥ì´ í•„ìš”í•  ìˆ˜ ìˆë‹¤. ë†’ì€ ì˜ì¡´ì„±: GitOpsëŠ” Git ì €ì¥ì†Œì— ëŒ€í•œ ë†’ì€ ì˜ì¡´ì„±ì„ ê°€ì§€ë©°, ì €ì¥ì†Œ ì ‘ê·¼ì´ ë¶ˆê°€ëŠ¥í•œ ê²½ìš° ì¸í”„ë¼ ë³€ê²½ì´ ì œí•œë  ìˆ˜ ìˆë‹¤. ê°„ë‹¨í•˜ê²Œ ì˜ˆì œ ì‹œë‚˜ë¦¬ì˜¤ë¥¼ êµ¬ì„±í•˜ì—¬ GitOps ì‹œìŠ¤í…œì„ êµ¬ì¶•í•˜ê³ ì í•œë‹¤. ë¨¼ì € ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì— Gitlabê³¼ ArgoCDë¥¼ ë°°í¬í•  ê²ƒì´ê³ , ê´€ë¦¬ ëŒ€ìƒì„ ì§€ë‚œ ì‹œê°„ì— ë°°ìš´ Harbor ë°°í¬ ì°¨íŠ¸ë¡œ ì§€ì •í•  ê²ƒì´ë‹¤.\nGitlab ë°°í¬ Gitlabì€ ì†ŒìŠ¤ ì›ê²© ì €ì¥ì†Œì´ë‹¤. í”íˆ ì“°ëŠ” ê¹ƒí—ˆë¸Œë¡œ ìƒê°í•˜ë©´ ì´í•´ê°€ ë¹ ë¥´ë‹¤. Gitlabì˜ ì°¨ë³„ì ì€ ì‚¬ì„¤(ê³µì‹ë¬¸ì„œì—ëŠ” offlineì´ë¼ ì¹­í•¨) ê¹ƒë©ì„ êµ¬ì¶•í•  ìˆ˜ ìˆë‹¤ëŠ” ì ì¸ë° ì§ì ‘ í—¬ë¦„ ì°¨íŠ¸ë¥¼ êµ¬ì„±í•˜ì—¬ ë°°í¬í•˜ê² ë‹¤.\nê¹ƒë© ì°¨íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ì´ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë‹¤.\n1 2 3 helm repo add gitlab https://charts.gitlab.io/ helm repo update helm fetch gitlab/gitlab --untar --version 6.8.1 ê¹ƒë© ì°¨íŠ¸ì— ë¶€ê°€ ì˜µì…˜ì´ ë§ë‹¤.. ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì. ë‹¤ìŒì€ í•„ìê°€ ì°¨íŠ¸ë¥¼ ë³´ê³  ê°„ëµíˆ ì •ë¦¬í•œ ë‚´ìš©ì´ë‹¤.\nìœ ë£Œ ë²„ì „ ë¬´ë£Œ ì œê³µ : ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ì˜¤í”„ë¼ì¸ ê¹ƒë© ì„¤ì¹˜ì‹œ enterprise edtion (ìœ ë£Œ, ì´í•˜ EEë¼ ì¹­í•¨) ì„ ë¬´ë£Œë¡œ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. ì´ìœ ë¥¼ ì°¾ì•„ë³´ë‹ˆ ê³ ê° ìœ ì¹˜ ì „ëµì´ë¼ í•œë‹¤. EE ì‚¬ìš©ì‹œ ê³ ê¸‰ ë³´ì•ˆ, ì¸ì¦, ê¶Œí•œ ê´€ë¦¬, ì§„í–‰ë¥  ë³´ê³ , ê³ ê¸‰ CI/CD ê¸°ëŠ¥, ë©€í‹° í”„ë¡œì íŠ¸ íŒŒì´í”„ë¼ì¸ ë“±ì˜ ê³ ê¸‰ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ìŠ¤í† ë¦¬ì§€ ê´€ë ¨ ê°€ìš©ì„± ì œê³µ : Gitlab ìì²´ì ìœ¼ë¡œ ë„ì»¤ ë ˆì§€ìŠ¤íŠ¸ë¦¬ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤. ë˜í•œ,ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ë¯¸ì§€ ë° ê¹ƒë© í˜ì´ì§€, ë“±ì˜ ë°ì´í„°ë“±ì— ëŒ€í•œ ì €ì¥ì†Œ ìŠ¤í† ë¦¬ì§€ë¡œ Minio ë¥¼ ì‚¬ìš©í•œë‹¤. ì•ì„  ë¸”ë¡œê·¸ ê¸€ì—ì„œ harbor ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— ëŒ€í•œ ê³ ê°€ìš©ì„± êµ¬ì¶•ì„ ë‹¤ë£¨ì—ˆëŠ”ë°, ê¹ƒë©ì—ì„œëŠ” ìë™ìœ¼ë¡œ ì—°ë™í•´ì£¼ëŠ” ê²ƒ ê°™ë‹¤. ë„¤íŠ¸ì›Œí¬ ìµœì í™” ê¸°ëŠ¥ ì œê³µ : gitlab ì„œë²„(Gitlay)ì— ëŒ€í•œ ë¡œë“œë°¸ëŸ°ì‹±(Prafect) ê¸°ëŠ¥ì„ ì œê³µí•˜ë©°, Workhorseë¼ëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•´ ì¤‘ì•™ í”„ë¡ì‹œ ë° íŒŒì¼ ì²˜ë¦¬ë¥¼ ê´€ë¦¬í•œë‹¤. ë³´ì•ˆ : Oauth, ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬(gitlab shell) ì„ ì œê³µí•œë‹¤. Observability ì œê³µ : ê·¸ë¼íŒŒë‚˜ ì—°ë™ ê¸°ëŠ¥, Tracing ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. CI / CD ì œê³µ : gitlab-runner ë¼ëŠ” ì»´í¬ë„ŒíŠ¸ë¥¼ í†µí•´ CI / CD ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ë­ì§€..? ë‹¨ìˆœíˆ ê¹ƒ ì €ì¥ì†Œë¥¼ í™•ì¥í•˜ì—¬ ëŒ€ë¶€ë¶„ì˜ addonë¥¼ ìë™ìœ¼ë¡œ ì—°ê³„ì‹œì¼œ ì œê³µí•˜ë‹¤ë‹ˆ, ì‹¬ì§€ì–´ ê³ ê°€ìš©ì„±, ìµœì í™”ì— ëŒ€í•œ êµ¬ì„±ë„ ìë™ìœ¼ë¡œ ì œê³µí•´ì¤€ë‹¤. ê¸°ëŠ¥ë³„ë¡œ ì„¸ì„¸íˆ ë³´ê³  ì‹¶ì€ ë§ˆìŒì´ êµ´ëšê°™ì§€ë§Œ, ì´ë²ˆ ë¸”ë¡œê·¸ê¸€ì—ì„œëŠ” gitops ì‹œìŠ¤í…œ ëŒ€í•œ ë‚´ìš©ë§Œ ë‹¤ë£¬ë‹¤. ì°¨íŠ¸ì—ì„œ ë‹¤ìŒê³¼ ê°™ì€ ë¶€ë¶„ì„ ìˆ˜ì •í•˜ì˜€ë‹¤.\nvalues-gitops.yaml\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 global: hosts: domain: {ë„ë©”ì¸ ì…ë ¥} ingress: configureCertmanager: false provider: aws class: alb annotations: alb.ingress.kubernetes.io/scheme: internet-facing alb.ingress.kubernetes.io/target-type: ip alb.ingress.kubernetes.io/listen-ports: \u0026#39;[{\u0026#34;HTTPS\u0026#34;:443}, {\u0026#34;HTTP\u0026#34;:80}]\u0026#39; alb.ingress.kubernetes.io/certificate-arn: {ACM arn ì…ë ¥} alb.ingress.kubernetes.io/success-codes: 200-399 alb.ingress.kubernetes.io/group.name: \u0026#34;gitlab\u0026#34; tls: enabled: false certmanager: install: false nginx-ingress: enabled: false prometheus: install: false gitlab-runner: install: false í—¬ë¦„ ì°¨íŠ¸ì—ì„œëŠ” ì°¨íŠ¸ ì˜¤ë²„ë¼ì´ë“œê°€ ê°€ëŠ¥í•˜ë‹¤. ìœ„ì˜ ì°¨íŠ¸ì—ì„œ ACMê°’ë§Œ ìˆ˜ì •í•´ì„œ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì.\n1 helm install gitlab gitlab/gitlab -f values-gitops.yaml --namespace gitlab --version 6.8.4 ì„¤ì¹˜ í›„ ë„ë©”ì¸ì„ í†µí•´ ë¡œê·¸ì¸ì„ ì§„í–‰í•œë‹¤. ì´ˆê¸° admin ê³„ì •ì˜ ì•„ì´ë””ëŠ” root ì´ë©°, ë¹„ë°€ë²ˆí˜¸ëŠ” ë‹¤ìŒì˜ ëª…ë ¹ì–´ì—ì„œ í™•ì¸í•œë‹¤.\n1 2 # ì›¹ root ê³„ì • ì•”í˜¸ í™•ì¸ kubectl get secrets -n gitlab gitlab-gitlab-initial-root-password --template={{.data.password}} | base64 -d ;echo ì ‘ì†í•˜ë©´ ê¹ƒë© í”„ë¡œì íŠ¸ í™”ë©´ì´ ë³´ì¸ë‹¤. ì´ì–´ì„œ PKOS ìŠ¤í„°ë””ì—ì„œ ì§„í–‰í•œ ì‹¤ìŠµ ë‚´ìš©ì„ í…ŒìŠ¤íŠ¸í•˜ê² ë‹¤. ì‚¬ìš©ì ê³„ì •ì„ ìƒì„±í•˜ì—¬ í† í°ì„ ë°œê¸‰ë°›ê³ , ì‹ ê·œ í”„ë¡œì íŠ¸ë¥¼ íŒŒì¼ì„ ì—…ë¡œë“œí•´ë³´ì.\nArgoCD ë°°í¬ ArgoCDëŠ” Git ë¦¬í¬ì§€í† ë¦¬ì— ì €ì¥ëœ ì¿ ë²„ë„¤í‹°ìŠ¤ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì™€ ì‹¤ì œ í´ëŸ¬ìŠ¤í„° ìƒíƒœë¥¼ ë™ê¸°í™”ì‹œì¼œì£¼ëŠ” ì§€ì†ì ì¸ ë°°í¬(Continuous Delivery, CD) íˆ´ì´ë‹¤. Argo CDë¥¼ ì‚¬ìš©í•˜ë©´ Git ë¦¬í¬ì§€í† ë¦¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸í”„ë¼ êµ¬ì„±ì„ ì½”ë“œë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆê²Œ ëœë‹¤. ì´ëŠ” ë‹¨ì¼ ì§„ì‹¤ ì›ì²œ(SSOT)ë¡œ ìë™í™”, ë³´ì•ˆ, ë²„ì „ ê´€ë¦¬ ì¸¡ë©´ì—ì„œ ìœ ìš©í•˜ë‹¤.\nArgoCD ë°°í¬ëŠ” Helm ì°¨íŠ¸ë¡œ ì§„í–‰í•œë‹¤.\n1 2 3 helm repo add argo https://argoproj.github.io/argo-helm helm repo update helm fetch argo/argo-cd --untar --version 5.19.14 ArgoCD ì°¨íŠ¸ ë¶„ëŸ‰ë„ ìƒë‹¹í•˜ë‹¤. ì•„í‚¤í…ì²˜ë¥¼ ë³´ë‹ˆ ì´í•´ê°€ ë¹ ë¥¸ ê²ƒ ê°™ì•„ì„œ ë¨¼ì € ê³µìœ í•œë‹¤.\nhttps://blog.searce.com/argocd-gitops-continuous-delivery-approach-on-google-kubernetes-engine-2a6b3f6813c0\nargo-cd-server: Argo CD API ì„œë²„ì™€ ì›¹ UIë¥¼ ì œê³µí•˜ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ì‚¬ìš©ì ì¸ì¦ ë° ê¶Œí•œ ê´€ë¦¬ë¥¼ ì²˜ë¦¬í•˜ë©°, í´ëŸ¬ìŠ¤í„°ì™€ Git ë¦¬í¬ì§€í† ë¦¬ ê°„ì˜ ë™ê¸°í™”ë¥¼ ê´€ë¦¬í•œë‹¤. argo-cd-repo-server: Git ë¦¬í¬ì§€í† ë¦¬ì™€ í†µì‹ í•˜ì—¬ ì‚¬ìš©ìê°€ ê´€ë¦¬í•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ íŒŒì¼ì„ ê°€ì ¸ì˜¤ëŠ” ì»´í¬ë„ŒíŠ¸ì´ë‹¤. ë˜í•œ, ë¦¬í¬ì§€í† ë¦¬ ë‚´ì˜ Helm ì°¨íŠ¸ì™€ Kustomize êµ¬ì„±ì„ ì²˜ë¦¬í•œë‹¤. argo-cd-application-controller: Argo CDì˜ í•µì‹¬ ì»´í¬ë„ŒíŠ¸ë¡œ, ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ìƒíƒœì™€ Git ë¦¬í¬ì§€í† ë¦¬ ìƒíƒœë¥¼ ë¹„êµí•˜ê³  ë™ê¸°í™”ë¥¼ ìˆ˜í–‰í•œë‹¤. í´ëŸ¬ìŠ¤í„°ì˜ ì‹¤ì œ ìƒíƒœì™€ ì›í•˜ëŠ” ìƒíƒœë¥¼ ì¼ì¹˜ì‹œí‚¤ëŠ” ì‘ì—…ì„ ë‹´ë‹¹í•œë‹¤. argo-cd-dex-server: ì¸ì¦ í”„ë¡ì‹œ ì—­í• ì„ í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ë¡œ, ë‹¤ì–‘í•œ OAuth ë° OIDC í”„ë¡œë°”ì´ë”ì™€ í†µí•©í•˜ì—¬ Argo CD ì¸ì¦ì„ ì²˜ë¦¬í•œë‹¤. argo-cd-redis: ìºì‹± ë° ì„¸ì…˜ ê´€ë¦¬ë¥¼ ìœ„í•œ Redis ë°ì´í„°ë² ì´ìŠ¤ì´ë‹¤. Argo CDëŠ” Redisë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ í–¥ìƒê³¼ ë¹ ë¥¸ ì‘ë‹µ ì‹œê°„ì„ ì œê³µí•œë‹¤. Kustomize ?\nì¿ ë²„ë„¤í‹°ìŠ¤ ë¦¬ì†ŒìŠ¤ êµ¬ì„±ì„ ì»¤ìŠ¤í„°ë§ˆì´ì§•ì„ ìœ„í•œ ë„êµ¬ì´ë‹¤. ë™ì¼í•œ êµ¬ì„±ì„ ê°€ì§„ ë§¤ë‹ˆíŒ¨ìŠ¤íŠ¸ì— ìˆ˜ì •í•  ë¶€ë¶„ë§Œ ì¶”ê°€í•´ì„œ ì˜¤ë²„ë¼ì´ë“œê°€ ê°€ëŠ¥í•˜ë‹¤.\nì•„ë˜ ì˜ˆëŠ” ì›ë³¸ ë² ì´ìŠ¤ ì•±(my-app) ì— dev, ops í™˜ê²½ë³„ í•„ìš” ê°’ì„ ì˜¤ë²„ë¼ì´ë“œí•˜ëŠ” ì˜ˆì œì´ë‹¤.\në¨¼ì € ë² ì´ìŠ¤ê°€ ë˜ëŠ” deploymentë¥¼ ì„ ì–¸í•˜ê³  Kustomize êµ¬ì„±í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 # base/deployment.yaml apiVersion: apps/v1 kind: Deployment metadata: name: my-app spec: replicas: 1 selector: matchLabels: app: my-app template: metadata: labels: app: my-app spec: containers: - name: my-app image: my-app-image:latest ports: - containerPort: 80 1 2 3 4 5 # base/kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization resources: - deployment.yaml ì´ì œ dev, Ops í™˜ê²½ì— ëŒ€í•œ kustomization.yaml íŒŒì¼ì„ ìƒì„±í•˜ê³  ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ê°€í•˜ì.\nDev í™˜ê²½ ì„¤ì •\n1 2 3 4 5 6 7 # overlays/dev/kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization bases: - ../../base patchesStrategicMerge: - deployment-patch.yaml 1 2 3 4 5 6 7 8 9 10 11 12 # verlays/dev/deployment-patch.yaml apiVersion: apps/v1 kind: Deployment metadata: name: my-app spec: replicas: 2 template: spec: containers: - name: my-app image: my-app-image:dev Ops í™˜ê²½ ì„¤ì •\n1 2 3 4 5 6 7 # overlays/ops/kustomization.yaml apiVersion: kustomize.config.k8s.io/v1beta1 kind: Kustomization bases: - ../../base patchesStrategicMerge: - deployment-patch.yaml 1 2 3 4 5 6 7 8 9 10 11 12 # overlays/ops/kustomization.yaml apiVersion: apps/v1 kind: Deployment metadata: name: my-app spec: replicas: 4 template: spec: containers: - name: my-app image: my-app-image:ops ëˆˆì¹˜ ì±˜ëŠ”ê°€? Opsì™€ devì˜ replicas ê°œìˆ˜ì™€ ì´ë¯¸ì§€ ì„¤ì •ë§Œ ë‹¬ëê³  ê·¸ ë¶€ë¶„ë§Œ ì¶”ê°€í–ˆë‹¤. ë°°í¬ëŠ” ë‹¤ìŒ ì‹ìœ¼ë¡œ ì§„í–‰í•œë‹¤.\n1 kubectl kustomize overlays/dev | kubectl apply -f - ìœ„ì˜ ì»´í¬ë„ŒíŠ¸ë³„ ì°¨íŠ¸ì—ì„œ ì„¤ì •ì´ ê°€ëŠ¥í•˜ë‹¤. ì¶”ê°€ ì„¤ì •ì€ ì•„ë˜ config.param ì—ì„œ ì˜¤ë²„ë¼ì´ë“œí•˜ëŠ” ê²ƒì„ ì¶”ì²œí•œë‹¤. ì‚¬ìš© ì˜ˆëŠ” ê¹ƒí—ˆë¸Œì— ìˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 # Argo CD configuration parameters ## Ref: https://github.com/argoproj/argo-cd/blob/master/docs/operator-manual/argocd-cmd-params-cm.yaml params: ## Controller Properties # -- Number of application status processors controller.status.processors: 20 # -- Number of application operation processors controller.operation.processors: 10 # -- Specifies timeout between application self heal attempts controller.self.heal.timeout.seconds: 5 # -- Repo server RPC call timeout seconds. controller.repo.server.timeout.seconds: 60 ê¹ƒí—ˆë¸Œì˜ ì‚¬ìš© ì˜ˆì—ëŠ” ì¤‘ìš”í•œ reSyncPreiod ì„¤ì •(ì €ì¥ì†Œ ë™ê¸°í™” ì‹œê°„) ì´ ì—†ëŠ” ê²ƒ ê°™ë‹¤. ì´ëŸ´ ë•ŒëŠ” ì§ì ‘ ì°¨íŠ¸ë¥¼ í™•ì¸í•˜ì—¬ êµ¬ì„± ê°’ì„ í™•ì¸í•˜ê³  config.paramsì— ì¶”ê°€í•˜ì.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 # argo-cd/templates/argocd-application-controller - command: - argocd-application-controller - --metrics-port={{ .Values.controller.containerPorts.metrics }} {{- if .Values.controller.metrics.applicationLabels.enabled }} {{- range .Values.controller.metrics.applicationLabels.labels }} - --metrics-application-labels - {{ . }} {{- end }} {{- end }} {{- with .Values.controller.args.statusProcessors }} - --status-processors - {{ . | quote }} {{- end }} {{- with .Values.controller.args.operationProcessors }} - --operation-processors - {{ . | quote }} {{- end }} {{- with .Values.controller.args.appResyncPeriod }} # config.params ì¶”ê°€ - --app-resync - {{ . | quote }} {{- end }} {{- with .Values.controller.args.appHardResyncPeriod }} - --app-hard-resync - {{ . | quote }} {{- end }} {{- with .Values.controller.args.selfHealTimeout }} - --self-heal-timeout-seconds - {{ . | quote }} {{- end }} ì‹¤ì œ ë°°í¬ëŠ” CLBì— externalDNS ë¡œ ì§„í–‰í•˜ì˜€ë‹¤.\n1 2 3 4 5 6 # values-argocd.yaml server: service: type: LoadBalancer annotations: external-dns.alpha.kubernetes.io/hostname: argocd.\u0026lt;ë„ë©”ì¸ ì…ë ¥\u0026gt; ë°°í¬\n1 2 kubectl create ns argocd helm install argocd argo/argo-cd -f values-argocd.yaml --namespace argocd --version 5.19.14 ì‹¤ì œë¡œ ë°°í¬í•  ì‹œ ê³ ë ¤í•  ì ì€ ì ‘ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì´ë‹¤. ArgoCDëŠ” í´ëŸ¬ìŠ¤í„°ë¥¼ ì§ì ‘ì ìœ¼ë¡œ ê´€ë¦¬í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì‹¤ì œ Devops íŒ€ì´ë‚˜ Admin ì‚¬ìš©ìê°€ ì‚¬ìš©í•  ê²ƒì´ë¼ ì˜ˆìƒí•œë‹¤. ì´ë¥¼ ìœ„í•´ í—ˆìš©ëœ ë„¤íŠ¸ì›Œí¬ ëŒ€ì—­ì—ì„œë§Œ ë¡œë“œë°¸ëŸ°ì„œ ì ‘ê·¼ì´ ê°€ëŠ¥í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ê²ƒì´ ì¤‘ìš”í•  ê²ƒ ê°™ë‹¤. ë¡œë“œë°¸ëŸ°ìŠ¤ ì„¤ì • í›„ ì ì ˆí•œ ë³´ì•ˆ ê·¸ë£¹ì„ ìƒì„±í•˜ì—¬ ì ‘ê·¼ì„ ì œì–´í•˜ë„ë¡ í•˜ì.\nì´ˆê¸° admin ë¡œê·¸ì¸ ì •ë³´ëŠ” ë‹¤ìŒì˜ ëª…ë ¹ì–´ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 #ë¹„ë°€ë²ˆí˜¸ ARGOPW=$(kubectl -n argocd get secret argocd-initial-admin-secret -o jsonpath=\u0026#34;{.data.password}\u0026#34; | base64 -d) echo $ARGOPW ë¡œê·¸ì¸ ì´í›„ ArgoCDì— í´ëŸ¬ìŠ¤í„°ì™€ ê¹ƒ ì €ì¥ì†Œ ë“±ë¡ì´ í•„ìš”í•˜ë‹¤. ArgoCD UI ë‚˜ CLI ë¥¼ í†µí•´ í™•ì¸ ë° ë“±ë¡ì´ ê°€ëŠ¥í•˜ë‹¤. í´ëŸ¬ìŠ¤í„°ëŠ” êµ¬ì¶•í•œ í´ëŸ¬ìŠ¤í„° ì •ë³´ê°€ ê¸°ë³¸ìœ¼ë¡œ ë“±ë¡ë˜ì–´ ìˆë‹¤. í–¥í›„ ìƒì‚°ì„±ì„ ìœ„í•´ CLIë¥¼ í†µí•´ í™•ì¸í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 # ìµœì‹ ë²„ì „ ì„¤ì¹˜ curl -sSL -o argocd-linux-amd64 https://github.com/argoproj/argo-cd/releases/latest/download/argocd-linux-amd64 install -m 555 argocd-linux-amd64 /usr/local/bin/argocd chmod +x /usr/local/bin/argocd # ë²„ì „ í™•ì¸ argocd version --short # argocd ì„œë²„ ë¡œê·¸ì¸ argocd login argocd.$KOPS_CLUSTER_NAME --username admin --password $ARGOPW WARNING: server certificate had error: x509: certificate is valid for localhost, argocd-server, argocd-server.argocd, argocd-server.argocd.svc, argocd-server.argocd.svc.cluster.local, not argocd.hanhorang.link. Proceed insecurely (y/n)? y \u0026#39;admin:login\u0026#39; logged in successfully Context \u0026#39;argocd.hanhorang.link\u0026#39; updated # argocd repo ë“±ë¡ argocd repo add https://gitlab.hanhorang.link/Horang/test-stg.git --username horang --password PASSWORDa! Repository \u0026#39;https://gitlab.hanhorang.link/Horang/test-stg.git\u0026#39; added # argocd í™•ì¸ argocd repo list TYPE NAME REPO INSECURE OCI LFS CREDS STATUS MESSAGE PROJECT git https://gitlab.hanhorang.link/Horang/test-stg.git false false false true Successful argocd cluster list SERVER NAME VERSION STATUS MESSAGE PROJECT https://kubernetes.default.svc in-cluster Unknown Cluster has no applications and is not being monitored. GitOps êµ¬ì¶• êµ¬ì¶•í•œ Gilab, ArgoCD ë¥¼ í†µí•´ì„œ GitOps ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ê² ë‹¤. gitops ì •ì˜ëŒ€ë¡œ ê¹ƒ ì €ì¥ì†Œì— ìˆëŠ” í—¬ë¦„ ì°¨íŠ¸ê°€ ì¿ ë²„ë„¤í‹°ìŠ¤ í™˜ê²½ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ë™ê¸°í™”ë˜ëŠ” ì§€ í…ŒìŠ¤íŠ¸í•´ë³´ê² ë‹¤. ì‚¬ìš© í—¬ë¦„ ì°¨íŠ¸ëŠ” ì•ì„œ ìŠ¤í† ë¦¬ì§€ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ êµ¬ì¶•í•œ minIO ë¥¼ ëŒ€ìƒìœ¼ë¡œ ì§„í–‰í•˜ê² ë‹¤. í•´ë‹¹ ì°¨íŠ¸ëŠ” í•„ìì˜ ê¹ƒí—ˆë¸Œì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 helm repo add minio https://charts.bitnami.com/bitnami helm repo update helm fetch minio/minio --untar --version 12.2.1 ë¨¼ì €, gitlab ì €ì¥ì†Œì— í—¬ë¦„ ì°¨íŠ¸ë¥¼ PUSHí•œë‹¤.\në‹¤ìŒì€ ArgoCDë¥¼ í†µí•´ ë™ê¸°í™”ë¥¼ ì§„í–‰í•œë‹¤. ë™ê¸°í™” êµ¬ì„±ì€ ArgoCD CRDë¡œ ì‘ì„±í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 apiVersion: argoproj.io/v1alpha1 kind: Application metadata: name: minio-helm namespace: argocd finalizers: - resources-finalizer.argocd.argoproj.io spec: destination: namespace: minio server: https://kubernetes.default.svc project: default source: repoURL: https://gitlab.hanhorang.link/Horang/test-stg path: minio/ targetRevision: HEAD helm: valueFiles: - values-minio.yaml syncPolicy: syncOptions: - CreateNamespace=true spec.destination : ë™ê¸°í™” í´ëŸ¬ìŠ¤í„° ëŒ€ìƒì„ ë‚˜íƒ€ë‚¸ë‹¤ spec.source : ê¹ƒí—ˆë¸Œ ì €ì¥ì†Œë¥¼ ì…ë ¥í•œë‹¤. spec. syncpolicy : ë™ê¸°í™” ì •ì±…ì„ êµ¬ì„±í•œë‹¤. ì˜µì…˜ì€ ê³µì‹ ë¬¸ì„œë¥¼ ì°¸ê³ ë°”ë€ë‹¤. CreateNamespace=true ì˜µì…˜ì€ ëŒ€ìƒ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì—†ìœ¼ë©´ ìƒì„±ì‹œí‚¨ë‹¤ëŠ” ì˜µì…˜ì´ë‹¤. ë°°í¬ í›„ ArgoCD UIì—ì„œ í™•ì¸í•˜ì.\n1 kubectl apply -f minio-helm-argo.yaml ë°°í¬ì‹œ OutofSync ì˜ ìƒíƒœê°€ ë˜ëŠ”ë° ìƒë‹¨ì˜ Sync AppëˆŒëŸ¬ ë™ê¸°í™”ë¥¼ ì§„í–‰í•œë‹¤.\në™ê¸°í™”ì‹œ ì˜µì…˜ì— ë”°ë¼ ì„¸ë¶€ ë™ì‘ì´ ê°€ëŠ¥í•˜ë‹¤.\nPRUNE: ë¦¬í¬ì§€í† ë¦¬ì— ì—†ëŠ” ë¦¬ì†ŒìŠ¤ë¥¼ ì‚­ì œí•¨ DRY RUN : í…ŒìŠ¤íŠ¸ë¡œ ì‹¤ì œ ë³€ê²½í•˜ì§€ ì•ŠìŒ APPLY ONLY: ë¦¬ì†ŒìŠ¤ ìƒì„± ë° ìˆ˜ì •ë§Œ ìˆ˜í–‰í•˜ê³  ì‚­ì œí•˜ì§€ ì•ŠìŒ FORCE : ê°•ì œ ì ìš©\nSKIP SCHEMA VALIDATION: ë¦¬ì†ŒìŠ¤ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì˜ JSON ìŠ¤í‚¤ë§ˆ ê²€ì¦ì„ ê±´ë„ˆë›°ëŠ” ì˜µì…˜ì´ë‹¤. ì´ ì˜µì…˜ì€ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì— í¬í•¨ëœ ìŠ¤í‚¤ë§ˆê°€ ìœ íš¨í•˜ì§€ ì•Šê±°ë‚˜ ê²€ì¦ë˜ì§€ ì•Šì•„ë„ ë°°í¬ë¥¼ ì§„í–‰í•˜ê³ ì í•  ë•Œ ì‚¬ìš©í•œë‹¤. AUTO-CREATE NAMESPACE: ArgoCDê°€ ë¦¬ì†ŒìŠ¤ë¥¼ ë°°í¬í•  ë„¤ì„ìŠ¤í˜ì´ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ê²½ìš° ìë™ìœ¼ë¡œ í•´ë‹¹ ë„¤ì„ìŠ¤í˜ì´ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” ì˜µì…˜ì´ë‹¤. PRUNE LAST: í´ëŸ¬ìŠ¤í„°ì— ì¡´ì¬í•˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” ë¦¬ì†ŒìŠ¤ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í•˜ì—¬ ê¹”ë”í•œ ìƒíƒœë¥¼ ìœ ì§€í•  ìˆ˜ ìˆë„ë¡ ë•ëŠ”ë‹¤. APPLY OUT OF SYNC ONLY: ArgoCDê°€ ì˜¤ì§ ë™ê¸°í™”ë˜ì§€ ì•Šì€ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•´ì„œë§Œ kubectl apply ëª…ë ¹ì„ ì‹¤í–‰í•˜ëŠ” ì˜µì…˜ì´ë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì´ë¯¸ ë™ê¸°í™”ëœ ë¦¬ì†ŒìŠ¤ëŠ” ê±´ë“œë¦¬ì§€ ì•Šê³ , ë³€ê²½ëœ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•´ì„œë§Œ ì—…ë°ì´íŠ¸ë¥¼ ì§„í–‰í•œë‹¤.\nRESPECT IGNORE DIFFERENCES: ArgoCDê°€ ë¦¬ì†ŒìŠ¤ë¥¼ ë¹„êµí•  ë•Œ, ë¬´ì‹œí•´ì•¼ í•˜ëŠ” ì°¨ì´ì ì„ ì¡´ì¤‘í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ì˜µì…˜ì´ë‹¤. ì´ë ‡ê²Œ í•˜ë©´ ì‚¬ìš©ìê°€ ì§€ì •í•œ íŠ¹ì • í•„ë“œì˜ ë³€ê²½ ì‚¬í•­ì„ ë¬´ì‹œí•˜ê³  ë™ê¸°í™” ì—¬ë¶€ë¥¼ ê²°ì •í•  ìˆ˜ ìˆë‹¤.\nSERVER-SIDE APPLY: ArgoCDê°€ ì„œë²„ ì¸¡ì—ì„œ ë¦¬ì†ŒìŠ¤ë¥¼ ì ìš©í•˜ë„ë¡ ì„¤ì •í•˜ëŠ” ì˜µì…˜ì´ë‹¤. ì´ ì˜µì…˜ì„ ì‚¬ìš©í•˜ë©´, ë¦¬ì†ŒìŠ¤ì˜ ë³€ê²½ ì‚¬í•­ì´ ì„œë²„ ì¸¡ì—ì„œ ìë™ìœ¼ë¡œ ë³‘í•©ë˜ì–´ ê´€ë¦¬ìê°€ ìˆ˜ë™ìœ¼ë¡œ ë³‘í•©í•  í•„ìš”ê°€ ì—†ë‹¤. ì´ ë°©ì‹ì€ í´ë¼ì´ì–¸íŠ¸ ì¸¡ì—ì„œ **kubectl apply**ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒë³´ë‹¤ ë” íš¨ìœ¨ì ì¸ ë¦¬ì†ŒìŠ¤ ê´€ë¦¬ë¥¼ ê°€ëŠ¥í•˜ê²Œ í•œë‹¤.\nREPLACE : ë¦¬ì†ŒìŠ¤ ë³€ê²½ì‹œ ê¸°ì¡´ ë¦¬ì†ŒìŠ¤ë¥¼ ì‚­ì œí•˜ê³  ìƒˆë¡œìš´ ë¦¬ì†ŒìŠ¤ë¥¼ ìƒì„±í•˜ì—¬ ëŒ€ì²´í•œë‹¤.\nRETRY : ë™ê¸°í™” ì‹¤íŒ¨ì‹œ ì¬ì‹œë„\nSync í›„ ë°°í¬ê¹Œì§€ ëª¨ë‹ˆí„°ë§ í›„ ì •ìƒì ìœ¼ë¡œ ì‘ë™í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nArgoCDëŠ” ê¸°ë³¸ì ìœ¼ë¡œ ìˆ˜ë™ì ìœ¼ë¡œ Sync ì‘ì—…ì´ í•„ìš”í•˜ë‹¤. ìë™ìœ¼ë¡œ ê¹ƒ ì €ì¥ì†Œì— ë‚´ìš©ìœ¼ë¡œë§Œ ë™ê¸°í™”ì‹œí‚¤ë ¤ë©´ self-healing ì˜µì…˜ì´ í•„ìš”í•˜ë‹¤. App Detailì˜ Policy ì„¤ì •ì—ì„œ í™œì„±í™”í•˜ì.\në§ˆì¹˜ë©° ì´ë²ˆ ê¸€ì—ì„œëŠ” Gitlab ì™€ ArgoCD ì°¨íŠ¸ë¥¼ ë¶„ì„í•˜ì—¬ êµ¬ì„±í•˜ì˜€ê³  GitOps ì‹œìŠ¤í…œì„ êµ¬ì¶•í•´ë³´ì•˜ë‹¤. ì¸í”„ë¼ ê´€ë¦¬ì ì¸¡ë©´ì—ì„œ SSOTë¥¼ êµ¬ì„±í•˜ë©´ ì½”ë“œ êµ¬ì„± ê´€ë¦¬ ì¸¡ë©´ì—ì„œ í¸ë¦¬í•´ì§ˆ ê²ƒì´ ëŠê»´ì§„ë‹¤. ê·¸ë¦¬ê³  Gitlabì™€ ArgoCD ë©”ë‰´ì–¼ì´ ì˜ ì •ë¦¬ë˜ì–´ ìˆë‹¤. í™•ì¥ ê¸°ëŠ¥(ë©”íŠ¸ë¦­, ì•ŒëŒ, ë³´ì•ˆ) í•„ìš”ì‹œ ë©”ë‰´ì–¼ì„ ì°¸ê³ í•˜ì!\n","date":"Mar 25","permalink":"https://HanHoRang31.github.io/post/pkos2-3-gitops/","tags":["KANS","kops","cloud","AWS","kubernetes","GitOps","Gitlab","ArgoCD","CI/CD"],"title":"[PKOS] GitOpsì™€ ArgoCD DeepDive"},{"categories":null,"contents":" 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. 2ì£¼ì°¨ ìŠ¤í„°ë””ì—ì„œëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ë„¤íŠ¸ì›Œí¬ì™€ ìŠ¤í† ë¦¬ì§€ë¥¼ ì¤‘ì ì ìœ¼ë¡œ ê³µë¶€í•˜ì˜€ë‹¤. ë¶„ëŸ‰ì´ ë§ì•„ ë„¤íŠ¸ì›Œí¬ì™€ ìŠ¤í† ë¦¬ì§€ë¥¼ ë‚˜ëˆ ì„œ ë¸”ë¡œê·¸ë¥¼ ì‘ì„±í•  ì˜ˆì •ì´ë‹¤. ì´ë²ˆ ë¸”ë¡œê·¸ ê¸€ì—ì„œëŠ” ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì— ëŒ€í•´ ê³µìœ í•˜ê² ë‹¤. ì¼ë°˜ì ìœ¼ë¡œ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ëŠ” IOPS ì„±ëŠ¥ì´ íŠ¹í™”ë˜ì–´ ìˆì§€ë§Œ ë…¸ë“œì— ì¢…ì†ë˜ì–´ ìˆì–´ ê³ ê°€ìš©ì„±ì´ë‚˜ ìŠ¤í† ë¦¬ì§€ ê¸°ëŠ¥ì— ì œí•œì´ ìˆë‹¤. ì´ëŸ¬í•œ ì œí•œì„ ì—†ì• ê¸° ìœ„í•œ ê³¼ì •ìœ¼ë¡œ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì˜ Hostpath, local ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•  ê²ƒì´ê³ , ë§ˆì§€ë§‰ìœ¼ë¡œëŠ” ë¡œì»¬ ë³¼ë¥¨ì—ì„œ ê³ ê°€ìš©ì„±ê³¼ ìŠ¤í† ë¦¬ì§€ ê¸°ëŠ¥(ë°±ì—…)ì„ ê°€ì§„ Mysql ë°ì´í„°ë² ì´ìŠ¤ë¥¼ êµ¬ì„±í•˜ê² ë‹¤. ì¶”ê°€ë¡œ ìŠ¤í† ë¦¬ì§€ ì„±ëŠ¥ ì¸¡ì •ê³¼ ëª¨ë‹ˆí„°ë§ ê³¼ì •, QnAë¥¼ ì¤€ë¹„í•˜ì˜€ë‹¤. ë³¸ë¡ ìœ¼ë¡œ ë“¤ì–´ê°€ì„œ, ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ì´ìœ ëŠ” ë¬´ì—‡ì¼ê¹Œ? ìŠ¤í† ë¦¬ì§€ê°€ ë°ì´í„°ë¥¼ ì €ì¥í•˜ëŠ” ìš©ë„ì¸ ê²ƒì²˜ëŸ¼ ë°ì´í„° ì €ì¥ì„ ìœ„í•´ì„œì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, ë°ì´í„°ë² ì´ìŠ¤ê°™ì€ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ íŒŒë“œë¡œ ìš´ì˜í•œë‹¤ê³  ê°€ì •í•´ë³´ì, íŒŒë“œ ë¼ì´í”„ì‚¬ì´í´ê³¼ ë³„ê°œë¡œ ë°ì´í„°ê°€ ë³´ì¡´ë˜ì–´ì•¼ í•œë‹¤. ì´ë¥¼ ìœ„í•´ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œëŠ” PV(Persistent Volume)ê³¼ PVC(Persistent Volume Claim) ë¦¬ì†ŒìŠ¤ë¥¼ ì œê³µí•œë‹¤. ë˜í•œ, ë°ì´í„° ê´€ë¦¬ ë°©ë²•(ë°ì´í„° ì €ì¥ ìœ„ì¹˜, ë°ì´í„° ê³µìœ , í™•ì¥ì„±)ì— ë”°ë¼ ì—¬ëŸ¬ ìŠ¤í† ë¦¬ì§€ ë³¼ë¥¨ê³¼ ê¸°ëŠ¥ì„ ì œê³µí•œë‹¤. ì´ì²˜ëŸ¼ ë°ì´í„°ë¥¼ ë³´ì¡´í•´ì•¼ í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìƒíƒœìˆëŠ”(Stateful) ì• í”Œë¦¬ì¼€ì´ì…˜ì´ë¼ ì¹­í•˜ë©° ìŠ¤í† ë¦¬ì§€ë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„° ë‚´ì˜ ì»¨í…Œì´ë„ˆì— ì•ˆì •ì ì´ê³  ì§€ì†ì ì¸ ë°ì´í„°ë¥¼ ì œê³µí•  ìˆ˜ ìˆë‹¤.\në¡œì»¬ ìŠ¤í† ë¦¬ì§€ ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ëŠ” ë§ ê·¸ëŒ€ë¡œ íŒŒë“œì˜ ìŠ¤í† ë¦¬ì§€ë¡œ ì„œë²„ ë‚´ë¶€ ë³¼ë¥¨ì˜ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ë‹¤. AWS EC2ëŠ” ë‚´ë¶€ ë³¼ë¥¨ì¸ ì¸ìŠ¤í† ì–´ ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•œë‹¤. ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ êµ¬í˜„ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œ HostPath, Local ë³¼ë¥¨ ë§ˆìš´íŠ¸ë¡œ ë‚˜ë‰˜ì–´ ì‚¬ìš©ì´ ê°€ëŠ¥í•˜ë‹¤. HostPath ë³¼ë¥¨ê³¼ Local ë³¼ë¥¨ì˜ ì°¨ì´ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ë³¼ë¥¨ ë¦¬ì†ŒìŠ¤(PV) ì‚¬ìš© ìœ ë¬´ì— ë”°ë¼ êµ¬ë¶„í•œë‹¤.\nì¼ë°˜ì ìœ¼ë¡œ ë‚´ë¶€ ë³¼ë¥¨ì˜ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ë§Œí¼, ë‹¤ë¥¸ ì›ê²© ìŠ¤í† ë¦¬ì§€ì™€ ë¹„êµí–ˆì„ë•Œ IOPS ì„±ëŠ¥ì´ ë›°ì–´ë‚˜ë‹¤. cncf ê³µì‹ì‚¬ì´íŠ¸ì—ì„œ IOPS ê¸°ì¤€ ì•½ 2~3ë°°ì˜ ì°¨ì´ê°€ ë‚œë‹¤ê³  í•˜ë‹ˆ ì„±ëŠ¥ í•„ìš”ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ì—ì„œëŠ” ë„ì…ì„ ê³ ë ¤í•  ë§Œí•˜ë‹¤. ê·¸ë¦¬ê³  ë¡œì»¬ìŠ¤í† ë¦¬ì§€ëŠ” EC2 ì— ì¢…ì†ë˜ì–´ ìˆì–´ ê³ ê°€ìš©ì„± êµ¬ì„±ê³¼ ë°±ì—…ê°™ì€ ê¸°ëŠ¥ ì‚¬ìš©ì— ì¶”ê°€ êµ¬ì„±ì´ í•„ìš”í•˜ë‹¤. í•„ìëŠ” ì´ë¥¼ í•´ê²°í•˜ê¸° ìœ„í•´ ë³¼ë¥¨í”„ë¡œë¹„ì €ë‹ í”ŒëŸ¬ê·¸ì¸ì¸ Local-path-provisioner ì™€ ë°±ì—… ì†”ë£¨ì…˜ì¸ Veleroë¥¼ ì‚¬ìš©í•˜ì˜€ë‹¤.\në¨¼ì € Local-path-provisioner í”ŒëŸ¬ê·¸ì¸ ì„¤ì¹˜ ê³¼ì •ì„ ì‚´í´ë³¼ ê²ƒì´ê³ , ë¡œì»¬ìŠ¤í† ë¦¬ì§€ ì´í•´ë¥¼ ìœ„í•´ 3ê°€ì§€ì˜ ì¼€ì´ìŠ¤ë¡œ ë‚˜ë‰˜ì–´ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•˜ê² ë‹¤.\nLocal-path-provisioner PVë¥¼ í†µí•œ ê³ ê°€ìš©ì„± í…ŒìŠ¤íŠ¸ Hospath PVë¥¼ í†µí•œ ê³ ê°€ìš©ì„± í…ŒìŠ¤íŠ¸ íŒŒë“œê°„ ë°ì´í„° ë™ê¸°í™” êµ¬ì„± local-path-provisioner ë³¼ë¥¨ í”„ë¡œë¹„ì €ë‹ í”ŒëŸ¬ê·¸ì¸ ì¤‘ í•˜ë‚˜ë¡œ, ë¡œì»¬ ë…¸ë“œì˜ íŒŒì¼ ì‹œìŠ¤í…œ ê²½ë¡œë¥¼ ì‚¬ìš©í•˜ì—¬ PVC(Persistent Volume Claim)ë¥¼ ë§Œë“¤ì–´ì£¼ëŠ” ì—­í• ì„ í•œë‹¤. PVCë¥¼ í†µí•´ ë³¼ë¥¨ì„ ìš”ì²­í•˜ë©´ PVê°€ ìë™ìœ¼ë¡œ ìƒì„±ë˜ì–´ ì—°ê²°ëœë‹¤ê³  ë³´ë©´ ëœë‹¤.\nì„¤ì¹˜ì‹œ, ë¡œì»¬ ë…¸ë“œì— ëŒ€í•œ ë³¼ë¥¨ ì„¤ì •ì´ í•„ìš”í•˜ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 curl -s -O https://raw.githubusercontent.com/rancher/local-path-provisioner/v0.0.23/deploy/local-path-storage.yaml vim local-path-storage.yaml ---------------------------- apiVersion: apps/v1 kind: Deployment metadata: name: local-path-provisioner namespace: local-path-storage spec: replicas: 1 selector: matchLabels: app: local-path-provisioner template: metadata: labels: app: local-path-provisioner spec: # ì¶”ê°€ ë¶€ë¶„ nodeSelector: kubernetes.io/hostname: \u0026#34;ë§ˆìŠ¤í„° ë…¸ë“œ ì´ë¦„ ì…ë ¥ \u0026#34; tolerations: - effect: NoSchedule key: node-role.kubernetes.io/control-plane operator: Exists ... kind: ConfigMap apiVersion: v1 metadata: name: local-path-config namespace: local-path-storage data: config.json: |- { \u0026#34;nodePathMap\u0026#34;:[ { \u0026#34;node\u0026#34;:\u0026#34;DEFAULT_PATH_FOR_NON_LISTED_NODES\u0026#34;, \u0026#34;paths\u0026#34;:[\u0026#34;/data/local-path\u0026#34;] # ì¶”ê°€ ë¶€ë¶„ } ] } ---------------------------- Deployment / spec.spec ì—ì„œ nodeselector ì™€ tolerations ë¡œ ë³¼ë¥¨ ë°°ì¹˜ ë…¸ë“œ ì„¤ì •(ë§ˆìŠ¤í„° ë…¸ë“œë¡œ íŒŒë“œ ë°°ì¹˜) Configmap / data config.jsonì—ì„œ ë¡œì»¬ ë³¼ë¥¨ PATH ì„¤ì • ì„¤ì¹˜ í™•ì¸\n1 2 3 4 kubectl get sc local-path ---------------------------- NAME PROVISIONER RECLAIMPOLICY VOLUMEBINDINGMODE ALLOWVOLUMEEXPANSION AGE local-path rancher.io/local-path Delete WaitForFirstConsumer false 29m Case 1. Local-path-provisioner PVë¥¼ í†µí•œ ê³ ê°€ìš©ì„± í…ŒìŠ¤íŠ¸ HostPath ë³¼ë¥¨ì´ IOPS ì„±ëŠ¥ì´ ì¢‹ì€ ê²ƒì„ ì•ì„œ í™•ì¸í•˜ì˜€ë‹¤. ì„±ëŠ¥ì ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ì€ ë³¼ë¥¨ì´ë¼ í•  ìˆ˜ ìˆìœ¼ë‚˜ ê³ ê°€ìš©ì„± êµ¬ì„±ì´ í•„ìš”í•˜ë‹¤.\nHostpath ë³¼ë¥¨ì˜ ë¬¸ì œì ìœ¼ë¡œ ë…¸ë“œê°„ ë§ˆì´ê·¸ë ˆì´ì…˜ì— ììœ ë¡­ì§€ ëª»í•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì´í•´ë¥¼ ìœ„í•´ ì§ì ‘ ì˜ˆì œ íŒŒë“œë¥¼ ë°°í¬í•´ë³´ê³  ê³ ê°€ìš©ì„±ì„ í…ŒìŠ¤íŠ¸ í•´ë³´ê² ë‹¤.\nLocal-path-provisioner PVë¥¼ í†µí•œ ê³ ê°€ìš©ì„± í…ŒìŠ¤íŠ¸\nì•ì„œ ë°°í¬í•œ Local-path-provisioner ë¥¼ í†µí•´ PVë¥¼ ìƒì„±í•˜ì—¬ íŒŒë“œë¥¼ ë°°í¬í•˜ê³  ê³ ê°€ìš©ì„± êµ¬ì„±ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 # íŒŒë“œ ì˜ˆì œ apiVersion: v1 kind: PersistentVolumeClaim metadata: name: localpath-claim spec: accessModes: - ReadWriteOnce resources: requests: storage: 2Gi storageClassName: \u0026#34;local-path\u0026#34; --- apiVersion: apps/v1 kind: Deployment metadata: name: date-pod labels: app: date spec: replicas: 1 selector: matchLabels: app: date template: metadata: labels: app: date spec: terminationGracePeriodSeconds: 3 containers: - name: app image: centos command: [\u0026#34;/bin/sh\u0026#34;] args: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 5; done\u0026#34;] volumeMounts: - name: pod-persistent-volume mountPath: /data volumes: - name: pod-persistent-volume persistentVolumeClaim: claimName: localpath-claim íŒŒë“œ ë°°í¬ í›„ ë…¸ë“œ ë“œë ˆì¸ì„ ì§„í–‰í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # ë°°í¬ íŒŒë“œì˜ ë…¸ë“œ í™•ì¸ PODNODE=$(kubectl get pod -l app=date -o jsonpath={.items[0].spec.nodeName}) echo $PODNODE # ë…¸ë“œ ë“œë ˆì¸ê³¼ íŒŒë“œ ëª¨ë‹ˆí„°ë§ kubectl drain $PODNODE --force --ignore-daemonsets --delete-emptydir-data \u0026amp;\u0026amp; kubectl get pod -w --------------------------------- node/i-0c41dc0f6eeb01730 cordoned Warning: ignoring DaemonSet-managed Pods: kube-system/aws-node-w8bxm, kube-system/ebs-csi-node-thndq, kube-system/node-local-dns-v2hhc evicting pod default/date-pod-d95d6b8f-q9skb evicting pod kube-system/metrics-server-5f65d889cd-9btc7 pod/metrics-server-5f65d889cd-9btc7 evicted pod/date-pod-d95d6b8f-q9skb evicted node/i-0c41dc0f6eeb01730 drained NAME READY STATUS RESTARTS AGE date-pod-d95d6b8f-x5vrb 0/1 Pending 0 2m ë…¸ë“œ ë“œë ˆì¸ì‹œ, ìƒíƒœê°€ Pending ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ëŠ” ë‹¤ë¥¸ ë…¸ë“œì— PVë³¼ë¥¨ì´ ì—†ê¸° ë•Œë¬¸ì´ë‹¤.\në§ˆì°¬ê°€ì§€ë¡œ íŒŒë“œë¥¼ 5ê°œë¡œ ì¶”ê°€í•´ë„ ë³¼ë¥¨ì´ ìˆëŠ” ë…¸ë“œì—ë§Œ íŒŒë“œê°€ ì˜¬ë¼ì˜¨ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 # ì˜ˆì œ íŒŒë“œ ê°œìˆ˜ 5ê°œë¡œ ì¦ê°€ kubectl scale deployment date-pod --replicas=5 Case2. HostPathë¥¼ í†µí•œ ê³ ê°€ìš©ì„± í…ŒìŠ¤íŠ¸ ë³¼ë¥¨ Hostpathë¡œ ë…¸ë“œ PATHë¥¼ ì§ì ‘ ì§€ì •í•˜ì—¬ ê³ ê°€ìš©ì„±ì„ í…ŒìŠ¤íŠ¸í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 apiVersion: apps/v1 kind: Deployment metadata: name: date-pod labels: app: date spec: replicas: 1 selector: matchLabels: app: date template: metadata: labels: app: date spec: terminationGracePeriodSeconds: 3 containers: - name: app image: centos command: [\u0026#34;/bin/sh\u0026#34;] args: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 5; done\u0026#34;] volumeMounts: - name: log mountPath: /data volumes: - name: log hostPath: path: \u0026#34;/data\u0026#34; type: DirectoryOrCreate íŒŒë“œ ë“œë ˆì¸ê³¼ ê°œìˆ˜ ì¡°ì ˆì‹œ ë…¸ë“œì— ìƒê´€ì—†ì´ ë°°í¬ê°€ ì§„í–‰ëœë‹¤.\ní•˜ì§€ë§Œ, ë³¼ë¥¨ë³„ë¡œ ë°ì´í„°ê°€ ìŒ“ì´ëŠ” ê²ƒì´ ë‹¤ë¥´ë‹¤. ê° ë…¸ë“œì— ë“¤ì–´ê°€ì„œ ë¡œê·¸ë¥¼ í™•ì¸í•´ë³´ë©´ ì°íˆëŠ” ê²ƒì´ ë‹¤ë¥¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nê³ ê°€ìš©ì„±ì´ë¼ í•  ìˆ˜ ìˆì§€ë§Œ ì ì¬ë˜ì–´ ìˆëŠ” ë°ì´í„°ê°€ ë‹¬ë¼ stateful ì• í”Œë¦¬ì¼€ì´ì…˜(ex. MySQL)ì„ ìš´ì˜í•˜ê¸°ì—” í•œê³„ê°€ ìˆë‹¤.\nì°¸ê³  ì±…ì—ì„œëŠ” ì´ëŸ¬í•œ ì œì•½ì‚¬í•­ì„ í•´ê²°í•˜ê¸° ìœ„í•´ì„œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ë‹¨ì—ì„œ ë‹¤ë¥¸ ë…¸ë“œì˜ íŒŒë“œì™€ ë°ì´í„°ë¥¼ ë™ê¸°í™”í•´ì„œ í•´ê²°í•  ìˆ˜ ìˆë‹¤ê³  í•œë‹¤.\në™ê¸°í™” ë°©ë²•ì„ ì°¾ì•„ë³´ë‹ˆ NFS ë³¼ë¥¨(ex. AWS EFS)ì„ êµ¬ì„±í•˜ì—¬ HostPath ë¥¼ ì—°ê²°í•˜ê±°ë‚˜, ë³¼ë¥¨ê°„ rsyncë¥¼ ì‚¬ìš©í•˜ë¼ ë‚˜ì˜¤ì§€ë§Œ, ì„±ëŠ¥(ë¡œì»¬SSDê°€ ì•„ë‹˜)ì´ ë–¨ì–´ì ¸ í•´ê²° ë°©ë²•ì€ ì•„ë‹Œ ê²ƒ ê°™ë‹¤.\nCase3. íŒŒë“œê°„ ë°ì´í„° ë™ê¸°í™” êµ¬ì„± ê·¸ë ‡ë‹¤ë©´ ì„±ëŠ¥ ì¢‹ê³ , ê³ ê°€ìš©ì„±ë„ ë³´ì¥ë˜ê³ , ë°ì´í„° ë™ê¸°í™”ë¥¼ ë³´ì¥í•  ìˆ˜ ìˆëŠ” Stateful ì• í”Œë¦¬ì¼€ì´ì…˜ì„ êµ¬ì„±í•  ìˆ˜ ìˆì„ê¹Œ?\nì¿ ë²„ë„¤í‹°ìŠ¤ ê³µì‹ë¬¸ì„œ ì˜ˆì œì—ì„œ ì´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆëŠ”ë° í•´ë‹¹ ì˜ˆì œë¥¼ êµ¬ì„±í•´ë³´ê³  í…ŒìŠ¤íŠ¸í•´ë³´ê² ë‹¤. í•´ë‹¹ ì˜ˆì œì—ì„œëŠ” ë°ì´í„°ë² ì´ìŠ¤ ë¦¬ì†ŒìŠ¤ë¡œ StatefulSetë¥¼ ì‚¬ìš©í•œë‹¤.\nStatefulSet ë¦¬ì†ŒìŠ¤ëŠ” ì´ë¦„ì²˜ëŸ¼ Statefulí•œ ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•´ ë§Œë“  ë¦¬ì†ŒìŠ¤ì´ë‹¤. StatefulSet ë¦¬ì†ŒìŠ¤ì˜ íŠ¹ì§•ì€ ë‹¤ìŒê³¼ ê°™ë‹¤.\nStatefulSet ë¦¬ì†ŒìŠ¤ì˜ íŠ¹ì§•\nPod ì´ë¦„\nStatefulSetì— ì˜í•´ ìƒì„±ëœ íŒŒë“œë“¤ì€ {Pod ì´ë¦„}-{ìˆœë²ˆ} ì‹ìœ¼ë¡œ ì´ë¦„ì´ ì •í•´ì§„ë‹¤. ì´ëŠ” í´ëŸ¬ìŠ¤í„° ë‚´ë¶€ í™˜ê²½ì—ì„œ ë°ì´í„°ë² ì´ìŠ¤ì— ì ‘ê·¼í•  ë•Œ ì‚¬ìš©í•˜ê¸° ìœ„í•´ì„œì´ë‹¤.\níŒŒë“œ ìˆœì°¨ì  ë°°í¬\nPod ìƒì„±ì‹œ ëª¨ë“  Pod ê°€ ë™ì‹œì— ìƒì„±ë˜ì§€ ì•Šê³  ìˆœì„œëŒ€ë¡œ í•˜ë‚˜ì”© ìƒì„±ëœë‹¤. ì´ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë§ˆìŠ¤í„° íŒŒë“œ â†’ ìŠ¬ë ˆì´ë¸Œ íŒŒë“œë¡œ ê¸°ë™í•´ì•¼ í•˜ëŠ” ì¡°ê±´ë“±ì—ì„œ ìœ ìš©í•˜ê²Œ ì‚¬ìš© ë  ìˆ˜ ìˆë‹¤.\níŒŒë“œë³„ ë³¼ë¥¨ ë§ˆìš´íŠ¸\nì¼ë°˜ì ìœ¼ë¡œ PVC \u0026amp; PVì— ì¤‘ë³µì ìœ¼ë¡œ Podë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ë‹¤. ì—°ê²°ëœ Podê°€ ì¡´ì¬í•˜ë©´ ê·¸ ë‹¤ìŒ íŒŒë“œë“¤ì€ PVCë¥¼ ì–»ì§€ ëª»í•´ ë³¼ë¥¨ì„ ì‚¬ìš©í•˜ì§€ ëª»í•œë‹¤. ë°˜ë©´, Statefulsetì—ì„œ PVCë¥¼ í…œí”Œë¦¿ í˜•íƒœë¡œ ì •ì˜í•˜ì—¬ Podë§ˆë‹¤ PVC, PVë¥¼ ìƒì„±í•˜ì—¬ íŒŒë“œë³„ë¡œ ë³¼ë¥¨ì„ ë§ˆìš´íŠ¸í•  ìˆ˜ ìˆê²Œ ëœë‹¤.\në‹¤ì‹œ ëŒì•„ê°€ì„œ ì¿ ë²„ë„¤í‹°ìŠ¤ ê³µì‹ë¬¸ì„œì˜ ì˜ˆì œëŠ” í´ëŸ¬ìŠ¤í„°ì— MySQL ìŠ¤í…Œì´íŠ¸í’€ì…‹ì´ ë°°í¬ë˜ê³  ê° ë ˆí”Œë¦¬ì¹´ì— ìˆœì„œëŒ€ë¡œ ë°°í¬ë˜ëŠ” ì˜ˆì œì´ë‹¤. ì¤‘ìš”í•˜ê²Œ ë³¼ ì ì€ ìŠ¤í…Œì´íŠ¸ í’€ì…‹ì˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ì´ë‹¤.\ní•´ë‹¹ StatefulSet ë§¤ë‹ˆí˜ìŠ¤íŠ¸ëŠ” 3ê°œì˜ replicaë¥¼ ê°€ì§„ MySQLì„ ìƒì„±í•œë‹¤. init ì»¨í…Œì´ë„ˆëŠ” ë‘ê°œ ë°°í¬ë˜ë©°, init-containerëŠ” MySQL init ì„¤ì •ì„ ìˆ˜í–‰í•˜ê³ , xtrabackup init-containerëŠ” MySQL í´ëŸ¬ìŠ¤í„° ë³µì œë¥¼ ìœ„í•´ ë°ì´í„°ë¥¼ í´ë¡ í•˜ì—¬ ë™ê¸°í™”ë¥¼ ì§„í–‰í•œë‹¤. init ì»¨í…Œì´ë„ˆ ì´í›„ MySQL ì»¨í…Œì´ë„ˆëŠ” ë°ì´í„°ë² ì´ìŠ¤ ì‘ì—…ì„ ìˆ˜í–‰í•˜ë©°, xtrabackup ì»¨í…Œì´ë„ˆëŠ” í´ë¡  ì‘ì—…ì„ ì§„í–‰í•œë‹¤.\nê³µì‹ ë¬¸ì„œì˜ ì˜ˆì œë¥¼ ê·¸ëŒ€ë¡œ ë°°í¬í•˜ë©´ ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ê°€ defaultë¡œ EBS ë³¼ë¥¨(ì™¸ë¶€)ì— ì—°ê²°ëœë‹¤. ì´ëŒ€ë¡œ ì§„í–‰í•˜ë©´ local-path-provisionerì—ì„œ ë°°í¬í•œ ë¡œì»¬ ë³¼ë¥¨ì—ì„œ ë§ˆìš´íŠ¸ë˜ì§€ ì•ŠëŠ”ë‹¤.\në¡œì»¬ ë³¼ë¥¨ì— ë§ˆìš´íŠ¸í•˜ê¸° ìœ„í•´ì„œëŠ” ì¶”ê°€ ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.\nlocal-path-provisioner ë°°í¬ íŒŒì¼ ìˆ˜ì •\nlocal-path-provisioner íŒŒë“œë¥¼ ì›Œí¬ ë…¸ë“œì—ë§Œ ë°°í¬í•˜ë„ë¡ ì„¤ì •í•œë‹¤. í•´ë‹¹ ì„¤ì •ì„ í†µí•´ ì›Œí¬ ë…¸ë“œì—ë§Œ ë¡œì»¬ ë³¼ë¥¨ì„ ìƒì„±í•˜ê³  íŒŒë“œì— ì—°ê²°í•  ìˆ˜ ìˆë„ë¡ í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 vim local-path-storage.yaml ---------------------------- apiVersion: apps/v1 kind: Deployment metadata: name: local-path-provisioner namespace: local-path-storage spec: replicas: 1 selector: matchLabels: app: local-path-provisioner template: metadata: labels: app: local-path-provisioner spec: spec: # ì•„ë˜ ë¶€ë¶„ ì¶”ê°€ tolerations: - effect: NoSchedule key: node-role.kubernetes.io/node operator: Exists ìŠ¤í…Œì´íŠ¸ í’€ì…‹ì˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ ë‚´ ìŠ¤í† ë¦¬ì§€í´ë˜ìŠ¤ ì§€ì • 1 2 3 4 5 6 7 8 9 volumeClaimTemplates: - metadata: name: data spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] storageClassName: local-path # ë¡œì»¬ ë³¼ë¥¨ ì¶”ê°€ resources: requests: storage: 10Gi ìŠ¤í…Œì´íŠ¸ í’€ì…‹ì˜ ë§¤ë‹ˆí˜ìŠ¤íŠ¸ replica count ë¥¼ ì›Œí¬ë…¸ë“œ(2) ê°œìˆ˜ ë§Œí¼ ìˆ˜ì • 1 2 3 serviceName: mysql replicas: 2 # ìˆ˜ì • template: ë°°í¬ í™•ì¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 kubectl apply -f ./ ---------------------------- configmap/mysql created service/mysql created service/mysql-read created statefulset.apps/mysql created kubectl get pods ---------------------------- NAME READY STATUS RESTARTS AGE mysql-0 2/2 Running 0 31m mysql-1 2/2 Running 0 31m ë™ê¸°í™” í…ŒìŠ¤íŠ¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 # íŒŒë“œ 0ì—ì„œ Mysql Data ìƒì„± kubectl exec -it pod/mysql-0 -- /bin/bash --------------------------------- Defaulted container \u0026#34;mysql\u0026#34; out of: mysql, xtrabackup, init-mysql (init), clone-mysql (init) --------------------------------- bash-4.2# mysql -u root -p --------------------------------- Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 140 Server version: 5.7.41-log MySQL Community Server (GPL) Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. --------------------------------- mysql\u0026gt; create database testdb; --------------------------------- Query OK, 1 row affected (0.01 sec) --------------------------------- mysql\u0026gt; use testdb; --------------------------------- Database changed --------------------------------- mysql\u0026gt; create table test(name varchar(10), testdata varchar(50)); --------------------------------- Query OK, 0 rows affected (0.02 sec) --------------------------------- mysql\u0026gt; insert into test values(\u0026#39;han\u0026#39;, \u0026#39;mysql example test\u0026#39;); --------------------------------- Query OK, 1 row affected (0.01 sec) --------------------------------- mysql\u0026gt; select * from test; --------------------------------- +------+--------------------+ | name | testdata | +------+--------------------+ | han | mysql example test | +------+--------------------+ 1 row in set (0.00 sec) 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 # íŒŒë“œ 1ì—ì„œ í™•ì¸ kubectl exec -it pod/mysql-1 -- /bin/bash --------------------------------- Defaulted container \u0026#34;mysql\u0026#34; out of: mysql, xtrabackup, init-mysql (init), clone-mysql (init) --------------------------------- bash-4.2# mysql -u root -p --------------------------------- Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 306 Server version: 5.7.41 MySQL Community Server (GPL) Copyright (c) 2000, 2023, Oracle and/or its affiliates. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type \u0026#39;help;\u0026#39; or \u0026#39;\\h\u0026#39; for help. Type \u0026#39;\\c\u0026#39; to clear the current input statement. --------------------------------- mysql\u0026gt; use testdb --------------------------------- Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed --------------------------------- mysql\u0026gt; select * from test; --------------------------------- +------+--------------------+ | name | testdata | +------+--------------------+ | han | mysql example test | +------+--------------------+ 1 row in set (0.00 sec) ëë‹¤! ë¡œì»¬ ë³¼ë¥¨ ê¸°ë°˜ìœ¼ë¡œ Mysql ì˜ˆì œë¥¼ ë°°í¬í•˜ì˜€ê³  ê³ ê°€ìš©ì„± êµ¬ì„±ì„ ìœ„í•´ ë™ê¸°í™”ê¹Œì§€ ì§„í–‰ì„ ì™„ë£Œí–ˆë‹¤!\në¡œì»¬ ë³¼ë¥¨ ë°±ì—…ê³¼ ë³µì› ì¿ ë²„ë„¤í‹°ìŠ¤ì—ì„œëŠ” HostPath ë³¼ë¥¨ì˜ ëŒ€í•œ ë°±ì—…ê³¼ ë³µì› ê¸°ëŠ¥ì€ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤. ë…¸ë“œ ë³„ë¡œ ë°±ì—… ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‘ì„±í•˜ê±°ë‚˜ ì¨ë“œíŒŒí‹° ì†”ë£¨ì…˜ì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ì´ë²ˆ ì ˆì—ì„œëŠ” local-path-provisioner ì„ ì‚¬ìš©í•´ì„œ ë³¼ë¥¨ì„ í”„ë¡œë¹„ì €ë‹í•œë§Œí¼, í•´ë‹¹ ë³¼ë¥¨ì— ë§ê²Œ ë°±ì—…ì„ í•  ìˆ˜ ìˆëŠ” ì¨ë“œíŒŒíŠ¸ ì†”ë£¨ì…˜ì„ ì°¾ì•„ë³´ì•˜ë‹¤.\nlocal-path-provisioner ê¹ƒí—ˆë¸Œ ì´ìŠˆë¥¼ ì°¾ì•„ë³´ë‹ˆ Velero ì†”ë£¨ì…˜ì„ ì´ìš©í•´ì„œ ë°±ì—…ì„ í•  ìˆ˜ ìˆë‹¤ê³  í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ë³´ê³ ì í•œë‹¤.\nVelero? ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì˜ ë¦¬ì†ŒìŠ¤ì™€ í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ì„ ë°±ì—…í•˜ê³  ë³µì›í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ íˆ´ì´ë‹¤.\nVelero ì„ ì‚¬ìš©í•˜ê¸°ì „ local-path-provisioner ë³¼ë¥¨ íƒ€ì…ì„ Localë¡œ ìˆ˜ì •í•´ì•¼ í•œë‹¤. Hostpath ë³¼ë¥¨ì„ ì§€ì›í•˜ì§€ ì•Šìœ¼ë‚˜ Local ë³¼ë¥¨ì€ Restic ê³¼ ì—°ê³„í•˜ì—¬ ë°±ì—…ì„ ì§€ì›í•˜ê¸° ë•Œë¬¸ì´ë‹¤. (ê³µì‹ë¬¸ì„œ)\nì´ëŠ” Local ë³¼ë¥¨ì´ ì¿ ë²„ë„¤í‹°ìŠ¤ì˜ ìì›ìœ¼ë¡œ ê´€ë¦¬ë˜ë©°, ìŠ¤í† ë¦¬ì§€ í´ë˜ìŠ¤ì™€ í¼ì‹œìŠ¤í„´íŠ¸ ë³¼ë¥¨ í´ë ˆì„(PVC)ì„ ì‚¬ìš©í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ìœ¼ë¡œ ë³´ì¸ë‹¤.\nlocal-path-provisioner ì‚¬ì „ ì‘ì—…\nLocal ë³¼ë¥¨ì„ ìˆ˜ì •í•˜ê¸° ìœ„í•´ì„œëŠ” local-path-provisioner íŒŒë“œì˜ ìˆ˜ì • ì‘ì—…ì´ í•„ìš”í•˜ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 volumeClaimTemplates: - metadata: name: data annotations: volumeType: local # ì¶”ê°€ spec: accessModes: [\u0026#34;ReadWriteOnce\u0026#34;] storageClassName: local-path resources: requests: storage: 10Gi ë¡œì»¬ ë³¼ë¥¨ í™•ì¸\n1 2 3 4 5 6 kubectl get pv \u0026lt;pv-name\u0026gt; -o yaml --------------------------------- spec: local: # local or HostPath ë³¼ë¥¨ path: /mnt/local-storage/ssd/vol1 ... Velero ì„¤ì¹˜\ní•„ìëŠ” Velero ë°±ì—… ë²„í‚·ì„ AWS S3 ì„¤ì •í•˜ì—¬ ì„¤ì¹˜ë¥¼ ì§„í–‰í•˜ì˜€ë‹¤.\nì„¤ì¹˜ëŠ” S3 ë²„ì¼“ ìƒì„± ë° ì„¤ì • / Veleo CLI ë¡œ ë‚˜ë‰œë‹¤.\nS3 ë²„ì¼“ ì§€ì • ë° IAM ì„¤ì •\nVelero ì—ì„œ S3 ë²„í‚·ì„ ì ‘ê·¼í•˜ê¸° ìœ„í•œ IAM USER IDì™€ KEY ìƒì„±\n1 aws s3 mb s3://\u0026lt;bucket-name\u0026gt; --region ap-northeast-2 IAM Policy ìƒì„±\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 # ë²„í‚· ë³€ìˆ˜ ì„¤ì • export BUCKET=\u0026lt;bucket-name\u0026gt; # IAM Policy ìƒì„± cat \u0026gt; velero-policy.json \u0026lt;\u0026lt;EOF { \u0026#34;Version\u0026#34;: \u0026#34;2012-10-17\u0026#34;, \u0026#34;Statement\u0026#34;: [ { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;ec2:DescribeVolumes\u0026#34;, \u0026#34;ec2:DescribeSnapshots\u0026#34;, \u0026#34;ec2:CreateTags\u0026#34;, \u0026#34;ec2:CreateVolume\u0026#34;, \u0026#34;ec2:CreateSnapshot\u0026#34;, \u0026#34;ec2:DeleteSnapshot\u0026#34; ], \u0026#34;Resource\u0026#34;: \u0026#34;*\u0026#34; }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:GetObject\u0026#34;, \u0026#34;s3:DeleteObject\u0026#34;, \u0026#34;s3:PutObject\u0026#34;, \u0026#34;s3:AbortMultipartUpload\u0026#34;, \u0026#34;s3:ListMultipartUploadParts\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::${BUCKET}/*\u0026#34; ] }, { \u0026#34;Effect\u0026#34;: \u0026#34;Allow\u0026#34;, \u0026#34;Action\u0026#34;: [ \u0026#34;s3:ListBucket\u0026#34; ], \u0026#34;Resource\u0026#34;: [ \u0026#34;arn:aws:s3:::${BUCKET}\u0026#34; ] } ] } EOF # IAM Policy Attach aws iam put-user-policy \\ --user-name velero \\ --policy-name velero \\ --policy-document file://velero-policy.json # IAM user ì •ë³´ ê°€ì ¸ì˜¤ê¸° aws iam create-access-key --user-name velero --------------------------------- { \u0026#34;AccessKey\u0026#34;: { \u0026#34;UserName\u0026#34;: \u0026#34;velero\u0026#34;, \u0026#34;AccessKeyId\u0026#34;: \u0026#34;{ID}\u0026#34;, # ë°‘ì˜ credentials-velero IDì— ì €ì¥ \u0026#34;Status\u0026#34;: \u0026#34;Active\u0026#34;, \u0026#34;SecretAccessKey\u0026#34;: \u0026#34;{KEY}\u0026#34;, # ë°‘ì˜ credentials-velero KEYì— ì €ì¥ \u0026#34;CreateDate\u0026#34;: \u0026#34;2023-03-16T04:31:23+00:00\u0026#34; } } # credentials-velero ìƒì„± ë° IAM ì •ë³´ ì €ì¥ cat \u0026lt;\u0026lt; EOF \u0026gt; credentials-velero [default] aws_access_key_id=\u0026lt;AWS_ACCESS_KEY_ID\u0026gt; aws_secret_access_key=\u0026lt;AWS_SECRET_ACCESS_KEY\u0026gt; EOF Velero CLI ì„¤ì¹˜ í›„ ì„œë²„ ì„¤ì¹˜\nresticì€ ë²„ì „ velero 1.10(ìµœì‹ ë²„ì „) ì´ìƒì—ì„œ ë” ì´ìƒ ì§€ì›ë˜ì§€ ì•ŠëŠ”ë‹¤. ë²„ì „ì„ 1.9.6ìœ¼ë¡œ ë§ì¶°ì„œ ë‹¤ìš´ë°›ì•„ì•¼ í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 # arch í™•ì¸ uname -m --------------------------------- x86_64 # velero CLI ì„¤ì¹˜ wget https://github.com/vmware-tanzu/velero/releases/download/v1.9.6/velero-v1.9.6-linux-amd64.tar.gz tar xzvf velero-v1.9.6-linux-amd64.tar.gz cp velero-v1.9.6-linux-amd64/velero ~/bin # CLI í™•ì¸ velero --------------------------------- Velero is a tool for managing disaster recovery, specifically for Kubernetes cluster resources. It provides a simple, configurable, and operationally robust way to back up your application state and associated data. If you\u0026#39;re familiar with kubectl, Velero supports a similar model, allowing you to execute commands such as \u0026#39;velero get backup\u0026#39; and \u0026#39;velero create schedule\u0026#39;. The same operations can also be performed as \u0026#39;velero backup get\u0026#39; and \u0026#39;velero schedule create\u0026#39;. ... Velero ì„¤ì¹˜\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 export BUCKET=\u0026lt;bucket-name\u0026gt; export REGION=ap-northeast-2 velero install \\ --provider aws \\ --bucket $BUCKET \\ --secret-file ./credentials-velero \\ --backup-location-config region=$REGION \\ --use-volume-snapshots=false \\ --plugins velero/velero-plugin-for-aws:v1.3.0 \\ --use-restic --------------------------------- ... Deployment/velero: created DaemonSet/restic: attempting to create resource DaemonSet/restic: attempting to create resource client DaemonSet/restic: created Velero is installed! â›µ Use \u0026#39;kubectl logs deployment/velero -n velero\u0026#39; to view the status. # Velero í™•ì¸ kubectl get all -n velero NAME READY STATUS RESTARTS AGE pod/restic-f5ngz 1/1 Running 0 38s pod/restic-x9sk9 1/1 Running 0 37s pod/velero-5f6657d4c8-jttxv 1/1 Running 0 38s NAME DESIRED CURRENT READY UP-TO-DATE AVAILABLE NODE SELECTOR AGE daemonset.apps/restic 2 2 2 2 2 \u0026lt;none\u0026gt; 38s NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/velero 1/1 1 1 38s NAME DESIRED CURRENT READY AGE replicaset.apps/velero-5f6657d4c8 1 1 1 38s Velero ë°±ì—…\nVeleroëŠ” Resticì„ ì‚¬ìš©í•˜ì—¬ PV ë³¼ë¥¨ì— ëŒ€í•´ ë°±ì—…í•˜ëŠ” ë°©ë²•ì— ë‘ ê°€ì§€ ì ‘ê·¼ ë°©ì‹ì„ ì§€ì›í•œë‹¤. (ê³µì‹ë¬¸ì„œ)\nì˜µíŠ¸ì¸ ì ‘ê·¼ ë°©ì‹(default): Resticì„ ì‚¬ìš©í•˜ì—¬ ë°±ì—…í•  ë³¼ë¥¨ì´ í¬í•¨ëœ ëª¨ë“  í¬ë“œì— annotationì„ ë‹¬ì•„ì•¼ í•œë‹¤. ì˜µíŠ¸ì•„ì›ƒ ì ‘ê·¼ ë°©ì‹: ëª¨ë“  í¬ë“œ ë³¼ë¥¨ì´ Resticì„ ì‚¬ìš©í•˜ì—¬ ë°±ì—…ë˜ê³  ë°±ì—…ë˜ì§€ ì•Šì•„ì•¼ í•˜ëŠ” ë³¼ë¥¨ì„ ì˜µíŠ¸ì•„ì›ƒí•  ìˆ˜ ìˆëŠ” ê¸°ëŠ¥ì´ ìˆë‹¤. ì´ë²ˆ ì ˆì—ì„œëŠ” ì˜µíŠ¸ì¸ ì ‘ê·¼ ë°©ì‹ì„ íƒí•  ê²ƒì´ê³  Case3 ì˜ Mysql ë³¼ë¥¨ì„ ë°±ì—…í•  ì˜ˆì •ì´ë‹¤. ë°±ì—…í•  ë³¼ë¥¨ì— ëŒ€í•´ backup.velero.io/backup-volumesannotation ë‹¬ê³  ë°±ì—…ì„ ì§„í–‰í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 # ì£¼ì„ ì¶”ê°€ podì— ë³¼ë¥¨ ì •ë³´ë¥¼ ì¶”ê°€ kubectl annotate pod/mysql-0 backup.velero.io/backup-volumes=data # ë°±ì—… velero backup create mysql --include-namespaces default --wait --------------------------------- Backup request \u0026#34;mysql\u0026#34; submitted successfully. Waiting for backup to complete. You may safely press ctrl-c to stop waiting - your backup will continue in the background. .................. Backup completed with status: Completed. You may check for more information using the commands `velero backup describe mysql` and `velero backup logs mysql`. # ë°±ì—… ëª©ë¡ í™•ì¸ velero get backup --------------------------------- NAME STATUS ERRORS WARNINGS CREATED EXPIRES STORAGE LOCATION SELECTOR mysql Completed 0 0 2023-03-16 14:22:39 +0900 KST 29d default \u0026lt;none\u0026gt; S3 ë²„í‚· ì¡°íšŒí•  ìˆ˜ ìˆë‹¤.\nS3 ì¡°íšŒì‹œ, backups(ì¿ ë²„ë„¤í‹°ìŠ¤ ë¦¬ì†ŒìŠ¤ ì €ì¥ ê²½ë¡œ) ì™€ restic(PV ë³¼ë¥¨ ë°ì´í„° ì €ì¥ ê²½ë¡œ)ì— ë°ì´í„°ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nVelero ë³µì›\nmysql ë°°í¬ íŒŒì¼ê³¼ PVë¥¼ ì§€ìš°ê³  ë³µì›ì„ ì§„í–‰í•˜ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 #mysql ì§€ìš°ê¸° kubectl delete -f ./ kubectl delete pvc/\u0026lt;PVC ë³¼ë¥¨\u0026gt; #velero ë³µì› velero restore create --from-backup mysql --wait --------------------------------- Restore request \u0026#34;mysql-20230316155542\u0026#34; submitted successfully. Waiting for restore to complete. You may safely press ctrl-c to stop waiting - your restore will continue in the background. ........... Restore completed with status: Completed. You may check for more information using the commands `velero restore describe mysql-20230316155542` and `velero restore logs mysql-20230316155542`. # ì¿ ë²„ë„¤í‹°ìŠ¤ ë¦¬ì†ŒìŠ¤ ë³µì› í™•ì¸ kubectl get all --------------------------------- NAME READY STATUS RESTARTS AGE pod/mysql-0 2/2 Running 0 39s pod/mysql-1 0/2 Init:CrashLoopBackOff 2 (18s ago) 39s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/kubernetes ClusterIP 100.64.0.1 \u0026lt;none\u0026gt; 443/TCP 4h39m service/mysql ClusterIP None \u0026lt;none\u0026gt; 3306/TCP 39s service/mysql-read ClusterIP 100.69.52.194 \u0026lt;none\u0026gt; 3306/TCP 39s kubectl get pv --------------------------------- NAME CAPACITY ACCESS MODES RECLAIM POLICY STATUS CLAIM STORAGECLASS REASON AGE pvc-601b919a-cf20-4478-9f28-10d541c66844 10Gi RWO Delete Bound default/data-mysql-0 local-path 71s pvc-b8a766a6-411f-47df-a548-d6b0ee091ea1 10Gi RWO Delete Bound default/data-mysql-1 local-path 70s # Mysql data í™•ì¸ kubectl exec -it pod/mysql-0 -- /bin/bash --------------------------------- Defaulted container \u0026#34;mysql\u0026#34; out of: mysql, xtrabackup, restic-wait (init), init-mysql (init), clone-mysql (init) bash-4.2# mysql -u root -p --------------------------------- Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 73 Server version: 5.7.41-log MySQL Community Server (GPL) mysql\u0026gt; use testdb; --------------------------------- Reading table information for completion of table and column names You can turn off this feature to get a quicker startup with -A Database changed --------------------------------- mysql\u0026gt; select * from test; +------+--------------------+ | name | testdata | +------+--------------------+ | han | mysql example test | +------+--------------------+ 1 row in set (0.01 sec) ë°ì´í„°ê°€ ê·¸ëŒ€ë¡œ ë³´ì¡´ë˜ì–´ ìˆë‹¤!\nVelero ìŠ¤ì¼€ì¥´ ë°±ì—…\ní¬ë¡ íƒ­ì²˜ëŸ¼ ë°±ì—…ë„ Veleroê°€ ê°€ëŠ¥í•˜ë‹¤. ë‹¤ìŒì€ 5ë¶„ë§ˆë‹¤ ë°±ì—…ì„ ì§„í–‰í•˜ëŠ” ì˜ˆì œì´ë‹¤.\në°±ì—…ëœ ì˜¤ë¸Œì íŠ¸ë³„ ë°ì´í„° ë³€í™”ë¥¼ ìœ„í•´ ë°ì´í„°ë² ì´ìŠ¤ì˜ ë°ì´í„°ë¥¼ ìˆ˜ì • í›„ ë³µì›ì„ í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 velero schedule create mysql-crontab --include-namespaces default --schedule=\u0026#34;*/5 * * * *\u0026#34; velero get backup --------------------------------- NAME STATUS ERRORS WARNINGS CREATED EXPIRES STORAGE LOCATION SELECTOR mysql Completed 0 0 2023-03-16 15:51:44 +0900 KST 29d default \u0026lt;none\u0026gt; mysql-crontab-20230316072517 Completed 0 0 2023-03-16 16:25:17 +0900 KST 29d default \u0026lt;none\u0026gt; mysql-crontab-20230316072017 Completed 0 0 2023-03-16 16:20:17 +0900 KST 29d default \u0026lt;none\u0026gt; #DB ì ‘ì† í›„ ë°ì´í„° ì‚­ì œ select * from test; +------+---------------------+ | name | testdata | +------+---------------------+ | han | mysql example test | | han | mysql example test2 | | han | mysql example test3 | +------+---------------------+ 3 rows in set (0.00 sec) mysql\u0026gt; delete from test; Query OK, 3 rows affected (0.00 sec) mysql\u0026gt; select * from test; Empty set (0.00 sec) #velero ë³µì› velero restore create --from-backup mysql-crontab-20230316072017 --wait --------------------------------- Restore request \u0026#34;mysql-crontab-20230316072017-20230316163030\u0026#34; submitted successfully. Waiting for restore to complete. You may safely press ctrl-c to stop waiting - your restore will continue in the background. Restore completed with status: Completed. You may check for more information using the commands `velero restore describe mysql-crontab-20230316072017-20230316163030` and `velero restore logs mysql-crontab-20230316072017-20230316163030`. # Mysql DATA í™•ì¸ mysql\u0026gt; select * from test; Empty set (0.00 sec) Mysql DATA í™•ì¸ ì˜ ê²°ê³¼ê°€ ì˜ˆìƒê³¼ ë‹¤ë¥´ë‹¤. ë°±ì—… ì§„í–‰ ì´í›„ ë°±ì—… ë°ì´í„°ì¸ í–‰3ê°œê°€ ìˆì–´ì•¼ í•˜ë‚˜, ìµœì‹  ë°ì´í„°ê°€ ì¡°íšŒëœë‹¤.\nì´ëŠ” Mysql íŒŒë“œê°€ 2ê°œ ìˆì–´ íŒŒë“œê°„ ë°ì´í„° ë¬´ê²°ì„±ì´ ë³´ì¥ë˜ì–´ ë°±ì—… ë°ì´í„° íŒŒì¼ì„ ì˜®ê¸´ë‹¤ í•œë“¤ ìˆ˜ì •ì´ ì•ˆë˜ê¸° ë•Œë¬¸ì´ë‹¤. ë”°ë¼ì„œ ë°±ì—…ë³¸ì˜ ê²°ê³¼ë¥¼ ì–»ê¸° ìœ„í•´ì„œëŠ” PV ë³¼ë¥¨ê³¼ Mysql ë¦¬ì†ŒìŠ¤ë¥¼ ì§€ìš°ê³  ë‹¤ì‹œ ë³µì›ì„ í•´ì•¼í•œë‹¤.\nVelero í´ëŸ¬ìŠ¤í„° ë§ˆì´ê·¸ë ˆì´ì…˜\ní´ëŸ¬ìŠ¤í„°ê°„ ë§ˆì´ê·¸ë ˆì´ì…˜ ë°©ë²•ìœ¼ë¡œ Veleroë¥¼ í™œìš©í•  ìˆ˜ ìˆë‹¤. ê³µì‹ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ í…ŒìŠ¤íŠ¸ë¥¼ ì§„í–‰í•´ë³´ê² ë‹¤.\nì§„í–‰ ì „ Velero ì—ì„œ í´ëŸ¬ìŠ¤í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì‹œ ì œì•½ì‚¬í•­ì´ ìˆìœ¼ë‹ˆ í™•ì¸ì´ í•„ìš”í•˜ë‹¤.\nVeleroëŠ” ê¸°ë³¸ì ìœ¼ë¡œ í´ë¼ìš°ë“œ ê³µê¸‰ì ê°„ì— PV ìŠ¤ëƒ…ìƒ·ì˜ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤. ì´ë¥¼ ìœ„í•œ ë°©ì•ˆìœ¼ë¡œ resticì„ ì´ìš©í•˜ì—¬ íŒŒì¼ì‹œìŠ¤í…œ ë ˆë²¨ì˜ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§„í–‰í•´ì•¼ í•œë‹¤. VeleroëŠ” ë°±ì—…ì´ ìˆ˜í–‰ëœ ìœ„ì¹˜ë³´ë‹¤ ë‚®ì€ Kubernetes ë²„ì „ì´ ìˆëŠ” í´ëŸ¬ìŠ¤í„°ë¡œì˜ ë³µì›ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤. ë™ì¼í•œ ë²„ì „ì˜ Kubernetesë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠëŠ” í´ëŸ¬ìŠ¤í„° ê°„ì— ì›Œí¬ë¡œë“œë¥¼ ë§ˆì´ê·¸ë ˆì´ì…˜í•˜ëŠ” ê²ƒì´ ê°€ëŠ¥í•  ìˆ˜ ìˆì§€ë§Œ ë§ˆì´ê·¸ë ˆì´ì…˜ ì „ì— ê° ì‚¬ìš©ì ì •ì˜ ë¦¬ì†ŒìŠ¤ì— ëŒ€í•œ í´ëŸ¬ìŠ¤í„° ê°„ API ê·¸ë£¹ì˜ í˜¸í™˜ì„±ì„ í¬í•¨í•˜ì—¬ ëª‡ ê°€ì§€ ìš”ì¸ì„ ê³ ë ¤í•´ì•¼ í•œë‹¤. AWS ë° Azureìš© Velero í”ŒëŸ¬ê·¸ì¸ì€ ë¦¬ì „ ê°„ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§€ì›í•˜ì§€ ì•ŠëŠ”ë‹¤.Â ì´ë¥¼ ìœ„í•œ ë°©ì•ˆìœ¼ë¡œ resticì„ ì‚¬ìš©í•´ì•¼ í•œë‹¤. ìš°ë¦¬ëŠ” resticì„ ì‚¬ìš©í•˜ë‹ˆ ì œì•½ì‚¬í•­ì— ììœ ë¡­ë‹¤. í´ëŸ¬ìŠ¤í„° ë§ˆì´ê·¸ë ˆì´ì…˜ì˜ ì˜ˆì— ëŒ€í•œ ì¼í™˜ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„°ë¥¼ ì¬ êµ¬ì¶•í•˜ì—¬ ì•ì„œ ìƒì„±í•œ Mysql ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ë³µì›í•´ë³´ê² ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 # velero ì„¤ì¹˜ export BUCKET=hanhorang-velero-s3 export REGION=ap-northeast-2 velero install \\ --provider aws \\ --bucket $BUCKET \\ --secret-file ./credentials-velero \\ --backup-location-config region=$REGION \\ --use-volume-snapshots=false \\ --plugins velero/velero-plugin-for-aws:v1.3.0 \\ --use-restic --------------------------------- velero get backup --------------------------------- NAME STATUS ERRORS WARNINGS CREATED EXPIRES STORAGE LOCATION SELECTOR mysql Completed 0 0 2023-03-17 00:31:21 +0900 KST 29d default \u0026lt;none\u0026gt; velero ë°±ì—… ê°œì²´ê°€ ê·¸ëŒ€ë¡œ ìˆë‹¤. ë³µì› ê³¼ì •ì€ ì• ê³¼ì •ê³¼ ë™ì¼í•˜ê¸°ì— ìƒëµí•˜ì˜€ë‹¤. í´ëŸ¬ìŠ¤í„°ë¥¼ ì¬êµ¬ì¶•í•´ë„ Velero ë°±ì—… ê°ì²´ê°€ ë‚¨ì•„ìˆëŠ” ì´ìœ ê°€ ë¬´ì—‡ì¼ê¹Œ?\nVelero ë¦¬ì†ŒìŠ¤ëŠ”Â ì˜¤ë¸Œì íŠ¸ ìŠ¤í† ë¦¬ì§€ì˜ ë°±ì—… íŒŒì¼ê³¼ ë™ê¸°í™”ë˜ê¸° ë•Œë¬¸ì´ë‹¤. ì„¤ì¹˜ ê³¼ì •ì—ì„œ ì‚­ì œí•œ í´ëŸ¬ìŠ¤í„°ì™€ ìƒˆë¡œìš´ í´ëŸ¬ìŠ¤í„°ì˜ Velero ë²„í‚·ì´ ë™ì¼í•˜ë¯€ë¡œ ë°±ì—… ê°ì²´ê°€ ê·¸ëŒ€ë¡œ ìˆìŒì„ í™•ì¸í•˜ì˜€ë‹¤. í´ëŸ¬ìŠ¤í„°1ê³¼ í´ëŸ¬ìŠ¤í„°2ê°€ ë³‘í–‰ ìš´ì˜ì‹œì—ë„ ë²„í‚· ë°ì´í„°ì— ë”°ë¼ Velero ë¦¬ì†ŒìŠ¤ê°€ ë™ê¸°í™”ê°€ ì´ë£¨ì–´ì§„ë‹¤ëŠ”ë° ê¸°ë³¸ ë™ê¸°í™” ê°„ê²©ì´ 1ë¶„ìœ¼ë¡œ ì´ ë¶€ë¶„ì„ í™•ì¸í•˜ì—¬ ë§ˆì´ê·¸ë ˆì´ì…˜ì„ ì§„í–‰í•˜ë©´ ë  ê²ƒ ê°™ë‹¤.\në¡œì»¬ ë³¼ë¥¨ ëª¨ë‹ˆí„°ë§ PV ë³¼ë¥¨ ì„±ëŠ¥ í™•ì¸í•  ìˆ˜ ìˆëŠ” krew df-pv ë„êµ¬ê°€ ìˆìœ¼ë‚˜, HostPath ë³¼ë¥¨ì€ ì¸ìŠ¤í† ì–´ìŠ¤í† ì–´ë¼ì„œ í™•ì¸ë˜ì§€ ì•ŠëŠ”ë‹¤. í•˜ì§€ë§Œ Local ë³¼ë¥¨ì€ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\n1 2 3 4 5 kubectl krew df-pv \u0026amp;\u0026amp; kubectl df-pv --------------------------------- PV NAME PVC NAME NAMESPACE NODE NAME POD NAME VOLUME MOUNT NAME SIZE USED AVAILABLE %USED IUSED IFREE %IUSED pvc-678e7407-9f76-4fd1-a9ad-8c2581b8df36 data-mysql-0 default i-0314088c74eee3276 mysql-0 data 123Gi 4Gi 119Gi 3.68 119172 16395900 0.72 pvc-d2c3cbcb-13ec-46de-81e9-1178d25dd4ad data-mysql-1 default i-0ab66ac834dc8710d mysql-1 data 123Gi 4Gi 119Gi 3.74 121203 16393869 0.73 ì„±ëŠ¥ ì¸¡ì • ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ì˜ ì„±ëŠ¥ ì¸¡ì • ë°©ë²•ìœ¼ë¡œ iostat ëª…ë ¹ì–´ì™€ krew íˆ´ì¸ kubestrì„ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ì¸¡ì •í•˜ê² ë‹¤.\nkubestr ìŠ¤í† ë¦¬ì§€ IOPS ì¸¡ì • íˆ´ì´ë‹¤. ìŠ¤í† ë¦¬ì§€ ì‚¬ìš©ì— ë”°ë¥¸ ê²€ì¦ìš©ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ì¢‹ì€ íˆ´ì¸ ê²ƒ ê°™ë‹¤. ì˜ˆì œë„ ë§ìœ¼ë‹ˆ ë§í¬ë¥¼ í†µí•´ í™•ì¸í•˜ì. ì´ë²ˆ ì˜ˆì œì—ì„œëŠ” ì‹¤ìŠµ ì°¸ê³ ìš© ì±…ì—ì„œ ì œê³µí•´ì£¼ì‹  ì˜ˆì œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ í†µí•´ ì„±ëŠ¥ì„ ì¸¡ì •í•  ê²ƒì´ë‹¤.\nfio-read.fio\nfioë¥¼ ì‚¬ìš©í•˜ì—¬ 4KB ë¸”ë¡ í¬ê¸°ë¥¼ ê°€ì§€ëŠ” ëœë¤ ì½ê¸° ë° ì“°ê¸°\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [global] ioengine=libaio direct=1 bs=4k runtime=120 time_based=1 iodepth=16 numjobs=4 # numjobs=16 size=1g group_reporting rw=randrw rwmixread=100 rwmixwrite=0 [read] ioengine=libaio : Asynchronous I/Oë¥¼ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ libaio ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. direct=1 : Direct I/Oë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. bs=4k : I/O ìš”ì²­ì— ì‚¬ìš©ë˜ëŠ” ë¸”ë¡ í¬ê¸°ëŠ” 4KBì…ë‹ˆë‹¤. runtime=120 : 120ì´ˆ ë™ì•ˆ ì‘ì—…ì„ ì‹¤í–‰í•©ë‹ˆë‹¤. time_based=1 : ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. iodepth=16 : ê° ì‘ì—…ì— ëŒ€í•œ I/O ìš”ì²­ ìˆ˜ë¥¼ 16ê°œë¡œ ì„¤ì •í•©ë‹ˆë‹¤. numjobs=4 : 4ê°œì˜ ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. size=1g : ê° ì‘ì—…ì— ëŒ€í•œ ë°ì´í„° í¬ê¸°ëŠ” 1GBì…ë‹ˆë‹¤. group_reporting : ëª¨ë“  ì‘ì—… ê²°ê³¼ë¥¼ í†µí•©í•˜ì—¬ ë³´ê³ í•©ë‹ˆë‹¤. rw=randrw : ëœë¤ ì½ê¸° ë° ì“°ê¸° ì‘ì—…ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. rwmixread=100 : ì‘ì—… ì¤‘ ì½ê¸° ì‘ì—…ì˜ ë¹„ìœ¨ì€ 100%ì…ë‹ˆë‹¤. rwmixwrite=0 : ì‘ì—… ì¤‘ ì“°ê¸° ì‘ì—…ì˜ ë¹„ìœ¨ì€ 0%ì…ë‹ˆë‹¤. fio-write.fio\në£¨íŠ¸ ë””ë ‰í† ë¦¬ì—ì„œ 4KB ë¸”ë¡ í¬ê¸°ë¡œ 16ê°œì˜ jobì´ 16ê°œì˜ i/o depthë¡œ ì‹¤í–‰ë˜ë©°, ì‹¤í–‰ ì‹œê°„ì´ 120ì´ˆì¸ 1GB íŒŒì¼ì— ëŒ€í•´ 100% ì“°ê¸° ëœë¤ í…ŒìŠ¤íŠ¸\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 [global] ioengine=libaio numjobs=16 iodepth=16 direct=1 bs=4k runtime=120 time_based=1 size=1g group_reporting rw=randrw rwmixread=0 rwmixwrite=100 directory=/ [read] rwmixwrite=100: 100% ì“°ê¸° í…ŒìŠ¤íŠ¸ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤. directory=/: í…ŒìŠ¤íŠ¸í•  ë””ë ‰í† ë¦¬ë¥¼ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ë¡œ ì„¤ì •í•©ë‹ˆë‹¤. ì„±ëŠ¥ ì¸¡ì •\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 kubestr fio -f fio-write.fio -s local-path --size 10G --------------------------------- PVC created kubestr-fio-pvc-hp69m Pod created kubestr-fio-pod-fcvcp Running FIO test (fio-write.fio) on StorageClass (local-path) with a PVC of Size (10G) Elapsed time- 4m11.664545514s FIO test results: FIO version - fio-3.30 Global options - ioengine=libaio verify= direct=1 gtod_reduce= JobName: blocksize= filesize= iodepth= rw= write: IOPS=3023.577881 BW(KiB/s)=12094 iops: min=992 max=8640 avg=3023.464355 bw(KiB/s): min=3968 max=34564 avg=12093.908203 Disk stats (read/write): nvme0n1: ios=0/362587 merge=0/173 ticks=0/6330627 in_queue=6330627, util=99.954132% fio-write ì‹¤í–‰ ê²°ê³¼, ì“°ê¸° í‰ê·  iopsê°€ 3034ì¸ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\nQ. í…ŒìŠ¤íŠ¸ê°€ ì•ˆë  ê²½ìš°, PV ìƒíƒœ Pending?\ní•´ë‹¹ ê²½ìš°ëŠ” PVC ìš”ì²­ì— ë§ëŠ” ë³¼ë¥¨ì˜ PVê°€ ì—†ì„ë•Œ ë°œìƒí•œë‹¤. PVC ìš”ì²­ì— ë§ëŠ” ë³¼ë¥¨ì´ ìˆëŠ”ì§€ ë˜ëŠ” Local-path-provisioner ì„¤ì •ì„ í™•ì¸í•˜ì. í•„ìì˜ ê²½ìš° Local-path-provisioner ì„¤ì •ìœ¼ë¡œ Pending ì´ ë°œìƒí–ˆë‹¤.\n1 2 3 4 kubectl get pvc -A --------------------------------- NAMESPACE NAME STATUS VOLUME CAPACITY ACCESS MODES STORAGECLASS AGE default kubestr-fio-pvc-dl7vx Pending local-path 4m34 ë…¸ë“œ ë³¼ë¥¨ IO ì„±ëŠ¥ ì¸¡ì • iostat ëª…ë ¹ì–´ë¥¼ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìŠ¤í† ë¦¬ì§€ì˜ ì„±ëŠ¥ê³¼ ì‚¬ìš©ëŸ‰ì— ê´€í•œ ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í´ëŸ¬ìŠ¤í„° ìš´ì˜ì‹œ ìŠ¤í† ë¦¬ì§€ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì˜ ì¼í™˜ìœ¼ë¡œ ì‚¬ìš©í•˜ì.\nì•„ë˜ ì˜ˆì œëŠ” fio-write ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ì¤‘ iostat ë¥¼ ì‹¤í–‰í•˜ì—¬ ìŠ¤í† ë¦¬ì§€ ì •ë³´ë¥¼ í™•ì¸í•œ ì˜ˆì œì´ë‹¤.\n1 2 3 4 5 6 7 # iostat íŒ¨í‚¤ì§€ ì„¤ì¹˜ sudo apt install -y sysstat iostat -xmdz 1 -p nvme2n1 --------------------------------- Device r/s rMB/s rrqm/s %rrqm r_await rareq-sz w/s wMB/s wrqm/s %wrqm w_await wareq-sz d/s dMB/s drqm/s %drqm d_await dareq-sz aqu-sz %util nvme2n1 0.00 0.00 0.00 0.00 0.00 0.00 24.00 0.10 2.00 7.69 0.75 4.33 0.00 0.00 0.00 0.00 0.00 0.00 0.02 4.00 w/s: ì´ˆë‹¹ ì“°ê¸° ìš”ì²­ ìˆ˜ wMB/s: ì´ˆë‹¹ ì“´ ë°ì´í„° ì–‘ (ë©”ê°€ë°”ì´íŠ¸/ì´ˆ) wrqm/s: ì´ˆë‹¹ ì“°ê¸° ìš”ì²­ íì— ë“¤ì–´ê°„ ìš”ì²­ ìˆ˜ %wrqm: ì“°ê¸° ìš”ì²­ íì— ë“¤ì–´ê°„ ìš”ì²­ ë¹„ìœ¨ w_await: ì“°ê¸° ìš”ì²­ ëŒ€ê¸° ì‹œê°„, ë“œë¼ì´ë²„ ìš”ì²­ ëŒ€ê¸°ì—´ì—ì„œ ê¸°ë‹¤ë¦° ì‹œê°„ê³¼ ì¥ì¹˜ì˜ I/O ì‘ë‹µì‹œê°„ì„ ëª¨ë‘ í¬í•¨í•œë‹¤. (ë°€ë¦¬ì´ˆ) wareq-sz: í‰ê·  ì“°ê¸° ìš”ì²­ í¬ê¸° (ì„¹í„°) aqu-sz: ìš”ì²­ ëŒ€ê¸°ì—´ì˜ í‰ê·  ê¸¸ì´ %util: ë””ìŠ¤í¬ ì‚¬ìš©ë¥  (0 ~ 100%) ë¡œì»¬ ìŠ¤í† ë¦¬ì§€ QnA Q1. AWS ì¸ìŠ¤í† ì–´ ìŠ¤í† ì–´ì— ëŒ€í•œ ë³¼ë¥¨ ìŠ¤í† ë¦¬ì§€ ì¡°ì ˆì´ ê°€ëŠ¥í•œê°€?\nì¸ìŠ¤í„´ìŠ¤ ìŠ¤í† ì–´ëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ì˜ ë¡œì»¬ ë””ìŠ¤í¬ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ê¸° ë•Œë¬¸ì— í¬ê¸° ì¡°ì •ì´ ë¶ˆê°€ëŠ¥í•˜ë‹¤. ì¸ìŠ¤í„´ìŠ¤ ìŠ¤í† ì–´ë¥¼ ì‚¬ìš©í•˜ëŠ” EC2 ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë³€ê²½í•˜ê±°ë‚˜ ìƒˆë¡œìš´ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì‹œì‘í•˜ì—¬ í¬ê¸°ë¥¼ ì¡°ì •í•´ì•¼ í•œë‹¤. ì¼ë°˜ì ìœ¼ë¡œ DB(Mysql) ë³¼ë¥¨ ì‚¬ìš©ëŸ‰ìœ¼ë¡œ 10G~100Gì„ ì„¤ì •í•œë‹¤ê³  í•˜ì§€ë§Œ, ì• í”Œë¦¬ì¼€ì´ì…˜ ê·œëª¨ì™€ ê¸°ê°„ì— ë”°ë¼ ì‚¬ìš©ëŸ‰ ì˜ˆì¸¡ì´ í˜ë“¤ë‹¤. í•„ìš”ì‹œ ë°±ì—…ì„ í†µí•´ ì¸ìŠ¤í† ì–´ ìŠ¤í† ì–´ ë³¼ë¥¨ì„ ë³€ê²½í•  ìˆ˜ ìˆë„ë¡ í•˜ì. EC2 ì¸ìŠ¤í„´ìŠ¤ì— ë”°ë¥¸ ë³¼ë¥¨(SSD) ëŠ” ë§í¬ì—ì„œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤.\nQ2. hostpath ë³¼ë¥¨ì„ ì—¬ëŸ¬ê°œì˜ íŒŒë“œê°€ ë™ì‹œì— ì‚¬ìš©í•  ìˆ˜ ìˆì„ê¹Œ?\në…¸ë“œì˜ íŒŒì¼ ì‹œìŠ¤í…œì€ ì—¬ëŸ¬ ê°œì˜ í”„ë¡œì„¸ìŠ¤ê°€ ë™ì‹œì— ì ‘ê·¼í•  ìˆ˜ ìˆëŠ” ê³µìœ  ë¦¬ì†ŒìŠ¤ì´ê¸° ë•Œë¬¸ì— ì—¬ëŸ¬ ê°œì˜ íŒŒë“œê°€ í•˜ë‚˜ì˜ hostpathë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆë‹¤. í•˜ì§€ë§Œ, ë°ì´í„° ì†ìƒì´ë‚˜ ê¶Œí•œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆë‹¤. í•˜ë‚˜ì˜ íŒŒë“œê°€ íŒŒì¼ì„ ì“´ í›„ì— ë‹¤ë¥¸ íŒŒë“œê°€ ë™ì¼í•œ íŒŒì¼ì„ ì½ì„ ê²½ìš°ë‚˜, ì—¬ëŸ¬ ê°œì˜ íŒŒë“œê°€ ë™ì‹œì— ë™ì¼í•œ íŒŒì¼ì„ ì“°ëŠ” ê²½ìš°ê°€ ìˆê¸° ë•Œë¬¸ì´ë‹¤. ì´ë¥¼ ìœ„í•´ ì ì ˆí•œ ë™ê¸°í™” ë° ë½ ë©”ì»¤ë‹ˆì¦˜ì„ êµ¬í˜„ì´ í•„ìš”í•˜ë‹¤.\ní…ŒìŠ¤íŠ¸ë¡œ ìŠ¤í„°ë””ì—ì„œ ê³µìœ í•´ì£¼ì‹  localpath-fail.yaml ë¥¼ ìˆ˜ì •í•´ì„œ ë¡œê·¸ë¥¼ í™•ì¸í•´ë´¤ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 apiVersion: apps/v1 kind: Deployment metadata: name: date-pod labels: app: date spec: replicas: 1 selector: matchLabels: app: date template: metadata: labels: app: date spec: terminationGracePeriodSeconds: 3 containers: - name: app image: centos command: [\u0026#34;/bin/sh\u0026#34;] args: [\u0026#34;-c\u0026#34;, \u0026#34;while true; do echo $(date -u) \u0026gt;\u0026gt; /data/out.txt; sleep 0.01; done\u0026#34;] # 0.01 ë¡œ ìˆ˜ì • volumeMounts: - name: pod-persistent-volume mountPath: /data volumes: - name: pod-persistent-volume persistentVolumeClaim: claimName: localpath-claim 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # íŒŒë“œ 10ê°œë¡œ ì¦ê°€í›„ í…ŒìŠ¤íŠ¸ kubectl scale deployment date-pod --replicas=10 -------------------------------------- # ë¡œê·¸ í™•ì¸ ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:05 | wc -l 355 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:05 | wc -l 355 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:06 | wc -l 457 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:07 | wc -l 511 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:08 | wc -l 513 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:09 | wc -l 530 ubuntu@i-0993bfc0c3f4818c8:/data/local-path/pvc-9676527c-e860-4c13-acc3-cda3bd1a5f1d_default_localpath-claim$ cat out.txt | grep 03:10 | wc -l 506 0.01ì´ˆ x 10 ê°œ íŒŒë“œë¡œ 1ì´ˆë‹¹ ì•½ 1000ê°œì˜ ê²°ê³¼ê°€ ë‚˜ì™€ì•¼ í•˜ì§€ë§Œ 350~530 ê°œì˜ ê²°ê³¼ê°€ ë‚˜ì˜¤ëŠ” ê²ƒì„ í™•ì¸í•˜ì˜€ë‹¤. ì•ì„œ kubestr ì¸¡ì •ì—ì„œ ì“°ê¸° IOPSë¥¼ ì¸¡ì •í•˜ì—¬ ì•½ 3000ì´ ë‚˜ì™”ìŒì—ë„ í„±ì—†ì´ ë¶€ì¡±í•œ ê²ƒì„ ì•Œ ìˆ˜ ìˆë‹¤.\nQ3. Velero ì˜ ë°±ì—… ìš©ëŸ‰ì€ ëª‡ ì¸ê°€?\nì‚¬ìš© ë²„í‚·ì— ë”°ë¼ ë‹¬ë¼ì§„ë‹¤. S3 ë²„í‚· ê¸°ì¤€ìœ¼ë¡œëŠ” í•´ë‹¹ ë²„í‚·ì˜ ìš©ëŸ‰ì— ë”°ë¼ê°€ëŠ”ë° ìµœëŒ€ 5í…Œë¼ê¹Œì§€ ì§€ì›ì´ ê°€ëŠ¥í•˜ë‹¤.\n","date":"Mar 18","permalink":"https://HanHoRang31.github.io/post/pkos2-2-localstorage/","tags":["KANS","kops","cloud","AWS","kubernetes","Volume","velero","local-path-provisioner"],"title":"[PKOS] ì¿ ë²„ë„¤í‹°ìŠ¤ ë¡œì»¬ìŠ¤í† ë¦¬ì§€ì™€ Veleroë¥¼ í†µí•œ ë°±ì—… í…ŒìŠ¤íŠ¸"},{"categories":null,"contents":" 1 2 Production Kubernetes Online Study (=PKOS)ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ ì‹¤ë¬´ ì‹¤ìŠµ ìŠ¤í„°ë””ì…ë‹ˆë‹¤. CloudNet@ Gasida(ê°€ì‹œë‹¤)ì´ ì§„í–‰í•˜ë©°, ì±… \u0026#34;24ë‹¨ê³„ ì‹¤ìŠµìœ¼ë¡œ ì •ë³µí•˜ëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤\u0026#34;ì„ ê¸°ë°˜ìœ¼ë¡œ ì§„í–‰í•˜ê³  ìˆìŠµë‹ˆë‹¤. PKOS 1ì£¼ì°¨ ìŠ¤í„°ë”” ë‚´ìš©ê³¼ ëŠë‚Œì ì„ ì •ë¦¬í•˜ê³ ì í•œë‹¤. ìŠ¤í„°ë””í•˜ë©´ì„œ ë§¤ë²ˆ ëŠë¼ëŠ” ê±°ì§€ë§Œ ì •ë§ ê´´ìˆ˜ë¶„ë“¤ ë„ˆë¬´ ë§ê³ , ë°°ìš¸ ì ì´ ì •ë§ ë§ë‹¤â€¦ íŠ¹íˆ ëª¨ì„ì¥ë‹˜ì´ì‹  ê°€ì‹œë‹¤ë‹˜ì˜ ìŠ¤í„°ë”” ë‚´ìš©ì€ ë³¼ ë•Œë§ˆë‹¤ ê°íƒ„ë§Œ ë‚˜ì˜¨ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ì— ëŒ€í•œ ì›ë¦¬ì™€ ì„¸ë¶€ ì»´í¬ë„ŒíŠ¸ì— ëŒ€í•œ ëª…ë ¹ì–´ê¹Œì§€ ë°°ìš´ ì ì´ ë§ë‹¤. ë³¸ ê¸€ì—ì„œëŠ” í•„ìê°€ ë°°ìš´ ë‚´ìš©ì„ ì •ë¦¬í•¨ê³¼ ë™ì‹œì— ê°œë…ì— ëŒ€í•´ ëª°ëë˜ ë¶€ë¶„ì´ë‚˜, íŠ¸ëŸ¬ë¸”ìŠˆíŒ…ì— ëŒ€í•œ ë‚´ìš©ì„ ì¤‘ì ì ìœ¼ë¡œ ì •ë¦¬í•˜ì˜€ë‹¤.\nì¶”ê°€ë¡œ, ëª°ëë˜ ë¶€ë¶„ì€ ChatGPTë¥¼ í™œìš©í•˜ì—¬ ì‘ì„±í•˜ì˜€ë‹¤. ChatGPTê°€ ì£¼ëŠ” ë‹µë³€ì€ ëŒ€ì²´ë¡œ ë§Œì¡±í•˜ì§€ë§Œ, ê³µì‹ ë¬¸ì„œì— ëŒ€í•œ ë‚´ìš©ê³¼ ë¹„êµí•˜ì—¬ ë‹¤ë¥¸ ë‚´ìš©ì´ ì¼ë¶€ ì¡´ì¬í•œë‹¤. ChatGPT í™œìš©ì‹œ, ê³µì‹ ë¬¸ì„œì™€ ì´ì¤‘ ê²€ì¦ì´ í•„ìš”í•˜ë‹¤ê³  ë³¸ë‹¤. ë³¸ ê¸€ì—ì„œë„ ë‹µë³€ ë‚´ìš©ì„ ì¼ë¶€ ìˆ˜ì •í•˜ì—¬ ì‘ì„±í•œë‹¤.\nkops? kopsëŠ” ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ë¥¼ ìƒì„±, ì—…ê·¸ë ˆì´ë“œ, ê´€ë¦¬í•˜ëŠ” ë° ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆ ì†ŒìŠ¤ ë„êµ¬ì´ë‹¤. ëª…ë ¹ì–´ íˆ´ë¡œ ì‰½ê²Œ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì„±í•˜ê³  ê´€ë¦¬í•  ìˆ˜ ìˆëŠ” íˆ´ì´ë¼ê³  ì´í•´í•˜ë©´ ë˜ê² ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ì˜ ì¸í”„ë¼ë¥¼ ì½”ë“œë¡œ ì •ì˜í•˜ê³  ê´€ë¦¬í•˜ëŠ”ë° ì‚¬ìš©í•  ìˆ˜ ìˆì–´ IaC ì´ë©°, ê°™ì€ IaC íˆ´ì¸ Terraform(í…Œë¼í¼)ê³¼ì˜ íŠ¹ì§•ì„ ë¹„êµí•˜ë©´ ë‹¤ìŒê³¼ ê°™ë‹¤.\nkopsê³¼ Terraform íŠ¹ì§• ë¹„êµ í‘œ\níŠ¹ì§• kops Terraform ì§€ì›í•˜ëŠ” í´ë¼ìš°ë“œ í”Œë«í¼(Provider) AWS, GCP, OpenStack, DigitalOcean ë“± AWS, GCP, Azure, Oracle Cloud, Alibaba Cloud, VMware, OpenStack ë“± ê´€ë¦¬ ëŒ€ìƒ Kubernetes í´ëŸ¬ìŠ¤í„° ì¸í”„ë¼ìŠ¤íŠ¸ëŸ­ì²˜ (ì„œë²„, ë„¤íŠ¸ì›Œí¬, ë°ì´í„°ë² ì´ìŠ¤ ë“±) ì½”ë“œ ì‘ì„± ë°©ì‹ YAML íŒŒì¼ HCL (HashiCorp Configuration Language) ìƒíƒœ ê´€ë¦¬ ìƒíƒœë¥¼ ì§€ì •ëœ ì €ì¥ì†Œ(state)ì— ì €ì¥ ìƒíƒœë¥¼ ì§€ì •ëœ ì €ì¥ì†Œ(backend)ì— ì €ì¥ ì¥ì  ê°„ë‹¨í•˜ê³  ì§ê´€ì ì¸ í´ëŸ¬ìŠ¤í„° êµ¬ì„± AWSë¿ë§Œ ì•„ë‹ˆë¼ ë‹¤ë¥¸ í´ë¼ìš°ë“œ í”„ë¡œë°”ì´ë”ë„ ì§€ì› ë‹¨ì  Kubernetes í´ëŸ¬ìŠ¤í„°ë§Œ ì§€ì› Kopsì— ë¹„í•´ ë°°ìš°ê¸°ê°€ ì–´ë ¤ì›€ ê·¸ë ‡ë‹¤ë©´ kopsëŠ” ì–¸ì œ ì¨ì•¼ í• ê¹Œ?\nëª¨ì„ì¥ë‹˜ ì˜ê²¬ê³¼ ë™ì¼í•˜ê²Œ êµìœ¡ìš©ì´ ì í•©í•˜ë‹¤ê³  ë³¸ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì´ ê°„ë‹¨í•˜ê³  ë°°ìš°ê¸° ì‰½ë‹¤. ë˜í•œ, ë°°í¬ ì†ë„ë„ ë¹ ë¥´ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ ê´€ë¦¬í˜• ì„œë¹„ìŠ¤ì¸ EKS ì™€ ë¹„êµí–ˆì„ ë•Œ, ë§ˆìŠ¤í„° ë…¸ë“œë“¤ì„ ì„¸ë¶€ì ìœ¼ë¡œ ì•Œ ìˆ˜ ìˆì–´ ì„¸ë¶€ ì›ë¦¬ ì´í•´ì— ì¢‹ê³ , ë¹„ìš©ë„ ì €ë ´í•˜ë‹¤. kops ê³µì‹ë¬¸ì„œë„ ì •ë¦¬ê°€ ì˜ ë˜ì–´ ìˆë‹¤. ëˆˆì—¬ê²¨ ë³¼ ì ì€ ê³µì‹ë¬¸ì„œì˜ addonê³¼ Operation ë¶€ë¶„ì´ë‹¤. í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ë¥¼ ë° addon ë°°í¬ë¥¼ ê°„ë‹¨í•˜ê²Œ í…ŒìŠ¤íŠ¸í•  ìˆ˜ ìˆê³  ë°°í¬ yamlë¥¼ í™•ì¸í•  ìˆ˜ ìˆê¸° ë•Œë¬¸ì´ë‹¤.\nì‹¤ìŠµ ìŠ¤í„°ë”” ë‚´ìš©ìœ¼ë¡œ kopsë¥¼ í†µí•´ AWSì— ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ë¥¼ êµ¬ì¶•í•˜ê³ , ê²Œì„ ë§ˆë¦¬ì˜¤ë¥¼ ì˜ˆì œë¡œ ë°°í¬í•˜ì˜€ë‹¤. ê³¼ì •ì€ í¬ê²Œ 3ê°€ì§€ë¡œ ì§„í–‰í•˜ì˜€ë‹¤.\në² ìŠ¤ì²œ ì„œë²„(kops-ec2) êµ¬ì„± kops ë¥¼ í†µí•œ í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ë° í™•ì¸ External DNS ì™€ ê²Œì„, ìŠˆí¼ë§ˆë¦¬ì˜¤ ë°°í¬ ì‹¤ìŠµ ê³¼ì • ì „ ì‚¬ì „ ì‘ì—…ìœ¼ë¡œ í¼ë¸”ë¦­ ë„ë©”ì¸ êµ¬ì…, í‚¤ í˜ì–´ ìƒì„±, S3 ë²„í‚· ìƒì„±, AWS IAM ìê²© ì¦ëª…ì„ ì§„í–‰í•˜ì˜€ë‹¤. ì‚¬ì „ ì‘ì—… ë‚´ìš©ì€ ê³µì‹ ë¬¸ì„œì—ì„œ ì°¸ê³ ê°€ ê°€ëŠ¥í•˜ë‹¤.\nQ. í¼ë¸”ë¦­ ë„ë©”ì¸ êµ¬ì… ì´ìœ  ?\ní¼ë¸”ë¦­ ë„ë©”ì¸ì€ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•˜ì—¬ êµ¬ì…í•˜ì˜€ë‹¤. í´ëŸ¬ìŠ¤í„° ì´ë¦„ì„ ë„ë©”ì¸ìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì™¸ë¶€ì—ì„œ ì„œë¹„ìŠ¤ ë””ìŠ¤ì»¤ë²„ë¦¬ ë° í´ëŸ¬ìŠ¤í„° ì•¡ì„¸ìŠ¤ê°€ ì‰½ê²Œ ê°€ëŠ¥í•´ì§€ê¸° ë•Œë¬¸ì´ë‹¤. ìŠ¤í„°ë””ì—ì„œëŠ” í•´ë‹¹ ë„ë©”ì¸ì„ í†µí•´ í´ëŸ¬ìŠ¤í„° êµ¬ì„± í™•ì¸ê³¼ ê²Œì„ ë°°í¬ í›„ ì ‘ê·¼ì„ ìœ„í•´ ì‚¬ìš©í•˜ì˜€ë‹¤.\n1. ë² ìŠ¤ì²œ ì„œë²„(kops-ec2) êµ¬ì„± ë² ìŠ¤ì²œ ì„œë²„ êµ¬ì„±ì€ ëª¨ì„ì¥ë‹˜ì´ ê³µìœ í•´ì£¼ì‹  CloudFormation í…œí”Œë¦¿ì„ í†µí•´ êµ¬ì„±í•˜ì˜€ë‹¤. í…œí”Œë¦¿ êµ¬ì„±ì€ VPC ì™€ igw êµ¬ì„±ê°™ì€ AWS ë„¤íŠ¸ì›Œí¬ êµ¬ì„±ê³¼ EC2 ì„œë²„ ì„¤ì •ìœ¼ë¡œ ë˜ì–´ìˆë‹¤. ê·¸ ì¤‘ EC2 ì„œë²„ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ë¥¼ í™•ì¸í•  í•„ìš”ê°€ ìˆëŠ”ë° kopsì™€ í•„ìš” íŒ¨í‚¤ì§€ë¥¼ ê°™ì´ ì„¤ì¹˜í•´ì£¼ê¸° ë•Œë¬¸ì´ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 #!/bin/bash # í˜¸ìŠ¤íŠ¸ ì´ë¦„ ë³€ê²½ hostnamectl --static set-hostname kops-ec2 # EC2 ì„œë²„ ì‹œê°„ì„ ì„œìš¸ë¡œ ë³€ê²½ ln -sf /usr/share/zoneinfo/Asia/Seoul /etc/localtime # Install Packages cd /root yum -y install tree jq git htop ## kubectl ì„¤ì¹˜ curl -LO \u0026#34;https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl\u0026#34; install -o root -g root -m 0755 kubectl /usr/local/bin/kubectl ## kops ì„¤ì¹˜ curl -Lo kops https://github.com/kubernetes/kops/releases/download/$(curl -s https://api.github.com/repos/kubernetes/kops/releases/latest | grep tag_name | cut -d \u0026#39;\u0026#34;\u0026#39; -f 4)/kops-linux-amd64 chmod +x kops mv kops /usr/local/bin/kops ## awscli ì„¤ì¹˜ curl \u0026#34;https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\u0026#34; -o \u0026#34;awscliv2.zip\u0026#34; unzip awscliv2.zip sudo ./aws/install ## í™˜ê²½ ë³€ìˆ˜ ì„¤ì • export PATH=/usr/local/bin:$PATH source ~/.bash_profile ## aws cli ìë™ ì™„ì„± ì„¤ì • complete -C \u0026#39;/usr/local/bin/aws_completer\u0026#39; aws ## SSH ì„¤ì • ssh-keygen -t rsa -N \u0026#34;\u0026#34; -f /root/.ssh/id_rsa ## vi -\u0026gt; vim ìœ¼ë¡œ ì„¤ì • echo \u0026#39;alias vi=vim\u0026#39; \u0026gt;\u0026gt; /etc/profile ## root ê³„ì • ë³€í™˜ echo \u0026#39;sudo su -\u0026#39; \u0026gt;\u0026gt; /home/ec2-user/.bashrc ## helm ì„¤ì¹˜ curl -s https://raw.githubusercontent.com/helm/helm/master/scripts/get-helm-3 | bash wget https://github.com/andreazorzetto/yh/releases/download/v0.4.0/yh-linux-amd64.zip unzip yh-linux-amd64.zip mv yh /usr/local/bin/ ë² ìŠ¤ì²œ ì„œë²„ êµ¬ì„± ê³¼ì • ì¤‘ ì—ëŸ¬ ë°œìƒ ì‹œ, AWS Cloudformationì—ì„œ ë¡œê·¸ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤. í•„ìëŠ” VPCê°€ ìµœëŒ€ì—¬ì„œ ë² ìŠ¤ì²œ ì„œë²„ êµ¬ì„±ì´ ì•ˆë˜ì—ˆë‹¤. í•´ê²°ì„ ìœ„í•´ í•„ìš”ì—†ëŠ” VPCë¥¼ ì‚­ì œí•˜ê³ , í…œí”Œë¦¿ìœ¼ë¡œ ìƒì„±í•œ Cloudformtation ìŠ¤íƒì„ ì‚­ì œí•˜ê³  ì¬ì‹¤í–‰í•˜ì˜€ë‹¤.\n2. kopsë¥¼ í†µí•œ í´ëŸ¬ìŠ¤í„° êµ¬ì¶• ë° í™•ì¸ ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•ì€ kops ëª…ë ¹ì–´ë¡œ êµ¬ì¶•í•˜ì˜€ë‹¤. í´ëŸ¬ìŠ¤í„° ìƒì„±ì— ëŒ€í•œ ì˜µì…˜ì€ ê³µì‹ ë¬¸ì„œì—ì„œ ì°¸ê³ í•  ìˆ˜ ìˆì—ˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 # í´ëŸ¬ìŠ¤í„° ìƒì„± bash ## export KOPS_STATE_STORE=s3://( í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì €ì¥ì†Œë¡œ í™œìš©í•  ë²„í‚· ì´ë¦„) ## export KOPS_CLUSTER_NAME=\u0026lt;ë„ë©”ì¸ ë©”ì¸ ì£¼ì†Œ\u0026gt; ## export REGION=ap-northeast-2 ì§€ì—­ kops create cluster \\ --cloud aws \\ --name $KOPS_CLUSTER_NAME \\ --state s3://$KOPS_STATE_STORE \\ --zones \u0026#34;$REGION\u0026#34;a,\u0026#34;$REGION\u0026#34;c \\ --networking amazonvpc \\ --network-cidr 172.30.0.0/16 \\ --kubernetes-version \u0026#34;1.24.10\u0026#34; \\ --node-count 2 \\ --node-size t3.medium \\ --master-size t3.medium \\ --ssh-public-key ~/.ssh/id_rsa.pub \\ -y --state : í´ëŸ¬ìŠ¤í„° ê´€ë ¨ ì„¤ì • íŒŒì¼ë“¤ì´ ì €ì¥ëœë‹¤. ì´ë ‡ê²Œ ì €ì¥ëœ ì„¤ì • íŒŒì¼ë“¤ì€ ë‚˜ì¤‘ì— í´ëŸ¬ìŠ¤í„°ë¥¼ ì—…ë°ì´íŠ¸í•˜ê±°ë‚˜ ì‚­ì œí•  ë•Œ ì‚¬ìš©ëœë‹¤. ì‹¤ìŠµì—ì„œëŠ” ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ì¸ S3ë¥¼ ì´ìš©í•˜ì˜€ë‹¤. â€”state í”Œë˜ê·¸ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë©´ ë¡œì»¬ ì €ì¥ì†Œì¸ ~/.kops ì— í´ëŸ¬ìŠ¤í„° ì„¤ì • íŒŒì¼ì´ ì €ì¥ëœë‹¤. í•˜ì§€ë§Œ ë¡œì»¬ ì‹œìŠ¤í…œì— ëŒ€í•œ ì˜ì¡´ì„±ì´ ë†’ì•„ì§€ê³  í˜‘ì—…ì‹œì— ëŒ€í•œ ê³µìœ ì„±ì´ ë–¨ì–´ì ¸ ì™¸ë¶€ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•˜ëŠ” ê²ƒì„ ê¶Œì¥í•œë‹¤. í•„ìëŠ” í´ëŸ¬ìŠ¤í„° ìƒì„±ì‹œ VPC ê°œìˆ˜ ì´ìœ (error creating VPC: VpcLimitExceeded) ë¡œ í´ëŸ¬ìŠ¤í„° ìƒì„±ì´ ë˜ì§€ ì•Šì•˜ë‹¤.\nì¬ì„¤ì¹˜ë¥¼ ìœ„í•´ì„œëŠ” ê¸°ì¡´ í´ëŸ¬ìŠ¤í„° ì‚­ì œê°€ í•„ìš”í•˜ë‹¤. ì‹¤ìŠµ ë‚´ìš©ì˜ êµ¬ì„± ë‹¨ê³„ì— ë”°ë¼ ì‚­ì œí•˜ë©´ ëœë‹¤.\n1 2 3 4 5 1. EC2 Auto Scaling ê·¸ë£¹ ì‚­ì œ 2. EC2 ì‹œì‘ í…œí”Œë¦¿ Launch Templates ì‚­ì œ 3. S3 ë²„í‚· ë¹„ìš°ê¸° 4. Route53ì— ì¶”ê°€ëœ A ë ˆì½”ë“œ 3ê°œ ì‚­ì œ 5. CloudFormation ì‚­ì œ VPC ë¬¸ì œëŠ” S3 ë²„í‚·ë§Œ ì§€ìš°ë©´ ëì—ˆë‹¤. Cloudformtation ìŠ¤íƒ ìƒì„±ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•˜ì—¬ AWS ë¦¬ì†ŒìŠ¤ë“¤ì€ ìƒì„±ë˜ì§€ ì•Šì•˜ê¸° ë•Œë¬¸ì´ë‹¤. ì•„ë˜ëŠ” kops ë¥¼ í†µí•œ í´ëŸ¬ìŠ¤í„° êµ¬ì„± ê³¼ì •ì„ ì •ë¦¬í•˜ì˜€ë‹¤\n1 2 3 4 5 6 7 8 1. kops create cluster ëª…ë ¹ì–´ ì‹¤í–‰ 2. í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì •ë³´ë¥¼ S3ì— ì €ì¥ 3. í´ëŸ¬ìŠ¤í„° êµ¬ì„± ì •ë³´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ CloudFormation ìŠ¤íƒ ìƒì„± 4. VPC ë° ê´€ë ¨ ë¦¬ì†ŒìŠ¤ ìƒì„± 5. ë§ˆìŠ¤í„° ë…¸ë“œ EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± 6. ë…¸ë“œ ê·¸ë£¹ EC2 ì¸ìŠ¤í„´ìŠ¤ ìƒì„± 7. ë…¸ë“œ ê·¸ë£¹ EC2 ì¸ìŠ¤í„´ìŠ¤ê°€ ë§ˆìŠ¤í„° ë…¸ë“œë¥¼ ì°¸ì¡°í•˜ì—¬ í´ëŸ¬ìŠ¤í„°ì— ê°€ì… 8. í´ëŸ¬ìŠ¤í„°ê°€ ì‹¤í–‰ë˜ê³  kubectlì„ í†µí•´ ì•¡ì„¸ìŠ¤ ê°€ëŠ¥í•´ì§ í´ëŸ¬ìŠ¤í„° êµ¬ì„± í™•ì¸ í™•ì¸\nìŠ¤í„°ë”” ì‹¤ìŠµ ë‚´ìš©ìœ¼ë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì„± í™•ì¸ì— ëŒ€í•œ ê²ƒë„ ì‹œê°„ì„ í• ë‹¹í•˜ì—¬ í™•ì¸í•˜ì˜€ë‹¤. ì¿ ë²„ë„¤í‹°ìŠ¤ í´ëŸ¬ìŠ¤í„°ê°€ ë³µì¡í•œ ë§Œí¼ í™•ì¸í•  ê²ƒì´ ë§ì•˜ëŠ”ë°, ì‹¤ìŠµ ë‚´ìš©ì„ ì°¸ê³ ë¡œ í•˜ì—¬ ëª…ë ¹ì–´ë¥¼ ì •ë¦¬í•´ë³´ì•˜ë‹¤.\ní´ëŸ¬ìŠ¤í„° ë„ë©”ì¸ í™•ì¸\ní´ëŸ¬ìŠ¤í„° êµ¬ì„±ì‹œ í´ëŸ¬ìŠ¤í„° ì´ë¦„ì„ í¼ë¸”ë¦­ ë„ë©”ì¸ìœ¼ë¡œ ì…ë ¥í•˜ì˜€ë‹¤. í•„ìëŠ” í¼ë¸”ë¦­ ë„ë©”ì¸ì„ AWS Route53 ì—ì„œ êµ¬ë§¤í•˜ì˜€ëŠ”ë°, ì´ ê°™ì€ ê²½ìš° route53ì—ì„œ Aë ˆì½”ë“œë„ë©”ì¸ì´ ì¶”ê°€ëœ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\ní´ëŸ¬ìŠ¤í„° êµ¬ì„± ì •ë³´ í™•ì¸\ní´ëŸ¬ìŠ¤í„° êµ¬ì„± ì •ë³´ëŠ” kubectl ì™€ kops íˆ´ë¡œ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. kops íˆ´ì„ í†µí•´ í´ëŸ¬ìŠ¤í„° ì •ë³´ ë¿ë§Œ ì•„ë‹ˆë¼ ì´ë¯¸ì§€ í™•ì¸(assets), ë³´ì•ˆ ì •ë³´ í™•ì¸ì´ ê°€ëŠ¥í•˜ë‹¤. ê³µì‹ë¬¸ì„œë¥¼ ë§í¬í•œë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 # í´ëŸ¬ìŠ¤í„° í™•ì¸ kops get cluster # í´ëŸ¬ìŠ¤í„° ì¸ìŠ¤í„´ìŠ¤ ê·¸ë£¹ í™•ì¸ kops get ig # í´ëŸ¬ìŠ¤í„° ì¸ìŠ¤í„´ìŠ¤ í™•ì¸ kops get instances # í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ ì •ë³´ í™•ì¸ kubectl get nodes -v6 # í´ëŸ¬ìŠ¤í„° ë°°í¬ íŒŒë“œ í™•ì¸ kubectl get pods -A # í´ëŸ¬ìŠ¤í„° ì •ë³´ í™•ì¸ k**ubectl cluster-info dump** í´ëŸ¬ìŠ¤í„° ì„¸ë¶€ êµ¬ì„± í™•ì¸\ní´ëŸ¬ìŠ¤í„° ì„¸ë¶€ êµ¬ì„± í™•ì¸ìœ¼ë¡œ ìŠ¤í† ë¦¬ì§€, ë„¤íŠ¸ì›Œí¬, íŒŒë“œ, ë§ˆìŠ¤í„° ë…¸ë“œ ì»´í¬ë„ŒíŠ¸ë“¤ì˜ êµ¬ì„± ì •ë³´ë¥¼ í™•ì¸í•˜ì˜€ë‹¤. ì¶”í›„ ì°¸ê³ ìš©ì„ ìœ„í•´ ì •ë¦¬í•´ë‘”ë‹¤. í¼ë¸”ë¦­ ë„ë©”ì¸ì„ ì´ìš©í•˜ì—¬ êµ¬ì„± ì •ë³´ë¥¼ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 # storage class í™•ì¸ kubectl get sc # ë…¸ë“œë³„ ìŠ¤í† ë¦¬ì§€ í™•ì¸ lsblk df -hT # ë„¤íŠ¸ì›Œí¬ í™•ì¸ sudo iptables -t nat -S # ë§ˆìŠ¤í„° ë…¸ë“œ ì»´í¬ë„ŒíŠ¸ í™•ì¸ **tree /etc/kubernetes/manifests/ # kubelet ì‘ë™ í™•ì¸ systemctl status kubelet # ì»¨í…Œì´ë„ˆ ì ‘ê·¼ ë°©ë²• í™•ì¸ ps axf | grep /usr/bin/containerd # ec2 ë©”íƒ€ë°ì´í„° í™•ì¸ - IAM role í™•ì¸** TOKEN=`curl -s -X PUT \u0026#34;http://169.254.169.254/latest/api/token\u0026#34; -H \u0026#34;X-aws-ec2-metadata-token-ttl-seconds: 21600\u0026#34;` echo $TOKEN curl -s -H \u0026#34;X-aws-ec2-metadata-token: $TOKEN\u0026#34; â€“v http://169.254.169.254/latest/meta-data/iam/security-credentials/\u0026lt;ë„ë©”ì¸\u0026gt; | jq kubectl get sc : kopsë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì„±ì‹œ ìŠ¤í† ë¦¬ì§€ CSI ê°€ ê¸°ë³¸ ì œê³µëœë‹¤. ìŠ¤í† ë¦¬ì§€ CSI ëŠ” í´ëŸ¬ìŠ¤í„° ìŠ¤í† ë¦¬ì§€ ê´€ë¦¬ ê¸°ëŠ¥ í”ŒëŸ¬ê·¸ì¸ì´ë‹¤. kops-csi ì™€ kops-ssd ê°€ ì¡´ì¬í•˜ëŠ”ë° kops-csi ëŠ” AWS EBS(gp3), EFS, GCP ë“±ì˜ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í”ŒëŸ¬ê·¸ì¸ì´ê³ , kops-ssd ëŠ” NVMe SSD ê¸°ë°˜ ì¸ìŠ¤í„´ìŠ¤ ìŠ¤í† ë¦¬ì§€ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” í”ŒëŸ¬ê·¸ì¸ì´ë‹¤.\nsudo iptables -t nat -S : Kubernetesì—ì„œ ì‚¬ìš©í•˜ëŠ” iptables rule ì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤. ì´ë²ˆ ì¥ì—ì„œ êµ¬ì„±í•œ ë„¤íŠ¸ì›Œí¬ CNIëŠ” VPCë¡œ ë…¸ë“œ IPì™€ ì„œë¹„ìŠ¤ IPì˜ í• ë‹¹ë³„ iptables ruleì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.\níŒŒë“œ IP ì„¤ì • iptables rule\nì„ì˜ì˜ ì• í”Œë¦¬ì¼€ì´ì…˜ íŒŒë“œ IPë¥¼ í™•ì¸í–ˆë‹¤. ì²´ì¸ì„ ë”°ë¼ê°€ë³´ë©´ ë“¤ì–´ì˜¤ëŠ” íŒ¨í‚· ì¤‘ ëª©ì ì§€ IP ì£¼ì†Œê°€ 100.64.59.121/32ì´ê³ , í”„ë¡œí† ì½œì´ TCPì´ë©°, ëª©ì ì§€ í¬íŠ¸ê°€ 80ì¸ íŒ¨í‚·ì´ 172.30.41.131:8080(íŒŒë“œ í• ë‹¹ IP) ìœ¼ë¡œ ê°€ëŠ” ê²ƒì„ í™•ì¸ í•  ìˆ˜ ìˆë‹¤. ë…¸ë“œ IP ì„¤ì • iptables rule\nì„ì˜ì˜ ë…¸íŠ¸ IPë¥¼ í™•ì¸í–ˆë‹¤. ë…¸ë“œ IPì— ëŒ€í•´NAT ê·œì¹™ì„ ì ìš©í•˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆì—ˆë‹¤. tree /etc/kubernetes/manifests/ : ë§ˆìŠ¤í„° ë…¸ë“œì—ì„œ ì‘ë™í•˜ëŠ” ì»´í¬ë„ŒíŠ¸ mainfest ì •ë³´ë“¤ì´ë‹¤. kubeletì— ì˜í•´ Static Podë¡œ ë°°í¬ë˜ì–´ ìˆìœ¼ë©° API ì„œë²„ì˜ ëª…ë ¹ì–´(kubectl apply, delete) ë“±ìœ¼ë¡œ ê´€ë¦¬ê°€ ë¶ˆê°€ëŠ¥í•˜ë‹¤. kubeletì„ í†µí•´ ì•„ë˜ ì»´í¬ë„ŒíŠ¸ì˜ manifest ë¥¼ ëª¨ë‹ˆí„°ë§í•˜ê³  ìˆìœ¼ë©° manifest ìˆ˜ì •ì‹œ ìë™ìœ¼ë¡œ ì—…ë°ì´íŠ¸ëœë‹¤.\n1 2 3 4 5 6 7 /etc/kubernetes/manifests/ â”œâ”€â”€ etcd-events-master-ap-northeast-2a.manifest â”œâ”€â”€ etcd-main-master-ap-northeast-2a.manifest â”œâ”€â”€ kube-apiserver.manifest â”œâ”€â”€ kube-controller-manager.manifest â”œâ”€â”€ kube-proxy.manifest â””â”€â”€ kube-scheduler.manifest 3. External DNS, ê²Œì„ ë§ˆë¦¬ì˜¤ ë°°í¬ ì‹¤ìŠµ ì˜ˆì œë¡œëŠ” ê²Œì„ ë§ˆë¦¬ì˜¤ë¥¼ ë°°í¬í•˜ì˜€ë‹¤. External DNSì€ ì¿ ë²„ë„¤í‹°ìŠ¤ addonìœ¼ë¡œ, ë‚´ë¶€ì—ì„œ ë™ì‘í•˜ëŠ” ë§ˆë¦¬ì˜¤ ì„œë¹„ìŠ¤ì˜ IP ì£¼ì†Œë¥¼ ì™¸ë¶€ì˜ DNS ì„œë²„ì— ìë™ìœ¼ë¡œ ë“±ë¡ì‹œì¼œì£¼ê¸° ìœ„í•´ ë°°í¬í•˜ì˜€ë‹¤. ì¸ìƒ ê¹Šì€ ì ì€ addonì¸ ExternalDNS ë°°í¬ì˜€ëŠ”ë°, kopsë¥¼ í†µí•´ í´ëŸ¬ìŠ¤í„° ì •ë³´ë¥¼ ìˆ˜ì •í•˜ë‹ˆ ìë™ìœ¼ë¡œ ë°°í¬ë˜ì—ˆë‹¤.\nê³µì‹ ë¬¸ì„œ1, ê³µì‹ ë¬¸ì„œ2 ì—ëŠ” í´ëŸ¬ìŠ¤í„° ìŠ¤í™ ìˆ˜ì •ì‹œì˜ ì˜µì…˜ì´ ì˜ ì •ë¦¬ë˜ì–´ ìˆë‹¤. ì¶”í›„ ê¸°ëŠ¥ í…ŒìŠ¤íŠ¸ì‹œ ì ‘ê·¼ì„ ìœ„í•´ ë‚¨ê²¨ë‘”ë‹¤.\n1 2 3 4 5 6 7 8 9 10 11 12 # í´ëŸ¬ìŠ¤í„° ìˆ˜ì • kops edit cluster # ì•„ë˜ spec ì— ExternalDNS ì •ë³´ ì¶”ê°€** -------------------------- spec: externalDns: provider: external-dns -------------------------- # í´ëŸ¬ìŠ¤í„° ì—…ë°ì´íŠ¸ í›„, ë¡¤ë§ ì—…ë°ì´íŠ¸ ì§„í–‰ kops update cluster --yes \u0026amp;\u0026amp; echo \u0026amp;\u0026amp; sleep 3 \u0026amp;\u0026amp; kops rolling-update cluster íŠ¸ëŸ¬ë¸”ìŠˆíŒ… API ì„œë²„ ì ‘ê·¼ì‹œ, ì•„ë˜ì˜ ì—ëŸ¬ ë©”ì„¸ì§€(couldnâ€™t get current server API group list: ~ dial tcp connect refused )ê°€ í™•ì¸ë˜ì—ˆë‹¤.\nì›ì¸ì€ í´ëŸ¬ìŠ¤í„° ì ‘ê·¼ í† í° ë§Œë£Œì˜€ë‹¤. kops ëª…ë ¹ì–´ë¥¼ í†µí•´ ìê²© ì¦ëª…ì„ ì¬ë°œê¸‰(kops export kubeconfig) ë°›ì„ ìˆ˜ ìˆë‹¤í•˜ì—¬ ì‹œë„í•´ë³´ì•˜ì§€ë§Œ, ì¿ ë²„ë„¤í‹°ìŠ¤ ìœ ì €ê°€ ì—†ì–´ì„œ ê·¸ëŸ°ì§€ ì ‘ê·¼ í† í°ì´ null ë¡œ ë°œê¸‰ë˜ì—ˆë‹¤. kops í´ëŸ¬ìŠ¤í„° ê´€ë¦¬ ì €ì¥ì†Œì¸ s3ì—ë„ ì ‘ê·¼ í† í° ì •ë³´ê°€ ì—†ì—ˆë‹¤. í•„ìëŠ” ë§ˆìŠ¤í„° ë…¸ë“œì— ì ‘ê·¼(~/.kube/config)í•˜ì—¬ í† í°ì„ ë³µì‚¬í•˜ë‹ˆ í•´ê²°í•˜ì˜€ë‹¤.\në§ˆì¹˜ë©° kops ê°„ë‹¨í•˜ë‹¤! íŠ¹íˆ ë§ˆìŠ¤í„° ë…¸ë“œë¥¼ ì§ì ‘ ì ‘ê·¼í•˜ì—¬ ì»¨íŠ¸ë¡¤í•  ìˆ˜ ìˆì–´ í´ëŸ¬ìŠ¤í„° ë™ì‘ ì´í•´ì— ì¢‹ì€ íˆ´ì´ì˜€ë‹¤. ê³µì‹ë¬¸ì„œë„ ì°¸ê³ í•  ê²ƒì´ ë§ë‹¤. ê³µì‹ ë¬¸ì„œ kops operation ì— ì¬ë°ŒëŠ” ì£¼ì œë“¤(ì¹´íœí„°)ì´ ë§ë˜ë° ì–¼ë¥¸ í…ŒìŠ¤íŠ¸í•´ë³´ê³  ì‹¶ì€ ë§ˆìŒì´ë‹¤. ì‹œê°„ë‚˜ëŠ”ëŒ€ë¡œ ì •ë¦¬í•´ì„œ ì˜¬ë ¤ë³´ê² ë‹¤.\n","date":"Mar 10","permalink":"https://HanHoRang31.github.io/post/pkos2-1-kops/","tags":["KANS","kops","cloud","AWS","kubernetes"],"title":"[PKOS] Kopsë¡œ í´ëŸ¬ìŠ¤í„° êµ¬ì¶•í•˜ê¸°"},{"categories":null,"contents":"","date":"Jan 01","permalink":"https://HanHoRang31.github.io/articles/","tags":null,"title":"Articles"}]